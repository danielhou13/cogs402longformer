{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation of BertForSequenceClassification in captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import IntegratedGradients, LayerConductance, LayerIntegratedGradients\n",
    "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.zero_grad()\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inputs):\n",
    "    print(\"[0]\", model(inputs)[0])\n",
    "    print(\"logits\", model(inputs).logits)\n",
    "    return model(inputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_token_id = tokenizer.pad_token_id # A token used for generating token reference\n",
    "sep_token_id = tokenizer.sep_token_id # A token used as a separator between question and text and it is also added to the end of the text.\n",
    "cls_token_id = tokenizer.cls_token_id # A token used for prepending to the concatenated question-text word sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_input_ref_pair(text, ref_token_id, sep_token_id, cls_token_id):\n",
    "\n",
    "    text_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + text_ids + [sep_token_id]\n",
    "    # construct reference token ids \n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(text_ids) + [sep_token_id]\n",
    "\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(text_ids)\n",
    "\n",
    "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
    "    seq_len = input_ids.size(1)\n",
    "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
    "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)# * -1\n",
    "    return token_type_ids, ref_token_type_ids\n",
    "\n",
    "def construct_input_ref_pos_id_pair(input_ids):\n",
    "    seq_length = input_ids.size(1)\n",
    "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
    "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
    "\n",
    "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    return position_ids, ref_position_ids\n",
    "    \n",
    "def construct_attention_mask(input_ids):\n",
    "    return torch.ones_like(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_forward(inputs):\n",
    "    preds = predict(inputs)\n",
    "    return torch.softmax(preds, dim = 1)[0][0].unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lig = LayerIntegratedGradients(custom_forward, model.bert.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"These tests do not work as expected.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, ref_input_ids, sep_id = construct_input_ref_pair(text, ref_token_id, sep_token_id, cls_token_id)\n",
    "token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, sep_id)\n",
    "position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "attention_mask = construct_attention_mask(input_ids)\n",
    "\n",
    "indices = input_ids[0].detach().tolist()\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-0.4273, -0.4544]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] tensor([[-0.4273, -0.4544]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "logits tensor([[-0.4273, -0.4544]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4273, -0.4544]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] tensor([[-0.4273, -0.4544]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "logits tensor([[-0.4273, -0.4544]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.5068], device='cuda:0', grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_forward(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] tensor([[-0.4273, -0.4544]], device='cuda:0')\n",
      "logits tensor([[-0.4273, -0.4544]], device='cuda:0')\n",
      "[0] tensor([[-0.4605, -0.2021]], device='cuda:0')\n",
      "logits tensor([[-0.4605, -0.2021]], device='cuda:0')\n",
      "[0] tensor([[-0.4601, -0.2025],\n",
      "        [-0.4605, -0.2058],\n",
      "        [-0.4606, -0.2109],\n",
      "        [-0.4598, -0.2176],\n",
      "        [-0.4591, -0.2273],\n",
      "        [-0.4576, -0.2394],\n",
      "        [-0.4557, -0.2545],\n",
      "        [-0.4520, -0.2718],\n",
      "        [-0.4467, -0.2925],\n",
      "        [-0.4395, -0.3169],\n",
      "        [-0.4301, -0.3448],\n",
      "        [-0.4177, -0.3738],\n",
      "        [-0.4027, -0.4049],\n",
      "        [-0.3861, -0.4365],\n",
      "        [-0.3680, -0.4704],\n",
      "        [-0.3501, -0.5103],\n",
      "        [-0.3313, -0.5565],\n",
      "        [-0.2948, -0.5728],\n",
      "        [-0.2679, -0.5732],\n",
      "        [-0.2714, -0.5778],\n",
      "        [-0.3487, -0.5928],\n",
      "        [-0.3946, -0.5775],\n",
      "        [-0.3777, -0.5418],\n",
      "        [-0.3761, -0.5293],\n",
      "        [-0.3722, -0.5326],\n",
      "        [-0.3610, -0.5259],\n",
      "        [-0.3510, -0.5116],\n",
      "        [-0.3462, -0.4981],\n",
      "        [-0.3471, -0.4862],\n",
      "        [-0.3519, -0.4763],\n",
      "        [-0.3592, -0.4680],\n",
      "        [-0.3676, -0.4621],\n",
      "        [-0.3757, -0.4580],\n",
      "        [-0.3830, -0.4556],\n",
      "        [-0.3895, -0.4540],\n",
      "        [-0.3949, -0.4530],\n",
      "        [-0.3998, -0.4526],\n",
      "        [-0.4041, -0.4522],\n",
      "        [-0.4075, -0.4522],\n",
      "        [-0.4108, -0.4524],\n",
      "        [-0.4138, -0.4528],\n",
      "        [-0.4163, -0.4529],\n",
      "        [-0.4188, -0.4532],\n",
      "        [-0.4207, -0.4531],\n",
      "        [-0.4227, -0.4536],\n",
      "        [-0.4240, -0.4539],\n",
      "        [-0.4255, -0.4544],\n",
      "        [-0.4264, -0.4543],\n",
      "        [-0.4272, -0.4547],\n",
      "        [-0.4274, -0.4545]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "logits tensor([[-0.4601, -0.2025],\n",
      "        [-0.4605, -0.2058],\n",
      "        [-0.4606, -0.2109],\n",
      "        [-0.4598, -0.2176],\n",
      "        [-0.4591, -0.2273],\n",
      "        [-0.4576, -0.2394],\n",
      "        [-0.4557, -0.2545],\n",
      "        [-0.4520, -0.2718],\n",
      "        [-0.4467, -0.2925],\n",
      "        [-0.4395, -0.3169],\n",
      "        [-0.4301, -0.3448],\n",
      "        [-0.4177, -0.3738],\n",
      "        [-0.4027, -0.4049],\n",
      "        [-0.3861, -0.4365],\n",
      "        [-0.3680, -0.4704],\n",
      "        [-0.3501, -0.5103],\n",
      "        [-0.3313, -0.5565],\n",
      "        [-0.2948, -0.5728],\n",
      "        [-0.2679, -0.5732],\n",
      "        [-0.2714, -0.5778],\n",
      "        [-0.3487, -0.5928],\n",
      "        [-0.3946, -0.5775],\n",
      "        [-0.3777, -0.5418],\n",
      "        [-0.3761, -0.5293],\n",
      "        [-0.3722, -0.5326],\n",
      "        [-0.3610, -0.5259],\n",
      "        [-0.3510, -0.5116],\n",
      "        [-0.3462, -0.4981],\n",
      "        [-0.3471, -0.4862],\n",
      "        [-0.3519, -0.4763],\n",
      "        [-0.3592, -0.4680],\n",
      "        [-0.3676, -0.4621],\n",
      "        [-0.3757, -0.4580],\n",
      "        [-0.3830, -0.4556],\n",
      "        [-0.3895, -0.4540],\n",
      "        [-0.3949, -0.4530],\n",
      "        [-0.3998, -0.4526],\n",
      "        [-0.4041, -0.4522],\n",
      "        [-0.4075, -0.4522],\n",
      "        [-0.4108, -0.4524],\n",
      "        [-0.4138, -0.4528],\n",
      "        [-0.4163, -0.4529],\n",
      "        [-0.4188, -0.4532],\n",
      "        [-0.4207, -0.4531],\n",
      "        [-0.4227, -0.4536],\n",
      "        [-0.4240, -0.4539],\n",
      "        [-0.4255, -0.4544],\n",
      "        [-0.4264, -0.4543],\n",
      "        [-0.4272, -0.4547],\n",
      "        [-0.4274, -0.4545]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "[0] tensor([[-0.4605, -0.2021]], device='cuda:0')\n",
      "logits tensor([[-0.4605, -0.2021]], device='cuda:0')\n",
      "[0] tensor([[-0.4273, -0.4544]], device='cuda:0')\n",
      "logits tensor([[-0.4273, -0.4544]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "attributions, delta = lig.attribute(inputs=input_ids,\n",
    "                                    baselines=ref_input_ids,\n",
    "                                    return_convergence_delta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] tensor([[-0.4273, -0.4544]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "logits tensor([[-0.4273, -0.4544]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Question:  These tests do not work as expected.\n",
      "Predicted Answer: 0, prob ungrammatical: 0.5067745\n"
     ]
    }
   ],
   "source": [
    "score = predict(input_ids)\n",
    "\n",
    "print('Question: ', text)\n",
    "print('Predicted Answer: ' + str(torch.argmax(score[0]).cpu().numpy()) + ', prob ungrammatical: ' + str(torch.softmax(score, dim = 1)[0][0].cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_attributions(attributions):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions_sum = summarize_attributions(attributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Visualization For Score \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (0.51)</b></text></td><td><text style=\"padding-right:2em\"><b>These tests do not work as expected.</b></text></td><td><text style=\"padding-right:2em\"><b>2.17</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> these                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> tests                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> do                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> not                    </font></mark><mark style=\"background-color: hsl(120, 75%, 78%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> work                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> expected                    </font></mark><mark style=\"background-color: hsl(120, 75%, 62%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (0.51)</b></text></td><td><text style=\"padding-right:2em\"><b>These tests do not work as expected.</b></text></td><td><text style=\"padding-right:2em\"><b>2.17</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> these                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> tests                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> do                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> not                    </font></mark><mark style=\"background-color: hsl(120, 75%, 78%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> work                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> expected                    </font></mark><mark style=\"background-color: hsl(120, 75%, 62%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# storing couple samples in an array for visualization purposes\n",
    "score_vis = viz.VisualizationDataRecord(\n",
    "                        attributions_sum,\n",
    "                        torch.softmax(score, dim = 1)[0][0],\n",
    "                        torch.argmax(torch.softmax(score, dim = 1)[0]),\n",
    "                        0,\n",
    "                        text,\n",
    "                        attributions_sum.sum(),       \n",
    "                        all_tokens,\n",
    "                        delta)\n",
    "\n",
    "print('\\033[1m', 'Visualization For Score', '\\033[0m')\n",
    "viz.visualize_text([score_vis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "cogs402",
   "language": "python",
   "name": "cogs402"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
