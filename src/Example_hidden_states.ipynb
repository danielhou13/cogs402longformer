{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielhou13/cogs402longformer/blob/main/src/Example_hidden_states.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZTPlUo8Wp1T",
        "outputId": "c072f1a9-c2f6-4a9b-977b-e99e94817011"
      },
      "id": "kZTPlUo8Wp1T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys\n",
        "# sys.path.append('/content/drive/My Drive/{}'.format(\"cogs402longformer/\"))"
      ],
      "metadata": {
        "id": "AlcBiC0nWtJE"
      },
      "id": "AlcBiC0nWtJE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets --quiet"
      ],
      "metadata": {
        "id": "s_6vceLhTIBf"
      },
      "id": "s_6vceLhTIBf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-qXH2JkTMdA",
        "outputId": "db9a9676-d6fa-4ddc-8706-248cf5f4e907"
      },
      "id": "M-qXH2JkTMdA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Dataset and Model"
      ],
      "metadata": {
        "id": "hSSPoSRn6r9A"
      },
      "id": "hSSPoSRn6r9A"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b774ad0-b725-4910-9050-423edf160ebd",
      "metadata": {
        "id": "9b774ad0-b725-4910-9050-423edf160ebd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the Reserach Papers dataset"
      ],
      "metadata": {
        "id": "hfHRqrpw_VlN"
      },
      "id": "hfHRqrpw_VlN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66cc97f5-7e3a-476c-9858-5643eeaa6675",
      "metadata": {
        "id": "66cc97f5-7e3a-476c-9858-5643eeaa6675"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "\n",
        "def longformer_finetuned_papers():\n",
        "    model = AutoModelForSequenceClassification.from_pretrained('danielhou13/longformer-finetuned_papers', num_labels = 2)\n",
        "    return model\n",
        "\n",
        "def preprocess_function(tokenizer, example, max_length):\n",
        "    example.update(tokenizer(example['text'], padding='max_length', max_length=max_length, truncation=True))\n",
        "    return example\n",
        "\n",
        "def get_papers_dataset(dataset_type):\n",
        "    max_length = 2048\n",
        "    dataset = load_dataset(\"danielhou13/cogs402dataset\")[dataset_type]\n",
        "\n",
        "    # tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "    dataset = dataset.map(lambda x: preprocess_function(tokenizer, x, max_length), batched=True)\n",
        "    setattr(dataset, 'input_columns', ['input_ids', 'attention_mask'])\n",
        "    setattr(dataset, 'target_columns', ['labels'])\n",
        "    setattr(dataset, 'max_length', max_length)\n",
        "    setattr(dataset, 'tokenizer', tokenizer)\n",
        "    return dataset\n",
        "\n",
        "def papers_test_set():\n",
        "    return get_papers_dataset('test')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the news dataset"
      ],
      "metadata": {
        "id": "Jq_wt-jn_Y6m"
      },
      "id": "Jq_wt-jn_Y6m"
    },
    {
      "cell_type": "code",
      "source": [
        "# def preprocess_function(tokenizer, example, max_length):\n",
        "#     example.update(tokenizer(example['text'], padding='max_length', max_length=max_length, truncation=True))\n",
        "#     return example\n",
        "\n",
        "# def longformer_finetuned_news():\n",
        "#     model = AutoModelForSequenceClassification.from_pretrained('danielhou13/longformer-finetuned-news-cogs402', num_labels = 2)\n",
        "#     return model\n",
        "\n",
        "# def get_news_dataset(dataset_type):\n",
        "#     max_length = 2048\n",
        "#     dataset = load_dataset(\"danielhou13/cogs402dataset2\")[dataset_type]\n",
        "\n",
        "#     tokenizer = AutoTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "#     dataset = dataset.map(lambda x: preprocess_function(tokenizer, x, max_length), batched=True)\n",
        "\n",
        "#     labels = map(int, dataset['hyperpartisan'])\n",
        "#     print(type(dataset['hyperpartisan']))\n",
        "#     labels = list(labels)\n",
        "#     dataset = dataset.add_column(\"labels\", labels)\n",
        "\n",
        "#     dataset = dataset.remove_columns(['text', 'title', 'hyperpartisan', 'url', 'published_at', 'bias'])\n",
        "#     print(dataset)\n",
        "#     setattr(dataset, 'input_columns', ['input_ids', 'attention_mask'])\n",
        "#     setattr(dataset, 'target_columns', ['labels'])\n",
        "#     setattr(dataset, 'max_length', max_length)\n",
        "#     setattr(dataset, 'tokenizer', tokenizer)\n",
        "#     return dataset\n",
        "\n",
        "# def news_train_set():\n",
        "#     return get_news_dataset('train')\n",
        "\n",
        "# def news_test_set():\n",
        "#     return get_news_dataset('validation')"
      ],
      "metadata": {
        "id": "gEI0AFC5-0qA"
      },
      "id": "gEI0AFC5-0qA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load papers model and dataset and preprocess it"
      ],
      "metadata": {
        "id": "srzj_2BeNGOK"
      },
      "id": "srzj_2BeNGOK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24ad54a3-db97-47e3-8cc7-417d4db2c99b",
      "metadata": {
        "id": "24ad54a3-db97-47e3-8cc7-417d4db2c99b"
      },
      "outputs": [],
      "source": [
        "cogs402_test = papers_test_set()\n",
        "model = longformer_finetuned_papers()\n",
        "columns = cogs402_test.input_columns + cogs402_test.target_columns\n",
        "print(columns)\n",
        "cogs402_test.set_format(type='torch', columns=columns)\n",
        "cogs402_test=cogs402_test.remove_columns(['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load news model and dataset and preprocess it"
      ],
      "metadata": {
        "id": "22BIYrX8NOVC"
      },
      "id": "22BIYrX8NOVC"
    },
    {
      "cell_type": "code",
      "source": [
        "# cogs402_test = news_test_set()\n",
        "# model = longformer_finetuned_news()\n",
        "# columns = cogs402_test.input_columns + cogs402_test.target_columns\n",
        "# print(columns)\n",
        "# cogs402_test.set_format(type='torch', columns=columns)"
      ],
      "metadata": {
        "id": "xh-YZZyo_eZx"
      },
      "id": "xh-YZZyo_eZx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deaabfa2-0855-41fd-870c-7a8b91e32d44",
      "metadata": {
        "id": "deaabfa2-0855-41fd-870c-7a8b91e32d44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae8c4d86-c913-4b8f-9978-fed62f9b10eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "print(model.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take example for evaluation and get the hidden_states"
      ],
      "metadata": {
        "id": "d4DdhW2T6wHE"
      },
      "id": "d4DdhW2T6wHE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a35e74a3-bd67-4ee2-8e5b-2da01503f27b",
      "metadata": {
        "id": "a35e74a3-bd67-4ee2-8e5b-2da01503f27b"
      },
      "outputs": [],
      "source": [
        "testexam = cogs402_test[923]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2abfe181-bc3e-41cb-a56e-30a7cf29d3b7",
      "metadata": {
        "id": "2abfe181-bc3e-41cb-a56e-30a7cf29d3b7"
      },
      "outputs": [],
      "source": [
        "# print(test['labels'][923])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04c5bcaf-5fe3-4813-8444-5cfb2c63a92b",
      "metadata": {
        "id": "04c5bcaf-5fe3-4813-8444-5cfb2c63a92b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8cab6bf-5db0-4d03-91ce-f9eeb73998ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output_attention.shape torch.Size([12, 1, 12, 2048, 514])\n",
            "gl_output_attention.shape torch.Size([12, 1, 12, 2048, 1])\n"
          ]
        }
      ],
      "source": [
        "output = model(testexam[\"input_ids\"].unsqueeze(0).cuda(), \n",
        "               attention_mask=testexam['attention_mask'].unsqueeze(0).cuda(), \n",
        "               labels=testexam['labels'].cuda(), \n",
        "               output_attentions = True,\n",
        "               output_hidden_states = True)\n",
        "hidden_states = output[2]\n",
        "output_attentions = torch.stack(batch_attn).cpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2467c3d1-fe58-4e6d-aa98-534a6df72fcc",
      "metadata": {
        "id": "2467c3d1-fe58-4e6d-aa98-534a6df72fcc"
      },
      "outputs": [],
      "source": [
        "# print(os.getcwd())\n",
        "# yes = torch.load(\"resources/longformer_test2/epoch_3/aggregate_attn.pt\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "Example_hidden_states.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}