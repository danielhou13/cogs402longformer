{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielhou13/cogs402longformer/blob/main/src/Attn_attr_cosine_sim_all.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook explores the relation between the model's attributions and attentions for a given example. Historically, we found that attentions are not a feasible method of explanation whereas attributions are, but attributions are also not part of a model's traditional outputs. Therefore it may be interesting to see if we can find anything with attentions by comparing them to a feasible and plausible method of explanation."
      ],
      "metadata": {
        "id": "mlqrlFd9SzDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4G07aiA37RC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c202488-937c-4113-c8de-e5ab71af8fdb"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dependencies"
      ],
      "metadata": {
        "id": "HkZ5bD2_z-0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers --quiet"
      ],
      "metadata": {
        "id": "zMjzQIFJ2P_T"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install captum --quiet"
      ],
      "metadata": {
        "id": "Uno0qwr12UTd"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets --quiet"
      ],
      "metadata": {
        "id": "OaOSPMJE3ONc"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rbo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTTL5d_d9KDH",
        "outputId": "53e0e7e6-b773-41ab-9edc-3e3ce6dec599"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rbo in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18 in /usr/local/lib/python3.7/dist-packages (from rbo) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "metadata": {
        "id": "hRSNYTrRIPkr"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "wrRRZJ6-0_Il"
      },
      "outputs": [],
      "source": [
        "from captum.attr import visualization as viz\n",
        "from captum.attr import IntegratedGradients, LayerConductance, LayerIntegratedGradients\n",
        "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer\n",
        "\n",
        "import torch\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "b5V31lsc0_Il"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import model"
      ],
      "metadata": {
        "id": "USHRv2j70Fb4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "9nzBfB-v0_Im"
      },
      "outputs": [],
      "source": [
        "from transformers import LongformerForSequenceClassification, LongformerTokenizer, LongformerConfig\n",
        "# replace <PATH-TO-SAVED-MODEL> with the real path of the saved model\n",
        "model_path = 'danielhou13/longformer-finetuned_papers_v2'\n",
        "#model_path = 'danielhou13/longformer-finetuned-new-cogs402'\n",
        "\n",
        "# load model\n",
        "model = LongformerForSequenceClassification.from_pretrained(model_path, num_labels = 2)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "model.zero_grad()\n",
        "\n",
        "# load tokenizer\n",
        "tokenizer = LongformerTokenizer.from_pretrained(\"allenai/longformer-base-4096\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create functions that give us the input ids and the position ids for the text we want to examine"
      ],
      "metadata": {
        "id": "bqbvfvXv0VTp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "y5-heo2y0_Im"
      },
      "outputs": [],
      "source": [
        "def predict(inputs, position_ids=None, attention_mask=None):\n",
        "    output = model(inputs,\n",
        "                   position_ids=position_ids,\n",
        "                   attention_mask=attention_mask)\n",
        "    return output.logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "vAAjmDRl0_In"
      },
      "outputs": [],
      "source": [
        "ref_token_id = tokenizer.pad_token_id # A token used for generating token reference\n",
        "sep_token_id = tokenizer.sep_token_id # A token used as a separator between question and text and it is also added to the end of the text.\n",
        "cls_token_id = tokenizer.cls_token_id # A token used for prepending to the concatenated question-text word sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "UgBSBpz-0_In"
      },
      "outputs": [],
      "source": [
        "max_length = 2046\n",
        "def construct_input_ref_pair(text, ref_token_id, sep_token_id, cls_token_id):\n",
        "\n",
        "    text_ids = tokenizer.encode(text, truncation = True, add_special_tokens=False, max_length = max_length)\n",
        "    # construct input token ids\n",
        "    input_ids = [cls_token_id] + text_ids + [sep_token_id]\n",
        "    # construct reference token ids \n",
        "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(text_ids) + [sep_token_id]\n",
        "\n",
        "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(text_ids)\n",
        "\n",
        "def construct_input_ref_pos_id_pair(input_ids):\n",
        "    seq_length = input_ids.size(1)\n",
        "\n",
        "    #taken from the longformer implementation\n",
        "    mask = input_ids.ne(ref_token_id).int()\n",
        "    incremental_indices = torch.cumsum(mask, dim=1).type_as(mask) * mask\n",
        "    position_ids = incremental_indices.long().squeeze() + ref_token_id\n",
        "\n",
        "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
        "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
        "\n",
        "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
        "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
        "    return position_ids, ref_position_ids\n",
        "    \n",
        "def construct_attention_mask(input_ids):\n",
        "    return torch.ones_like(input_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import dataset and take a few examples from it for testing purposes"
      ],
      "metadata": {
        "id": "BdY6GsO00RG_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we import the papers dataset"
      ],
      "metadata": {
        "id": "e_gGIPpwkmbH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "w6aQM9nM0_Ip",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "3e5071e9fbf94e2da04281922708573a",
            "0621f7a6149b4b749f73b91030e429ff",
            "bcfe5ea0e5354560aae0c533e111c7fb",
            "e9396bae9c9146708507c0f520369ad9",
            "3d80c00c745748fbac8673e901a99d0d",
            "4a7a47616f3b49948887f523cf085db4",
            "4fec74910f7746e28cd391613851017b",
            "54c2f6764a6f4a6ba889f08cfd36d22c",
            "9bf109f713f24c98abea3faa1aa4d45f",
            "237add805bee4a07a09151587aef036d",
            "724f3939a56a45b78f87acca25c2f390"
          ]
        },
        "outputId": "cd74cbf5-3cc9-47c4-83a2-83689061cdbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration danielhou13--cogs402dataset-144b958ac1a53abb\n",
            "Reusing dataset parquet (/root/.cache/huggingface/datasets/danielhou13___parquet/danielhou13--cogs402dataset-144b958ac1a53abb/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e5071e9fbf94e2da04281922708573a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "cogs402_ds = load_dataset(\"danielhou13/cogs402dataset\")[\"test\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we import the news dataset"
      ],
      "metadata": {
        "id": "bHUUw096r-EL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cogs402_ds2 = load_dataset('hyperpartisan_news_detection', 'bypublisher')['validation']\n",
        "# val_size = 5000\n",
        "# val_indices = np.random.randint(0, len(cogs402_ds2), val_size)\n",
        "# val_ds = cogs402_ds2.select(val_indices)\n",
        "# labels2 = map(int, val_ds['hyperpartisan'])\n",
        "# labels2 = list(labels2)\n",
        "# val_ds = val_ds.add_column(\"labels\", labels2)"
      ],
      "metadata": {
        "id": "58zzpZYRWRDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "axwpHq-y0_Io"
      },
      "outputs": [],
      "source": [
        "#set 1 if we are dealing with a positive class, and 0 if dealing with negative class\n",
        "def custom_forward(inputs, position_ids=None, attention_mask=None):\n",
        "    preds = predict(inputs,\n",
        "                   position_ids=position_ids,\n",
        "                   attention_mask=attention_mask\n",
        "                   )\n",
        "    return torch.softmax(preds, dim = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform Layer Integrated Gradients using the longformer's embeddings"
      ],
      "metadata": {
        "id": "bQaYaSDf0buh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "lIeE9P7b0_Ir"
      },
      "outputs": [],
      "source": [
        "def summarize_attributions(attributions):\n",
        "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
        "    return attributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "4uDuDrip0_Ip"
      },
      "outputs": [],
      "source": [
        "lig = LayerIntegratedGradients(custom_forward, model.longformer.embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function will let us get the example and the baseline inputs in order to perform integrated gradients, and add the attributions to our visualization tool. Additionally, we will add the attributions and tokens for each example into an array so we can use them when we want to further example the attributions scores for each example"
      ],
      "metadata": {
        "id": "n2Xp75N0rtqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_attributions = {}\n",
        "# all_tokens = {}"
      ],
      "metadata": {
        "id": "wf1SNgF73l1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_attributions = torch.load('/content/drive/MyDrive/cogs402longformer/results/papers/papers_attributions/example_attrib_dict_all.pt')"
      ],
      "metadata": {
        "id": "g4nc7qSvUedJ"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tqdm import tqdm\n",
        "\n",
        "# for i in tqdm(range(len(cogs402_ds))):\n",
        "#   if str(i) not in all_attributions:\n",
        "#     #get input ids, position ids and attention mask for integrated gradients\n",
        "#     text = cogs402_ds['text'][i]\n",
        "#     label = cogs402_ds['labels'][i]\n",
        "\n",
        "#     input_ids, ref_input_ids, sep_id = construct_input_ref_pair(text, ref_token_id, sep_token_id, cls_token_id)\n",
        "#     position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
        "#     attention_mask = construct_attention_mask(input_ids)\n",
        "\n",
        "#     attributions = lig.attribute(inputs=input_ids,\n",
        "#                                       baselines=ref_input_ids,\n",
        "#                                       additional_forward_args=(position_ids, attention_mask),\n",
        "#                                       target=1,\n",
        "#                                       n_steps=50,\n",
        "#                                       internal_batch_size = 2)\n",
        "\n",
        "#     attributions_sum = summarize_attributions(attributions)\n",
        "\n",
        "#     all_attributions[str(i)] = attributions_sum.detach().cpu().numpy()\n",
        "\n",
        "#     torch.save(all_attributions, '/content/drive/MyDrive/cogs402longformer/results/papers/papers_attributions/example_attrib_dict_all.pt')"
      ],
      "metadata": {
        "id": "ItEOhzhNTdxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then get the attentions and global attentions so we can compare with the attributions"
      ],
      "metadata": {
        "id": "BGDWlUa3GvNS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the longformer has a unique attention matrix shape, we convert it into the required sequence length x sequence length matrix"
      ],
      "metadata": {
        "id": "dISC7-FaG2Lh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_head_matrix(output_attentions, global_attentions):\n",
        "    new_attention_matrix = torch.zeros((output_attentions.shape[0], \n",
        "                                      output_attentions.shape[0]))\n",
        "    for i in range(output_attentions.shape[0]):\n",
        "        test_non_zeroes = torch.nonzero(output_attentions[i]).squeeze()\n",
        "        test2 = output_attentions[i][test_non_zeroes[1:]]\n",
        "        new_attention_matrix_indices = test_non_zeroes[1:]-257 + i\n",
        "        new_attention_matrix[i][new_attention_matrix_indices] = test2\n",
        "        new_attention_matrix[i][0] = output_attentions[i][0]\n",
        "        new_attention_matrix[0] = global_attentions.squeeze()[:output_attentions.shape[0]]\n",
        "    return new_attention_matrix\n",
        "\n",
        "\n",
        "def attentions_all_heads(output_attentions, global_attentions):\n",
        "    new_matrix = []\n",
        "    for i in range(output_attentions.shape[0]):\n",
        "        matrix = create_head_matrix(output_attentions[i], global_attentions[i])\n",
        "        new_matrix.append(matrix)\n",
        "    return torch.stack(new_matrix)\n",
        "\n",
        "def all_layers(output_attentions, global_attentions):\n",
        "    new_matrix = []\n",
        "    for i in range(output_attentions.shape[0]):\n",
        "        matrix = attentions_all_heads(output_attentions[i], global_attentions[i])\n",
        "        new_matrix.append(matrix)\n",
        "    return torch.stack(new_matrix)"
      ],
      "metadata": {
        "id": "AFyZpNST1JRr"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We scale the attention matrix by head importance"
      ],
      "metadata": {
        "id": "WJynBkquG9cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_by_importance(attention_matrix, head_importance):\n",
        "  new_matrix = np.zeros_like(attention_matrix)\n",
        "  for i in range(attention_matrix.shape[0]):\n",
        "    head_importance_layer = head_importance[i]\n",
        "    new_matrix[i] = attention_matrix[i] * np.expand_dims(head_importance_layer, axis=(1))\n",
        "  return new_matrix"
      ],
      "metadata": {
        "id": "nDuqZlIZ1NSr"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head_importance = torch.load(\"/content/drive/MyDrive/cogs402longformer/t3-visapplication/resources/papers/pretrained/head_importance.pt\")\n",
        "# head_importance = torch.load(\"/content/drive/MyDrive/cogs402longformer/t3-visapplication/resources/news/head_importance.pt\")"
      ],
      "metadata": {
        "id": "Bt_2TsKb1ML5"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(all_attentions_final)"
      ],
      "metadata": {
        "id": "mEsQ10FOVNqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following block of code creates a new dictionary of attention matrices. Each key corresponds to their respective example in the dataset (range 0 - dataset length) and stores a layer x head x seq_len matrix of attentions for each key"
      ],
      "metadata": {
        "id": "fCZJ4gIKO8ys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_attentions = {}"
      ],
      "metadata": {
        "id": "F8QC9aqjtiZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following loads a saved dictionary of attention matrices without having applied head importance to the matrices."
      ],
      "metadata": {
        "id": "m-20QqqlPNs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_attentions = torch.load('/content/drive/MyDrive/cogs402longformer/results/papers/papers_attributions/full_attention_matrices/papers_atten_summed_dict.pt')"
      ],
      "metadata": {
        "id": "JeKFfGfueDPZ"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for i in tqdm(range(len(cogs402_ds))):\n",
        "  if str(i) not in all_attentions:\n",
        "    #get input ids, position ids and attention mask for integrated gradients\n",
        "    text = cogs402_ds['text'][i]\n",
        "    label = cogs402_ds['labels'][i]\n",
        "\n",
        "    input_ids, ref_input_ids, sep_id = construct_input_ref_pair(text, ref_token_id, sep_token_id, cls_token_id)\n",
        "    position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
        "    attention_mask = construct_attention_mask(input_ids)\n",
        "\n",
        "    output = model(input_ids.cuda(), attention_mask=attention_mask.cuda(), labels=torch.tensor(label).cuda(), output_attentions = True)\n",
        "\n",
        "    batch_attn = output[-2]\n",
        "    output_attentions = torch.stack(batch_attn).cpu().squeeze()\n",
        "    global_attention = output[-1]\n",
        "    output_global_attentions = torch.stack(global_attention).cpu().squeeze()\n",
        "\n",
        "    converted_mat = all_layers(output_attentions, output_global_attentions).detach().cpu().numpy()\n",
        "    \n",
        "    attention_matrix_summed = converted_mat.sum(axis=2)\n",
        "    all_attentions[str(i)] = attention_matrix_summed\n",
        "\n",
        "    if i%10 == 9:\n",
        "      torch.save(all_attentions, '/content/drive/MyDrive/cogs402longformer/results/papers/papers_attributions/full_attention_matrices/papers_atten_summed_dict.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mx69KUz20KmC",
        "outputId": "d2c86bb2-9980-4464-a4db-47a4daf37309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1070/1070 [11:55:01<00:00, 40.09s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_attentions = torch.load('/content/drive/MyDrive/cogs402longformer/results/papers/papers_attributions/full_attention_matrices/papers_atten_summed_dict.pt')"
      ],
      "metadata": {
        "id": "Zzq88pz5T8Q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following are two dictionaries of attention weights for each token (how much each token is attended to), weighted by head importance, for layer 12 and over all layers. The number of keys in the dictionary is 1070 (number of items in the validation set) and each key contains an array of shape (seq_len,)."
      ],
      "metadata": {
        "id": "DyGjnOpaM8dZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_attentions_final = torch.load('/content/drive/MyDrive/cogs402longformer/results/papers/papers_attributions/full_attention_matrices/example_atten_dict_12.pt')\n",
        "all_attentions_all = torch.load('/content/drive/MyDrive/cogs402longformer/results/papers/papers_attributions/full_attention_matrices/example_atten_dict_all.pt')"
      ],
      "metadata": {
        "id": "eJuGcLQpS-Ky"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_attentions_final = {}\n",
        "all_attentions_all = {}\n",
        "for i in tqdm(range(len(cogs402_ds))):\n",
        "  if str(i) not in all_attentions_final and str(i) not in all_attentions_all:\n",
        "\n",
        "    att_mat = all_attentions[str(i)]\n",
        "\n",
        "    # uncomment the line if you wish to scale by head importance\n",
        "    att_mat = scale_by_importance(att_mat, head_importance)\n",
        "\n",
        "    # Sum the attentions for the last layer and over all layers\n",
        "    attention_final_layer = att_mat[11].sum(axis=0)\n",
        "    all_attentions_final[str(i)] = attention_final_layer\n",
        "\n",
        "    attention_all_layer = att_mat.sum(axis=1)\n",
        "    attention_all_layer = attention_all_layer.sum(axis=0)\n",
        "    all_attentions_all[str(i)] = attention_all_layer\n",
        "    \n",
        "    torch.save(all_attentions_final, '/content/drive/MyDrive/cogs402longformer/results/papers/papers_attributions/full_attention_matrices/example_atten_dict_12.pt')\n",
        "    torch.save(all_attentions_all, '/content/drive/MyDrive/cogs402longformer/results/papers/papers_attributions/full_attention_matrices/example_atten_dict_all.pt')"
      ],
      "metadata": {
        "id": "ZWeFQNW8MmJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4aedc00-5499-4f69-95b0-ebce4e64d452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1070/1070 [02:59<00:00,  5.97it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(data):\n",
        "    return (data - np.min(data)) / (np. max(data) - np.min(data))"
      ],
      "metadata": {
        "id": "ukncMseTj1-K"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following block of code iterates through the entire dataset, grabs the appropriate attributions and attentions from their respective dictionaries, and computes the cosine similarities, kendall tau coefficients, and the RBO."
      ],
      "metadata": {
        "id": "bw08J8acuEY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.linalg import norm\n",
        "import scipy.stats as stats\n",
        "import rbo"
      ],
      "metadata": {
        "id": "t4ppKBXJC3AB"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sim_dataframe(cogs402_ds, all_attentions, all_attributions):\n",
        "\n",
        "  dataframe = []\n",
        "\n",
        "  for i in tqdm(range(len(cogs402_ds))):\n",
        "    exam_attrib = all_attributions[str(i)]\n",
        "    attention_final_layer = all_attentions[str(i)]\n",
        "    \n",
        "    exam_attrib = exam_attrib[:len(all_attentions[str(i)])]\n",
        "\n",
        "    #raw attributions\n",
        "    cosine_raw = np.dot(exam_attrib, attention_final_layer) / (norm(exam_attrib)*norm(attention_final_layer))\n",
        "\n",
        "    attention_final_layer2 = normalize(attention_final_layer)\n",
        "\n",
        "    exam_attrib2 = np.abs(exam_attrib)\n",
        "    exam_attrib2 = normalize(exam_attrib2)\n",
        "    \n",
        "    #normalized attributions\n",
        "    cosine = np.dot(exam_attrib2, attention_final_layer2) / (norm(exam_attrib2)*norm(attention_final_layer2))\n",
        "\n",
        "    exam_attrib3 = np.abs(exam_attrib)\n",
        "    exam_attrib3 = normalize(exam_attrib3)\n",
        "    median_exam = np.percentile(exam_attrib3, 50)\n",
        "    exam_attrib3[exam_attrib3 < median_exam] = 0\n",
        "\n",
        "    attention_final_layer3 = np.copy(attention_final_layer)\n",
        "    attention_final_layer3 = normalize(attention_final_layer3)\n",
        "    median_12 = np.percentile(attention_final_layer3, 50)\n",
        "    attention_final_layer3[attention_final_layer3 < median_12] = 0\n",
        "\n",
        "\n",
        "    #sim for attributions and attentions above the median\n",
        "    cosine_med = np.dot(exam_attrib3, attention_final_layer3) / (norm(exam_attrib3)*norm(attention_final_layer3))\n",
        "\n",
        "    exam_attrib4 = np.abs(exam_attrib)\n",
        "    exam_attrib4 = normalize(exam_attrib4)\n",
        "    mean_exam = np.mean(exam_attrib4)\n",
        "    exam_attrib4[exam_attrib4 < mean_exam] = 0\n",
        "\n",
        "    attention_final_layer4 = np.copy(attention_final_layer)\n",
        "    attention_final_layer4 = normalize(attention_final_layer4)\n",
        "    mean_12 = np.mean(attention_final_layer4)\n",
        "    attention_final_layer4[attention_final_layer4 < mean_12] = 0\n",
        "\n",
        "    #sim for attributions and attentions above the mean\n",
        "    cosine_mean = np.dot(exam_attrib4, attention_final_layer4) / (norm(exam_attrib4)*norm(attention_final_layer4))\n",
        "\n",
        "    exam_attrib_rank = np.abs(exam_attrib)\n",
        "    order_attrib = exam_attrib_rank.argsort()\n",
        "    ranks_attrib = order_attrib.argsort()\n",
        "\n",
        "    attention_final_layer_rank = np.copy(attention_final_layer)\n",
        "    order = attention_final_layer_rank.argsort()\n",
        "    ranks = order.argsort()\n",
        "\n",
        "    #sim using the ranks of the tokens\n",
        "    cosine_rank = np.dot(ranks_attrib, ranks) / (norm(ranks_attrib)*norm(ranks))\n",
        "\n",
        "    tau, p_value = stats.kendalltau(ranks_attrib, ranks)\n",
        "\n",
        "    rbo_sim = rbo.RankingSimilarity(order_attrib, order).rbo()\n",
        "\n",
        "    d = {'example': i, 'similarity normalized': cosine, 'similarity raw': cosine_raw, 'sim_norm w/ median threshold':cosine_med, 'sim_norm w/ mean threshold':cosine_mean, \"sim w/ ranks\":cosine_rank,\n",
        "        \"kendalltau\": tau, \"rbo\":rbo_sim}\n",
        "    dataframe.append(d)\n",
        "\n",
        "  return pd.DataFrame(dataframe)"
      ],
      "metadata": {
        "id": "dmKF8EBP2Nqz"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The attributions and the attentions have different ranges. The attributions could range from -1 to 1 whereas the attentions range from 0 to 1. However, negative attributions would not necessarily mean that they have the lowest attention, rather they might have really high attention as they are more likely to help the model predict the negative class, and might be something the attentions picked up as a feature."
      ],
      "metadata": {
        "id": "6cwcV4jXNWe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = get_sim_dataframe(cogs402_ds, all_attentions_final, all_attributions)"
      ],
      "metadata": {
        "id": "gQIFZTQzlAEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eafc410-9f11-45e3-d373-7b4169e78034"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1070/1070 [00:07<00:00, 142.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = get_sim_dataframe(cogs402_ds, all_attentions_all, all_attributions)"
      ],
      "metadata": {
        "id": "gtCEZaQFOgwh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f8e38a3-3e2e-4580-8189-ced4522a9d8c"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1070/1070 [00:07<00:00, 142.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "Yn97-oeTC_qt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "db119408-33e7-4b67-c9f5-0b85d2d5b763"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      example  similarity normalized  similarity raw  \\\n",
              "0           0               0.086231        0.056545   \n",
              "1           1               0.303640       -0.159406   \n",
              "2           2               0.342358       -0.044282   \n",
              "3           3               0.359119       -0.026443   \n",
              "4           4               0.215446        0.018165   \n",
              "...       ...                    ...             ...   \n",
              "1065     1065               0.193410        0.053807   \n",
              "1066     1066               0.099270        0.013470   \n",
              "1067     1067               0.176846       -0.130924   \n",
              "1068     1068               0.350094        0.027682   \n",
              "1069     1069               0.288194        0.146703   \n",
              "\n",
              "      sim_norm w/ median threshold  sim_norm w/ mean threshold  sim w/ ranks  \\\n",
              "0                         0.085778                    0.080140      0.846132   \n",
              "1                         0.290472                    0.274704      0.787343   \n",
              "2                         0.339240                    0.330811      0.796982   \n",
              "3                         0.358427                    0.351231      0.832356   \n",
              "4                         0.208882                    0.198422      0.784480   \n",
              "...                            ...                         ...           ...   \n",
              "1065                      0.192517                    0.183444      0.844898   \n",
              "1066                      0.098644                    0.089926      0.832053   \n",
              "1067                      0.170863                    0.160646      0.798710   \n",
              "1068                      0.343700                    0.338141      0.779024   \n",
              "1069                      0.280853                    0.256996      0.815511   \n",
              "\n",
              "      kendalltau       rbo  \n",
              "0       0.263652  0.588661  \n",
              "1       0.101176  0.531017  \n",
              "2       0.127206  0.541704  \n",
              "3       0.223314  0.577435  \n",
              "4       0.092379  0.528429  \n",
              "...          ...       ...  \n",
              "1065    0.257581  0.575340  \n",
              "1066    0.222068  0.568146  \n",
              "1067    0.132414  0.548549  \n",
              "1068    0.078339  0.518761  \n",
              "1069    0.177660  0.555712  \n",
              "\n",
              "[1070 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9797b7f6-fc66-4a15-b8e1-46c945e9c232\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>example</th>\n",
              "      <th>similarity normalized</th>\n",
              "      <th>similarity raw</th>\n",
              "      <th>sim_norm w/ median threshold</th>\n",
              "      <th>sim_norm w/ mean threshold</th>\n",
              "      <th>sim w/ ranks</th>\n",
              "      <th>kendalltau</th>\n",
              "      <th>rbo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.086231</td>\n",
              "      <td>0.056545</td>\n",
              "      <td>0.085778</td>\n",
              "      <td>0.080140</td>\n",
              "      <td>0.846132</td>\n",
              "      <td>0.263652</td>\n",
              "      <td>0.588661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.303640</td>\n",
              "      <td>-0.159406</td>\n",
              "      <td>0.290472</td>\n",
              "      <td>0.274704</td>\n",
              "      <td>0.787343</td>\n",
              "      <td>0.101176</td>\n",
              "      <td>0.531017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.342358</td>\n",
              "      <td>-0.044282</td>\n",
              "      <td>0.339240</td>\n",
              "      <td>0.330811</td>\n",
              "      <td>0.796982</td>\n",
              "      <td>0.127206</td>\n",
              "      <td>0.541704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.359119</td>\n",
              "      <td>-0.026443</td>\n",
              "      <td>0.358427</td>\n",
              "      <td>0.351231</td>\n",
              "      <td>0.832356</td>\n",
              "      <td>0.223314</td>\n",
              "      <td>0.577435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.215446</td>\n",
              "      <td>0.018165</td>\n",
              "      <td>0.208882</td>\n",
              "      <td>0.198422</td>\n",
              "      <td>0.784480</td>\n",
              "      <td>0.092379</td>\n",
              "      <td>0.528429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1065</th>\n",
              "      <td>1065</td>\n",
              "      <td>0.193410</td>\n",
              "      <td>0.053807</td>\n",
              "      <td>0.192517</td>\n",
              "      <td>0.183444</td>\n",
              "      <td>0.844898</td>\n",
              "      <td>0.257581</td>\n",
              "      <td>0.575340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1066</th>\n",
              "      <td>1066</td>\n",
              "      <td>0.099270</td>\n",
              "      <td>0.013470</td>\n",
              "      <td>0.098644</td>\n",
              "      <td>0.089926</td>\n",
              "      <td>0.832053</td>\n",
              "      <td>0.222068</td>\n",
              "      <td>0.568146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1067</th>\n",
              "      <td>1067</td>\n",
              "      <td>0.176846</td>\n",
              "      <td>-0.130924</td>\n",
              "      <td>0.170863</td>\n",
              "      <td>0.160646</td>\n",
              "      <td>0.798710</td>\n",
              "      <td>0.132414</td>\n",
              "      <td>0.548549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1068</th>\n",
              "      <td>1068</td>\n",
              "      <td>0.350094</td>\n",
              "      <td>0.027682</td>\n",
              "      <td>0.343700</td>\n",
              "      <td>0.338141</td>\n",
              "      <td>0.779024</td>\n",
              "      <td>0.078339</td>\n",
              "      <td>0.518761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1069</th>\n",
              "      <td>1069</td>\n",
              "      <td>0.288194</td>\n",
              "      <td>0.146703</td>\n",
              "      <td>0.280853</td>\n",
              "      <td>0.256996</td>\n",
              "      <td>0.815511</td>\n",
              "      <td>0.177660</td>\n",
              "      <td>0.555712</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1070 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9797b7f6-fc66-4a15-b8e1-46c945e9c232')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9797b7f6-fc66-4a15-b8e1-46c945e9c232 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9797b7f6-fc66-4a15-b8e1-46c945e9c232');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.max()"
      ],
      "metadata": {
        "id": "SY9blyjLDeUt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f4f47a7-c497-436d-b315-35e93fc500a5"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "example                         1069.000000\n",
              "similarity normalized              0.532130\n",
              "similarity raw                     0.378550\n",
              "sim_norm w/ median threshold       0.529216\n",
              "sim_norm w/ mean threshold         0.521735\n",
              "sim w/ ranks                       0.873251\n",
              "kendalltau                         0.344156\n",
              "rbo                                0.636516\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.min()"
      ],
      "metadata": {
        "id": "U8Egh8vVEL3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76adbaf-606c-4dce-de4f-5f93b7958984"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "example                         0.000000\n",
              "similarity normalized           0.021997\n",
              "similarity raw                 -0.337544\n",
              "sim_norm w/ median threshold    0.021838\n",
              "sim_norm w/ mean threshold      0.018403\n",
              "sim w/ ranks                    0.731883\n",
              "kendalltau                     -0.048717\n",
              "rbo                             0.483627\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"similarity normalized\"].idxmax()"
      ],
      "metadata": {
        "id": "Yx0DGY3nDvLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a13f52b3-06f7-4fc7-f316-13d49485a435"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "589"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"similarity normalized\"].idxmin()"
      ],
      "metadata": {
        "id": "0yC3MwvQEuOX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ae2fd75-dd16-467f-e388-ef8a3354125a"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "903"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[589]"
      ],
      "metadata": {
        "id": "IizF8vq9D-ya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3379d80e-97e2-479f-8ef1-f192d13dea2f"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "example                         589.000000\n",
              "similarity normalized             0.532130\n",
              "similarity raw                    0.013085\n",
              "sim_norm w/ median threshold      0.529216\n",
              "sim_norm w/ mean threshold        0.521735\n",
              "sim w/ ranks                      0.792425\n",
              "kendalltau                        0.114412\n",
              "rbo                               0.533278\n",
              "Name: 589, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.max()"
      ],
      "metadata": {
        "id": "VIDkyg0RDqTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c1c242a-ce28-4655-beb4-13aeded1d14a"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "example                         1069.000000\n",
              "similarity normalized              0.287572\n",
              "similarity raw                     0.198161\n",
              "sim_norm w/ median threshold       0.269140\n",
              "sim_norm w/ mean threshold         0.250140\n",
              "sim w/ ranks                       0.845095\n",
              "kendalltau                         0.266276\n",
              "rbo                                0.606015\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.mean()"
      ],
      "metadata": {
        "id": "2HPzjI4i4Oz0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c8fbb8-1f88-464f-acc6-28dd8a8702d9"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "example                         534.500000\n",
              "similarity normalized             0.227269\n",
              "similarity raw                    0.032436\n",
              "sim_norm w/ median threshold      0.223305\n",
              "sim_norm w/ mean threshold        0.209596\n",
              "sim w/ ranks                      0.811874\n",
              "kendalltau                        0.168294\n",
              "rbo                               0.557020\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdhfJcyEYxpZ",
        "outputId": "0e5d6696-f1cf-41cb-fa90-666ba42f8436"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "example                         534.500000\n",
              "similarity normalized             0.120074\n",
              "similarity raw                    0.016374\n",
              "sim_norm w/ median threshold      0.113154\n",
              "sim_norm w/ mean threshold        0.102037\n",
              "sim w/ ranks                      0.799616\n",
              "kendalltau                        0.134198\n",
              "rbo                               0.542645\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following block of code iterates through the entire dataset, grabs the appropriate attributions and attentions from their respective dictionaries, and computes the cosine similarities, kendall tau coefficients, and the RBO. The difference is that this block of code masks the values where the input is a non-alphanumeric token (e.g. \".,][?\") before calculating similarities."
      ],
      "metadata": {
        "id": "HYT4iQynt6-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sim_dataframe_alpha(cogs402_ds, all_attentions, all_attributions):\n",
        "\n",
        "  dataframe = []\n",
        "\n",
        "  for i in tqdm(range(len(cogs402_ds))):\n",
        "    exam_attrib = all_attributions[str(i)]\n",
        "    attention_final_layer = all_attentions[str(i)]\n",
        "    \n",
        "    exam_attrib = exam_attrib[:len(all_attentions[str(i)])]\n",
        "\n",
        "    #input_ids\n",
        "    text = cogs402_ds['text'][i]\n",
        "    input_ids, _, sep_id = construct_input_ref_pair(text, ref_token_id, sep_token_id, cls_token_id)\n",
        "    indices = input_ids[0].detach().tolist()\n",
        "    all_tokens_curr = tokenizer.convert_ids_to_tokens(indices)\n",
        "\n",
        "    exam_tokens = all_tokens_curr\n",
        "    alpha_neumeric_nums = [idx for idx, element in enumerate(exam_tokens) if element.isalnum()]\n",
        "    mask = np.ones(attention_final_layer.shape,dtype=bool) \n",
        "    mask[alpha_neumeric_nums] = False\n",
        "\n",
        "    attention_final_layer[mask] = 0\n",
        "    exam_attrib[mask] = 0\n",
        "\n",
        "    #raw attributions\n",
        "    cosine_raw = np.dot(exam_attrib, attention_final_layer) / (norm(exam_attrib)*norm(attention_final_layer))\n",
        "\n",
        "    #normalized attributions\n",
        "    attention_final_layer2 = normalize(attention_final_layer)\n",
        "\n",
        "    exam_attrib2 = np.abs(exam_attrib)\n",
        "    exam_attrib2 = normalize(exam_attrib2)\n",
        "    \n",
        "    cosine = np.dot(exam_attrib2, attention_final_layer2) / (norm(exam_attrib2)*norm(attention_final_layer2))\n",
        "\n",
        "    #sim for attributions and attentions above the median\n",
        "    exam_attrib3 = np.abs(exam_attrib)\n",
        "    exam_attrib3 = normalize(exam_attrib3)\n",
        "    median_exam = np.percentile(exam_attrib3, 50)\n",
        "    exam_attrib3[exam_attrib3 < median_exam] = 0\n",
        "\n",
        "    attention_final_layer3 = np.copy(attention_final_layer)\n",
        "    attention_final_layer3 = normalize(attention_final_layer3)\n",
        "    median_12 = np.percentile(attention_final_layer3, 50)\n",
        "    attention_final_layer3[attention_final_layer3 < median_12] = 0\n",
        "\n",
        "    cosine_med = np.dot(exam_attrib3, attention_final_layer3) / (norm(exam_attrib3)*norm(attention_final_layer3))\n",
        "\n",
        "    #sim for attributions and attentions above the mean\n",
        "    exam_attrib4 = np.abs(exam_attrib)\n",
        "    exam_attrib4 = normalize(exam_attrib4)\n",
        "    mean_exam = np.mean(exam_attrib4)\n",
        "    exam_attrib4[exam_attrib4 < mean_exam] = 0\n",
        "\n",
        "    attention_final_layer4 = np.copy(attention_final_layer)\n",
        "    attention_final_layer4 = normalize(attention_final_layer4)\n",
        "    mean_12 = np.mean(attention_final_layer4)\n",
        "    attention_final_layer4[attention_final_layer4 < mean_12] = 0\n",
        "    \n",
        "    cosine_mean = np.dot(exam_attrib4, attention_final_layer4) / (norm(exam_attrib4)*norm(attention_final_layer4))\n",
        "\n",
        "    #sim using the ranks of the tokens\n",
        "    exam_attrib_rank = np.abs(exam_attrib)\n",
        "    order_attrib = exam_attrib_rank.argsort()\n",
        "    ranks_attrib = order_attrib.argsort()\n",
        "\n",
        "    attention_final_layer_rank = np.copy(attention_final_layer)\n",
        "    order = attention_final_layer_rank.argsort()\n",
        "    ranks = order.argsort()\n",
        "\n",
        "    \n",
        "    cosine_rank = np.dot(ranks_attrib, ranks) / (norm(ranks_attrib)*norm(ranks))\n",
        "\n",
        "    tau, p_value = stats.kendalltau(ranks_attrib, ranks)\n",
        "\n",
        "    rbo_sim = rbo.RankingSimilarity(order_attrib, order).rbo()\n",
        "\n",
        "    d = {'example': i, 'similarity normalized': cosine, 'similarity raw': cosine_raw, 'sim_norm w/ median threshold':cosine_med, 'sim_norm w/ mean threshold':cosine_mean, \"sim w/ ranks\":cosine_rank,\n",
        "        \"kendalltau\": tau, \"rbo\":rbo_sim}\n",
        "    dataframe.append(d)\n",
        "\n",
        "  return pd.DataFrame(dataframe)"
      ],
      "metadata": {
        "id": "sXoj61dc6sQ0"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_alpha = get_sim_dataframe_alpha(cogs402_ds, all_attentions_final, all_attributions)"
      ],
      "metadata": {
        "id": "AC49DcgfH-6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "056a28e5-2bd3-4c89-93d1-d7ca2df03d47"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1070/1070 [03:31<00:00,  5.06it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_alpha2 = get_sim_dataframe_alpha(cogs402_ds, all_attentions_all, all_attributions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0WW-X0dofyb",
        "outputId": "722946fb-359e-4c00-b145-18cb8d230032"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1070/1070 [03:30<00:00,  5.08it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_alpha.mean()"
      ],
      "metadata": {
        "id": "2lNm1B5FJIbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac072c9e-1f4f-44e5-f81b-61fdb8648e27"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "example                         534.500000\n",
              "similarity normalized             0.400218\n",
              "similarity raw                    0.045698\n",
              "sim_norm w/ median threshold      0.382465\n",
              "sim_norm w/ mean threshold        0.353881\n",
              "sim w/ ranks                      0.884370\n",
              "kendalltau                        0.400200\n",
              "rbo                               0.792063\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_alpha2.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4akOqvPZdoa",
        "outputId": "496ffaf0-10b7-457b-e74c-46cf6a463aac"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "example                         534.500000\n",
              "similarity normalized             0.302328\n",
              "similarity raw                   -0.003185\n",
              "sim_norm w/ median threshold      0.280655\n",
              "sim_norm w/ mean threshold        0.257808\n",
              "sim w/ ranks                      0.876614\n",
              "kendalltau                        0.374737\n",
              "rbo                               0.784229\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you wish to find the unscaled version of the attentions, the following block of code gives two dictionaries of unscaled attentions."
      ],
      "metadata": {
        "id": "Wrri3dZoajIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_attentions_final2 = torch.load('/content/drive/MyDrive/cogs402longformer/results/papers/papers_attributions/full_attention_matrices/example_atten_dict_12_unscale.pt')\n",
        "all_attentions_all2 = torch.load('/content/drive/MyDrive/cogs402longformer/results/papers/papers_attributions/full_attention_matrices/example_atten_dict_all_unscale.pt')"
      ],
      "metadata": {
        "id": "4lAQkA7wk27O"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all_attentions_final = {}\n",
        "# all_attentions_all = {}\n",
        "# for i in tqdm(range(len(cogs402_ds))):\n",
        "#   if str(i) not in all_attentions_final and str(i) not in all_attentions_all:\n",
        "\n",
        "#     att_mat = all_attentions[str(i)]\n",
        "\n",
        "#     # Sum the attentions for the last layer and over all layers\n",
        "#     attention_final_layer = att_mat[11].sum(axis=0)\n",
        "#     all_attentions_final[str(i)] = attention_final_layer\n",
        "\n",
        "#     attention_all_layer = att_mat.sum(axis=1)\n",
        "#     attention_all_layer = attention_all_layer.sum(axis=0)\n",
        "#     all_attentions_all[str(i)] = attention_all_layer\n",
        "    \n",
        "#     torch.save(all_attentions_final, '/content/drive/MyDrive/cogs402longformer/results/papers/papers_attributions/full_attention_matrices/example_atten_dict_12_unscale.pt')\n",
        "#     torch.save(all_attentions_all, '/content/drive/MyDrive/cogs402longformer/results/papers/papers_attributions/full_attention_matrices/example_atten_dict_all_unscale.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMpNSHvMZpy0",
        "outputId": "d1297e0b-0634-49f7-ed15-185db4ccfffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1070/1070 [03:07<00:00,  5.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataframe_final_layer = []\n",
        "# dataframe_all_layer = [] "
      ],
      "metadata": {
        "id": "aBFx2y5FgkiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_unscale = get_sim_dataframe(cogs402_ds, all_attentions_final2, all_attributions)\n",
        "df_unscale2 = get_sim_dataframe(cogs402_ds, all_attentions_all2, all_attributions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zzxb8qDXkt-S",
        "outputId": "98c0a97a-94b7-4cbc-edc9-bb9d736762e9"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1070/1070 [00:07<00:00, 138.71it/s]\n",
            "100%|██████████| 1070/1070 [00:07<00:00, 144.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_unscale.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R6CNQz5npSQ",
        "outputId": "d3ea7fb6-65e9-416e-e4e3-e773dca59cb6"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "example                         534.500000\n",
              "similarity normalized             0.105481\n",
              "similarity raw                    0.020551\n",
              "sim_norm w/ median threshold      0.095462\n",
              "sim_norm w/ mean threshold        0.076707\n",
              "sim w/ ranks                      0.777507\n",
              "kendalltau                        0.077260\n",
              "rbo                               0.521135\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_unscale2.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJKEhyEonuNI",
        "outputId": "170d27aa-3cd8-4fc3-9575-0dbf2e036737"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "example                         534.500000\n",
              "similarity normalized             0.059124\n",
              "similarity raw                    0.000046\n",
              "sim_norm w/ median threshold      0.053317\n",
              "sim_norm w/ mean threshold        0.037848\n",
              "sim w/ ranks                      0.776544\n",
              "kendalltau                        0.074032\n",
              "rbo                               0.525490\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_unscale_alpha = get_sim_dataframe_alpha(cogs402_ds, all_attentions_final2, all_attributions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kTlwzd1sve4",
        "outputId": "8041d99a-dc4c-4601-ad40-f0cf3dd6095a"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1070/1070 [03:33<00:00,  5.00it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_unscale_alpha2 = get_sim_dataframe_alpha(cogs402_ds, all_attentions_all2, all_attributions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCqPMGqgs4Cg",
        "outputId": "48e843e0-9531-4c4b-eb58-29949ca24c28"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1070/1070 [03:34<00:00,  4.99it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_unscale_alpha.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAXTz9nkt0xu",
        "outputId": "448efa5a-7f49-4e2e-b308-3a9de7803764"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "example                         534.500000\n",
              "similarity normalized             0.408307\n",
              "similarity raw                    0.024952\n",
              "sim_norm w/ median threshold      0.384152\n",
              "sim_norm w/ mean threshold        0.354161\n",
              "sim w/ ranks                      0.881266\n",
              "kendalltau                        0.390058\n",
              "rbo                               0.789077\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_unscale_alpha2.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYP_JvItt3eL",
        "outputId": "52c06d15-2757-4011-e2b2-afd008530ec7"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "example                         534.500000\n",
              "similarity normalized             0.235386\n",
              "similarity raw                   -0.002723\n",
              "sim_norm w/ median threshold      0.211407\n",
              "sim_norm w/ mean threshold        0.194379\n",
              "sim w/ ranks                      0.876572\n",
              "kendalltau                        0.374509\n",
              "rbo                               0.783674\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 227
        }
      ]
    }
  ],
  "metadata": {
    "file_extension": ".py",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "Attn_attr_cosine_sim_all.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3e5071e9fbf94e2da04281922708573a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0621f7a6149b4b749f73b91030e429ff",
              "IPY_MODEL_bcfe5ea0e5354560aae0c533e111c7fb",
              "IPY_MODEL_e9396bae9c9146708507c0f520369ad9"
            ],
            "layout": "IPY_MODEL_3d80c00c745748fbac8673e901a99d0d"
          }
        },
        "0621f7a6149b4b749f73b91030e429ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a7a47616f3b49948887f523cf085db4",
            "placeholder": "​",
            "style": "IPY_MODEL_4fec74910f7746e28cd391613851017b",
            "value": "100%"
          }
        },
        "bcfe5ea0e5354560aae0c533e111c7fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54c2f6764a6f4a6ba889f08cfd36d22c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9bf109f713f24c98abea3faa1aa4d45f",
            "value": 2
          }
        },
        "e9396bae9c9146708507c0f520369ad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_237add805bee4a07a09151587aef036d",
            "placeholder": "​",
            "style": "IPY_MODEL_724f3939a56a45b78f87acca25c2f390",
            "value": " 2/2 [00:00&lt;00:00,  5.63it/s]"
          }
        },
        "3d80c00c745748fbac8673e901a99d0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a7a47616f3b49948887f523cf085db4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fec74910f7746e28cd391613851017b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54c2f6764a6f4a6ba889f08cfd36d22c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bf109f713f24c98abea3faa1aa4d45f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "237add805bee4a07a09151587aef036d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "724f3939a56a45b78f87acca25c2f390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}