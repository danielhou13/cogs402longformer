{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c6ea87-bfae-4837-a6c8-80aa8158b9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\T3-Vis\\application\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f88515c-c912-4457-9071-8fcebe05aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "835b5de0-8ecd-4715-9662-eb6e250e4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.load(\"resources/pretrained/aggregate_attn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a9a4475-8199-4679-9628-8f293d63bce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "705ee705-11d3-4c28-935d-cd7e60940171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16384\n"
     ]
    }
   ],
   "source": [
    "print(len(test[1]['attn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "963f733d-b40d-4fac-8985-26256889de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_attention(output_attention, n_heads, pruned_heads):\n",
    "    attentions = [(l.squeeze(0) * 100).round().byte().cpu() for l in output_attention]\n",
    "    attn_vectors = []\n",
    "    for layer in range(len(attentions)):\n",
    "        attn_vectors.append([])\n",
    "        next_head_idx = 0\n",
    "        for head in range(n_heads):\n",
    "            if (layer in pruned_heads.keys()) and (head in pruned_heads[layer]):\n",
    "                attn_vectors[layer].append([])\n",
    "            else:\n",
    "                attn_vectors[layer].append(attentions[layer][next_head_idx].tolist())\n",
    "                next_head_idx += 1\n",
    "    return attn_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4935c525-ae8e-4a50-8fe6-41caee31712b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16384,)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(test[1]['attn']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b76ccdae-bfca-4db0-a850-b6b33359f214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "def longformer_finetuned_papers():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained('danielhou13/longformer-finetuned_papers', num_labels = 2)\n",
    "    return model\n",
    "def preprocess_function(tokenizer, example, max_length):\n",
    "    example.update(tokenizer(example['text'], padding='max_length', max_length=max_length, truncation=True))\n",
    "    return example\n",
    "\n",
    "def get_papers_dataset(dataset_type):\n",
    "    max_length = 2048\n",
    "    dataset = load_dataset(\"danielhou13/cogs402dataset\")[dataset_type]\n",
    "    new_col = list(np.arange(0, len(dataset)))\n",
    "    dataset = dataset.add_column(\"idx\", new_col)\n",
    "    visualize_columns = dataset.column_names\n",
    "    visualize_columns = ['idx', 'text', 'labels']\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "    dataset = dataset.map(lambda x: preprocess_function(tokenizer, x, max_length), batched=True)\n",
    "    setattr(dataset, 'visualize_columns', visualize_columns)\n",
    "    setattr(dataset, 'input_columns', ['input_ids', 'attention_mask'])\n",
    "    setattr(dataset, 'target_columns', ['labels'])\n",
    "    setattr(dataset, 'max_length', max_length)\n",
    "    setattr(dataset, 'tokenizer', tokenizer)\n",
    "    return dataset\n",
    "\n",
    "def papers_test_set():\n",
    "    return get_papers_dataset('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a11646f8-70c1-425a-bbed-a27e85980dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration danielhou13--cogs402dataset-5c7aa10e6c95142f\n",
      "Reusing dataset parquet (C:\\Users\\danie\\.cache\\huggingface\\datasets\\parquet\\danielhou13--cogs402dataset-5c7aa10e6c95142f\\0.0.0\\0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655e1d6aa9754829b1f77d6d41cc5599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\danie\\.cache\\huggingface\\datasets\\parquet\\danielhou13--cogs402dataset-5c7aa10e6c95142f\\0.0.0\\0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901\\cache-cb5d1ef3ec235523.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_ids', 'attention_mask', 'labels']\n"
     ]
    }
   ],
   "source": [
    "cogs402_test = papers_test_set()\n",
    "model = longformer_finetuned_papers()\n",
    "columns = cogs402_test.input_columns + cogs402_test.target_columns\n",
    "print(columns)\n",
    "cogs402_test.set_format(type='torch', columns=columns + ['idx'])\n",
    "cogs402_test=cogs402_test.remove_columns(['text', 'idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef96f6c5-de30-41d7-984c-b78acc3c21e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d36141de-5ab0-4873-9aaf-cca07763ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(cogs402_test[\"input_ids\"][923].unsqueeze(0).cuda(), attention_mask=cogs402_test['attention_mask'][923].unsqueeze(0).cuda(), labels=cogs402_test['labels'][923].cuda(), output_attentions=True)\n",
    "batch_attn = output[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36bdb364-44b3-4386-8754-9c69cd072971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_head_matrix(output_attentions, global_attentions):\n",
    "    new_attention_matrix = torch.zeros((output_attentions.shape[0], \n",
    "                                        output_attentions.shape[0]))\n",
    "    for i in range(output_attentions.shape[0]):\n",
    "        test_non_zeroes = torch.nonzero(output_attentions[i]).squeeze()\n",
    "        if test_non_zeroes.shape[0]>0:\n",
    "            test2 = output_attentions[i][test_non_zeroes[1:]]\n",
    "            new_attention_matrix_indices = test_non_zeroes[1:]-257 + i\n",
    "            new_attention_matrix[i][new_attention_matrix_indices] = test2\n",
    "            new_attention_matrix[i][0] = output_attentions[i][0]\n",
    "        new_attention_matrix[0] = global_attentions.squeeze()[:output_attentions.shape[0]]\n",
    "    return new_attention_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9febc69-57ed-4e18-b3ab-189874322dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def format_attention(output_attention, global_attention, n_heads, pruned_heads):\n",
    "    attentions = [(l.squeeze(0) * 100).cpu() for l in output_attention]\n",
    "    global_attention = torch.stack(global_attention).squeeze().cpu()\n",
    "    attn_vectors = []\n",
    "    for layer in tqdm(range(len(attentions))):\n",
    "        attn_vectors.append([])\n",
    "        for head in range(n_heads):\n",
    "            if (layer in pruned_heads.keys()) and (head in pruned_heads[layer]):\n",
    "                attn_vectors[layer].append([])\n",
    "            else:\n",
    "                matrix = torch.Tensor(attentions[layer][head]).float()\n",
    "                new_matrix = create_head_matrix(matrix, global_attention[layer][head])\n",
    "                attn_vectors[layer].append(new_matrix.tolist())\n",
    "    return attn_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbe3efae-f5dc-4b66-a308-5fa4de69b79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [01:35<00:00,  7.96s/it]\n"
     ]
    }
   ],
   "source": [
    "test = format_attention(output['attentions'], output['global_attentions'], model.config.num_attention_heads, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8381bc42-082f-4d52-ad00-2828e91bc78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a61149f-46aa-4756-9477-258770df3319",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97084336-706f-4dfc-b138-c6f402b81b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 12, 2048, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8559f434-77ad-45c3-88ea-7b24bafed963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogs402",
   "language": "python",
   "name": "cogs402"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
