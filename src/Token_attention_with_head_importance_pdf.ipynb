{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielhou13/cogs402longformer/blob/main/src/Token_attention_with_head_importance_pdf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is primarily the same as the section on converting to a PDF in [Token_attention_with_head_importance](https://colab.research.google.com/drive/1iVojJQp0CZS484tMZqIizosXPLxgKvRX?usp=sharing); however, this notebook solely focuses on converting the attentions into a PDF visualization. This notebook also predicts over the dataset and finds interesting examples to visualize such as false negatives, false postiives, and very confident predictions."
      ],
      "metadata": {
        "id": "t8OGqf7Pl7-h"
      },
      "id": "t8OGqf7Pl7-h"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZTPlUo8Wp1T",
        "outputId": "904bcd52-bec1-4d96-bb25-ea7820c62642"
      },
      "id": "kZTPlUo8Wp1T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys\n",
        "# sys.path.append('/content/drive/My Drive/{}'.format(\"cogs402longformer/\"))"
      ],
      "metadata": {
        "id": "AlcBiC0nWtJE"
      },
      "id": "AlcBiC0nWtJE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets --quiet"
      ],
      "metadata": {
        "id": "s_6vceLhTIBf"
      },
      "id": "s_6vceLhTIBf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-qXH2JkTMdA",
        "outputId": "7b4ad985-b4df-4149-ae91-2c2172eca3c2"
      },
      "id": "M-qXH2JkTMdA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Dataset and Model"
      ],
      "metadata": {
        "id": "hSSPoSRn6r9A"
      },
      "id": "hSSPoSRn6r9A"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b774ad0-b725-4910-9050-423edf160ebd",
      "metadata": {
        "id": "9b774ad0-b725-4910-9050-423edf160ebd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the Reserach Papers dataset"
      ],
      "metadata": {
        "id": "hfHRqrpw_VlN"
      },
      "id": "hfHRqrpw_VlN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66cc97f5-7e3a-476c-9858-5643eeaa6675",
      "metadata": {
        "id": "66cc97f5-7e3a-476c-9858-5643eeaa6675"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "model_path = 'danielhou13/longformer-finetuned_papers_v2'\n",
        "model_path2 = 'danielhou13/longformer-finetuned-news-cogs402'\n",
        "model_path3 = 'allenai/longformer-base-4096'\n",
        "\n",
        "# def longformer_finetuned_papers(model):\n",
        "#     model = AutoModelForSequenceClassification.from_pretrained(model, num_labels = 2)\n",
        "#     return model\n",
        "\n",
        "# def preprocess_function(tokenizer, example, max_length):\n",
        "#     example.update(tokenizer(example['text'], padding='max_length', max_length=max_length, truncation=True))\n",
        "#     return example\n",
        "\n",
        "# def get_papers_dataset(dataset_type):\n",
        "#     max_length = 2048\n",
        "#     dataset = load_dataset(\"danielhou13/cogs402dataset\")[dataset_type]\n",
        "\n",
        "#     # tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "#     dataset = dataset.map(lambda x: preprocess_function(tokenizer, x, max_length), batched=True)\n",
        "#     setattr(dataset, 'input_columns', ['input_ids', 'attention_mask'])\n",
        "#     setattr(dataset, 'target_columns', ['labels'])\n",
        "#     setattr(dataset, 'max_length', max_length)\n",
        "#     setattr(dataset, 'tokenizer', tokenizer)\n",
        "#     return dataset\n",
        "\n",
        "# def papers_test_set():\n",
        "#     return get_papers_dataset('test')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the news dataset"
      ],
      "metadata": {
        "id": "Jq_wt-jn_Y6m"
      },
      "id": "Jq_wt-jn_Y6m"
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(tokenizer, example, max_length):\n",
        "    example.update(tokenizer(example['text'], padding='max_length', max_length=max_length, truncation=True))\n",
        "    return example\n",
        "\n",
        "def longformer_finetuned_news(model):\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model, num_labels = 2)\n",
        "    return model\n",
        "\n",
        "def get_news_dataset(dataset_type):\n",
        "    max_length = 2048\n",
        "    dataset = load_dataset(\"danielhou13/cogs402dataset2\")[dataset_type]\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "    dataset = dataset.map(lambda x: preprocess_function(tokenizer, x, max_length), batched=True)\n",
        "\n",
        "    labels = map(int, dataset['hyperpartisan'])\n",
        "    print(type(dataset['hyperpartisan']))\n",
        "    labels = list(labels)\n",
        "    dataset = dataset.add_column(\"labels\", labels)\n",
        "\n",
        "    dataset = dataset.remove_columns(['title', 'hyperpartisan', 'url', 'published_at', 'bias'])\n",
        "    print(dataset)\n",
        "    setattr(dataset, 'input_columns', ['input_ids', 'attention_mask'])\n",
        "    setattr(dataset, 'target_columns', ['labels'])\n",
        "    setattr(dataset, 'max_length', max_length)\n",
        "    setattr(dataset, 'tokenizer', tokenizer)\n",
        "    return dataset\n",
        "\n",
        "def news_train_set():\n",
        "    return get_news_dataset('train')\n",
        "\n",
        "def news_test_set():\n",
        "    return get_news_dataset('validation')"
      ],
      "metadata": {
        "id": "gEI0AFC5-0qA"
      },
      "id": "gEI0AFC5-0qA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load papers model and dataset and preprocess it"
      ],
      "metadata": {
        "id": "srzj_2BeNGOK"
      },
      "id": "srzj_2BeNGOK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24ad54a3-db97-47e3-8cc7-417d4db2c99b",
      "metadata": {
        "id": "24ad54a3-db97-47e3-8cc7-417d4db2c99b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "a6dce85e86b34a1780bf12086a1ee4f9",
            "44dcfd955cdd45fcb5f7143779d1455f",
            "5c28fd290d03480a934176063125314f",
            "726230bdeb7142ce94443bafb3ba2452",
            "b6cffa51ee3a4a44810c10aed886f137",
            "fc200b4e97624419b5e759ff622c07c1",
            "dbf09edc15ba40848cad18aeb039b5c8",
            "4fd43b7d420d4f028668e525c13aa9e6",
            "8397069bae4947538a712460572c9bbe",
            "67ac7a637cff452b81c183f94eebed0e",
            "7859f9b15b094519ac10d52136192331",
            "839ef042ccef4a2bacdbbe55b67fc786",
            "806700da0ca246d0a9c50b7595e12d04",
            "ea975d9e3d944bdaaa746b618ff67b16",
            "44a71759146d4ccd8e7bef5ca205e0cd",
            "1d635fabe4f242b181df2f3dc1204d09",
            "8be3b02bb62e41fba48bb2f4f6c380e6",
            "c3f3f6d559b44f1ca116b267543e0811",
            "268e0ec0747b4db7ab878063236f5931",
            "d8f91fbb1bea4016ab5fe5732793a997",
            "0837887b910c433fa680aa969bac9cf4",
            "91b2bfc04e32401aadc7f29311cf295a"
          ]
        },
        "outputId": "90edf8ba-ad5d-4c13-b184-36b61ca1a2f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration danielhou13--cogs402dataset2-52067477e0d49a06\n",
            "Reusing dataset parquet (/root/.cache/huggingface/datasets/danielhou13___parquet/danielhou13--cogs402dataset2-52067477e0d49a06/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6dce85e86b34a1780bf12086a1ee4f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Parameter 'function'=<function get_news_dataset.<locals>.<lambda> at 0x7ff0d7b1f560> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "839ef042ccef4a2bacdbbe55b67fc786"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "Dataset({\n",
            "    features: ['text', 'input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 2500\n",
            "})\n",
            "['input_ids', 'attention_mask', 'labels']\n"
          ]
        }
      ],
      "source": [
        "cogs402_test = news_test_set()\n",
        "model = longformer_finetuned_news(model_path)\n",
        "columns = cogs402_test.input_columns + cogs402_test.target_columns\n",
        "print(columns)\n",
        "cogs402_test.set_format(type='torch', columns=columns)\n",
        "cogs402_test=cogs402_test.remove_columns(['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load news model and dataset and preprocess it"
      ],
      "metadata": {
        "id": "22BIYrX8NOVC"
      },
      "id": "22BIYrX8NOVC"
    },
    {
      "cell_type": "code",
      "source": [
        "# cogs402_test = news_test_set()\n",
        "# model = longformer_finetuned_news()\n",
        "# columns = cogs402_test.input_columns + cogs402_test.target_columns\n",
        "# print(columns)\n",
        "# cogs402_test.set_format(type='torch', columns=columns)"
      ],
      "metadata": {
        "id": "xh-YZZyo_eZx"
      },
      "id": "xh-YZZyo_eZx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deaabfa2-0855-41fd-870c-7a8b91e32d44",
      "metadata": {
        "id": "deaabfa2-0855-41fd-870c-7a8b91e32d44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f067744-3e7f-4281-c955-ddc69fd13e50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "print(model.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict using the model on the selected dataset"
      ],
      "metadata": {
        "id": "IXjbkX-PAGay"
      },
      "id": "IXjbkX-PAGay"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "batch_size = 1\n",
        "gradient_acc = 4\n",
        "model_name = f\"longformer-finetuned_papers\"\n",
        "training_args = TrainingArguments(output_dir=f\"models/{model_name}\",\n",
        "                                  num_train_epochs = 2,\n",
        "                                  learning_rate=2e-5,\n",
        "                                  per_device_train_batch_size=batch_size,\n",
        "                                  per_device_eval_batch_size=batch_size,\n",
        "                                  weight_decay=0.01,\n",
        "                                  evaluation_strategy=\"epoch\",\n",
        "                                  disable_tqdm=False,\n",
        "                                  push_to_hub=False,\n",
        "                                  log_level=\"error\",\n",
        "                                  fp16=True,\n",
        "                                  gradient_accumulation_steps=gradient_acc,\n",
        "                                  gradient_checkpointing=True,\n",
        "                                  save_strategy = \"epoch\")"
      ],
      "metadata": {
        "id": "7PUTFonI_XLM"
      },
      "id": "7PUTFonI_XLM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1 and accuracy are good general metrics for model performance. Recall and precision can be used if we require low false negatives or false positives."
      ],
      "metadata": {
        "id": "NSxE_HDPAKaT"
      },
      "id": "NSxE_HDPAKaT"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"f1\": f1}"
      ],
      "metadata": {
        "id": "65V97tOz_e37"
      },
      "id": "65V97tOz_e37",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator = data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "TpkwUmWN_lu1"
      },
      "id": "TpkwUmWN_lu1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_output = trainer.predict(cogs402_test)"
      ],
      "metadata": {
        "id": "4W9kCODH_wfT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "e661a74d-dd2f-49a9-ca50-67eb76649e3f"
      },
      "id": "4W9kCODH_wfT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 06:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "False negatives and False postives are usually very interesting examples."
      ],
      "metadata": {
        "id": "wjeyImJmApjd"
      },
      "id": "wjeyImJmApjd"
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = np.argmax(preds_output.predictions, axis=1)\n",
        "y_true = np.array(cogs402_test[\"labels\"])"
      ],
      "metadata": {
        "id": "IyRQ0z-QAzAU"
      },
      "id": "IyRQ0z-QAzAU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diff = y_true-y_preds\n",
        "correct = np.where(diff == 0)[0]\n",
        "\n",
        "pos = np.where((y_true-y_preds == 0) & (y_true==1))[0]\n",
        "neg = np.where((y_true-y_preds == 0) & (y_true==0))[0]\n",
        "\n",
        "false_pos = np.where(diff == -1)[0]\n",
        "false_neg = np.where(diff == 1)[0]\n",
        "\n",
        "print('Correctly classified: ', correct)\n",
        "\n",
        "print('cor pos: ', pos)\n",
        "print('cor neg: ', neg)\n",
        "\n",
        "print('False positives: ', false_pos)\n",
        "print('False negatives: ', false_neg)"
      ],
      "metadata": {
        "id": "ZoIa9_KIA2rt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "958d74f1-14b5-42f3-8ed5-ec44f09576b9"
      },
      "id": "ZoIa9_KIA2rt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correctly classified:  [   0    1    3 ... 2494 2496 2498]\n",
            "cor pos:  [   0    1    3 ... 2494 2496 2498]\n",
            "cor neg:  [ 136  373  376  440  520  700  710  792 1060 1181 1577 1608 1674 1837\n",
            " 2089 2099 2127 2160 2170 2233 2449]\n",
            "False positives:  [   2    4    6 ... 2495 2497 2499]\n",
            "False negatives:  [  32  561  762 1093 1283]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take example for evaluation based on randomness"
      ],
      "metadata": {
        "id": "d4DdhW2T6wHE"
      },
      "id": "d4DdhW2T6wHE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a35e74a3-bd67-4ee2-8e5b-2da01503f27b",
      "metadata": {
        "id": "a35e74a3-bd67-4ee2-8e5b-2da01503f27b"
      },
      "outputs": [],
      "source": [
        "rand_pos = np.random.choice(pos, size=1)\n",
        "rand_neg = np.random.choice(neg, size=1)\n",
        "rand_fp = np.random.choice(false_pos, size=1)\n",
        "rand_fn = np.random.choice(false_neg, size=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(tokenizer.convert_ids_to_tokens(cogs402_test[\"input_ids\"][rand_neg[0]]))"
      ],
      "metadata": {
        "id": "f2TDMpA1nqk_"
      },
      "id": "f2TDMpA1nqk_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some other interesting examples include the examples that are the most confidently predicted to be positive or negative. I.e. the examples with the highest predicted probability."
      ],
      "metadata": {
        "id": "kyVEhUfidwRV"
      },
      "id": "kyVEhUfidwRV"
    },
    {
      "cell_type": "code",
      "source": [
        "highest_pos = [np.argmax(preds_output.predictions[:,1])]\n",
        "# highest_neg = [np.argmax(preds_output.predictions[:,0])]\n",
        "highest_neg = [np.argmax(np.delete(preds_output.predictions, 1933, 0)[:,0])]\n",
        "print(highest_pos)\n",
        "print(highest_neg)"
      ],
      "metadata": {
        "id": "6WWpe52Cd3wk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aacf7f3-6cc9-4a47-bb1a-68344308116b"
      },
      "id": "6WWpe52Cd3wk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[672]\n",
            "[1577]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_val = highest_pos\n",
        "print(test_val)\n",
        "testexam = cogs402_test[test_val]"
      ],
      "metadata": {
        "id": "FrX3LUUxeORB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3478b61f-6b0a-4979-9258-4499e140b14a"
      },
      "id": "FrX3LUUxeORB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[672]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04c5bcaf-5fe3-4813-8444-5cfb2c63a92b",
      "metadata": {
        "id": "04c5bcaf-5fe3-4813-8444-5cfb2c63a92b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eac51e00-dcbd-456b-eac5-86a6d867e682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output_attention.shape torch.Size([12, 1, 12, 2048, 514])\n",
            "gl_output_attention.shape torch.Size([12, 1, 12, 2048, 1])\n"
          ]
        }
      ],
      "source": [
        "output = model(testexam[\"input_ids\"].cuda(), attention_mask=testexam['attention_mask'].cuda(), labels=testexam['labels'].cuda(), output_attentions = True)\n",
        "batch_attn = output[-2]\n",
        "output_attentions = torch.stack(batch_attn).cpu()\n",
        "global_attention = output[-1]\n",
        "output_global_attentions = torch.stack(global_attention).cpu()\n",
        "print(\"output_attention.shape\", output_attentions.shape)\n",
        "print(\"gl_output_attention.shape\", output_global_attentions.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(testexam['labels'][0])\n",
        "print(output[1].argmax())"
      ],
      "metadata": {
        "id": "SO4yNy98t_UP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49bf0790-3ec2-4ac0-f5f7-7b7ef3f62f4d"
      },
      "id": "SO4yNy98t_UP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0)\n",
            "tensor(1, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2467c3d1-fe58-4e6d-aa98-534a6df72fcc",
      "metadata": {
        "id": "2467c3d1-fe58-4e6d-aa98-534a6df72fcc"
      },
      "outputs": [],
      "source": [
        "# print(os.getcwd())\n",
        "# yes = torch.load(\"resources/longformer_test2/epoch_3/aggregate_attn.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert sliding attention matrix to correct seq_len x seq_len matrix"
      ],
      "metadata": {
        "id": "OevnNprR67LK"
      },
      "id": "OevnNprR67LK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0882a3e5-1b0c-4319-92a3-92f5b516d854",
      "metadata": {
        "id": "0882a3e5-1b0c-4319-92a3-92f5b516d854"
      },
      "outputs": [],
      "source": [
        "def create_head_matrix(output_attentions, global_attentions):\n",
        "    new_attention_matrix = torch.zeros((output_attentions.shape[0], \n",
        "                                      output_attentions.shape[0]))\n",
        "    for i in range(output_attentions.shape[0]):\n",
        "        test_non_zeroes = torch.nonzero(output_attentions[i]).squeeze()\n",
        "        test2 = output_attentions[i][test_non_zeroes[1:]]\n",
        "        new_attention_matrix_indices = test_non_zeroes[1:]-257 + i\n",
        "        new_attention_matrix[i][new_attention_matrix_indices] = test2\n",
        "        new_attention_matrix[i][0] = output_attentions[i][0]\n",
        "        new_attention_matrix[0] = global_attentions.squeeze()[:output_attentions.shape[0]]\n",
        "    return new_attention_matrix\n",
        "\n",
        "\n",
        "def attentions_all_heads(output_attentions, global_attentions):\n",
        "    new_matrix = []\n",
        "    for i in range(output_attentions.shape[0]):\n",
        "        matrix = create_head_matrix(output_attentions[i], global_attentions[i])\n",
        "        new_matrix.append(matrix)\n",
        "    return torch.stack(new_matrix)\n",
        "\n",
        "def all_batches(output_attentions, global_attentions):\n",
        "    new_matrix = []\n",
        "    for i in range(output_attentions.shape[0]):\n",
        "        matrix = attentions_all_heads(output_attentions[i], global_attentions[i])\n",
        "        new_matrix.append(matrix)\n",
        "    return torch.stack(new_matrix)\n",
        "\n",
        "def all_layers(output_attentions, global_attentions):\n",
        "    new_matrix = []\n",
        "    for i in range(output_attentions.shape[0]):\n",
        "        matrix = all_batches(output_attentions[i], global_attentions[i])\n",
        "        new_matrix.append(matrix)\n",
        "    return torch.stack(new_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converted_mat = all_layers(output_attentions, output_global_attentions).detach().cpu().numpy()\n",
        "print(converted_mat.shape)"
      ],
      "metadata": {
        "id": "IpdfMEMAuvyR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a2ca92-ec78-4e49-b4b0-29ef2f7ac293"
      },
      "id": "IpdfMEMAuvyR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12, 1, 12, 2048, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(testexam['input_ids'])"
      ],
      "metadata": {
        "id": "SIwlL_rUIlO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62907442-82ff-48f6-f52e-90598676788e"
      },
      "id": "SIwlL_rUIlO3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0, 41552,   642,  ...,     1,     1,     1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = tokenizer.convert_ids_to_tokens(testexam[\"input_ids\"][0])"
      ],
      "metadata": {
        "id": "N-Wr_p4LsTv-"
      },
      "id": "N-Wr_p4LsTv-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load head importance model and scale the attentions by head importance"
      ],
      "metadata": {
        "id": "P-nS_AHa7Hv6"
      },
      "id": "P-nS_AHa7Hv6"
    },
    {
      "cell_type": "code",
      "source": [
        "# head_importance = torch.load(\"/content/drive/MyDrive/cogs402longformer/t3-visapplication/resources/papers/pretrained/head_importance.pt\")\n",
        "head_importance = torch.load(\"/content/drive/MyDrive/cogs402longformer/t3-visapplication/resources/news/head_importance.pt\")"
      ],
      "metadata": {
        "id": "UsAznmcDyBgR"
      },
      "id": "UsAznmcDyBgR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_by_importance(attention_matrix, head_importance):\n",
        "  new_matrix = np.zeros_like(attention_matrix)\n",
        "  for i in range(attention_matrix.shape[0]):\n",
        "    head_importance_layer = head_importance[i]\n",
        "    for j in range(attention_matrix.shape[1]):\n",
        "      new_matrix[i,j] = attention_matrix[i,j] * np.expand_dims(head_importance_layer, axis=(1,2))\n",
        "  return new_matrix"
      ],
      "metadata": {
        "id": "_HFs_vLw0230"
      },
      "id": "_HFs_vLw0230",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converted_mat_importance = scale_by_importance(converted_mat, head_importance)"
      ],
      "metadata": {
        "id": "XUcjPfxeHbqT"
      },
      "id": "XUcjPfxeHbqT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the sum of the attentions for all the tokens (column-wise). In other words, find out how much every word is attended to"
      ],
      "metadata": {
        "id": "u0ViKJAn7Ap0"
      },
      "id": "u0ViKJAn7Ap0"
    },
    {
      "cell_type": "code",
      "source": [
        "attention_matrix_importance = converted_mat_importance.sum(axis=3)\n",
        "print(attention_matrix_importance.shape)"
      ],
      "metadata": {
        "id": "EhMNdupbxFrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b33d86e1-cce3-48db-ecef-704e2554ec17"
      },
      "id": "EhMNdupbxFrx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12, 1, 12, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A dataframe is good for picking out information from the example, but it isn't the best being a easy to read visualization. Its easier to see how much each word is attended to in an example if we have the actual example, with the words highlighted based on the magnitude of attention.\n",
        "\n",
        "We use https://github.com/jiesutd/Text-Attention-Heatmap-Visualization to show how much each token in the example is attended to, up to the max number of tokens we specified earlier."
      ],
      "metadata": {
        "id": "DjTu0_guLI1T"
      },
      "id": "DjTu0_guLI1T"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get top k attended words for each head, for each example in batch, for each layer"
      ],
      "metadata": {
        "id": "cc0pgucS7OIp"
      },
      "id": "cc0pgucS7OIp"
    },
    {
      "cell_type": "code",
      "source": [
        "## convert the text/attention list to latex code, which will further generates the text heatmap based on attention weights.\n",
        "import numpy as np\n",
        "\n",
        "latex_special_token = [\"!@#$%^&*(){}\"]\n",
        "\n",
        "def generate(text_list, attention_list, latex_file, color='red', rescale_value = False):\n",
        "\tassert(len(text_list) == len(attention_list))\n",
        "\tif rescale_value:\n",
        "\t\tattention_list = rescale(attention_list)\n",
        "\tword_num = len(text_list)\n",
        "\ttext_list = clean_word(text_list)\n",
        "\twith open(latex_file,'w') as f:\n",
        "\t\tf.write(r'''\\documentclass[varwidth]{standalone}\n",
        "\\special{papersize=210mm,297mm}\n",
        "\\usepackage{color}\n",
        "\\usepackage{tcolorbox}\n",
        "\\usepackage{CJK}\n",
        "\\usepackage{adjustbox}\n",
        "\\tcbset{width=0.9\\textwidth,boxrule=0pt,colback=red,arc=0pt,auto outer arc,left=0pt,right=0pt,boxsep=5pt}\n",
        "\\begin{document}\n",
        "\\begin{CJK*}{UTF8}{gbsn}'''+'\\n')\n",
        "\t\tstring = r'''{\\setlength{\\fboxsep}{0pt}\\colorbox{white!0}{\\parbox{0.9\\textwidth}{'''+\"\\n\"\n",
        "\t\tfor idx in range(word_num):\n",
        "\t\t\tstring += \"\\\\colorbox{%s!%s}{\"%(color, attention_list[idx])+\"\\\\strut \" + text_list[idx]+\"} \"\n",
        "\t\tstring += \"\\n}}}\"\n",
        "\t\tf.write(string+'\\n')\n",
        "\t\tf.write(r'''\\end{CJK*}\n",
        "\\end{document}''')\n",
        "\n",
        "def rescale(input_list):\n",
        "\tthe_array = np.asarray(input_list)\n",
        "\tthe_max = np.max(the_array)\n",
        "\tthe_min = np.min(the_array)\n",
        "\trescale = (the_array - the_min)/(the_max-the_min)*100\n",
        "\treturn rescale.tolist()\n",
        "\n",
        "\n",
        "def clean_word(word_list):\n",
        "\tnew_word_list = []\n",
        "\tfor word in word_list:\n",
        "\t\tfor latex_sensitive in [\"\\\\\", \"%\", \"&\", \"^\", \"#\", \"_\",  \"{\", \"}\"]:\n",
        "\t\t\tif latex_sensitive in word:\n",
        "\t\t\t\tword = word.replace(latex_sensitive, '\\\\'+latex_sensitive)\n",
        "\t\tnew_word_list.append(word)\n",
        "\treturn new_word_list"
      ],
      "metadata": {
        "id": "FCsAm5i3jmKA"
      },
      "id": "FCsAm5i3jmKA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(data):\n",
        "    return (data - np.min(data)) / (np.max(data) - np.min(data))"
      ],
      "metadata": {
        "id": "FV8g7ChBrJPs"
      },
      "id": "FV8g7ChBrJPs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_attention = attention_matrix_importance.squeeze().sum(axis=1)\n",
        "average_attention = average_attention.sum(axis=0)\n",
        "average_attention = normalize(average_attention)\n",
        "print(average_attention * 100)"
      ],
      "metadata": {
        "id": "goaO9arYjopz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb7048f9-2347-43f3-ac59-ff13bef76a31"
      },
      "id": "goaO9arYjopz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100.          1.005807    1.0239174 ...   0.          0.\n",
            "   0.       ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title_all = f\"news_{test_val[0]}_base.tex\"\n",
        "generate(all_tokens, (average_attention*100), title_all, 'red')"
      ],
      "metadata": {
        "id": "htPtu7kErWfN"
      },
      "id": "htPtu7kErWfN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding up all the heads isn't probably the best way of finding out the important tokens of the example because the last layer is what drives the prediction. This part focuses on only the last layer's attention for visualization."
      ],
      "metadata": {
        "id": "TCKn9M3ILsEh"
      },
      "id": "TCKn9M3ILsEh"
    },
    {
      "cell_type": "code",
      "source": [
        "print(attention_matrix_importance[11].squeeze().shape)\n",
        "average_attention_final_layer = attention_matrix_importance[11].squeeze().sum(axis=0)\n",
        "average_attention_final_layer = normalize(average_attention_final_layer)\n",
        "print(average_attention_final_layer*100)"
      ],
      "metadata": {
        "id": "GaM018NVunZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea9b868d-0669-442c-cdab-e4dc4721973b"
      },
      "id": "GaM018NVunZH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12, 2048)\n",
            "[2.30078    0.46655098 0.27441218 ... 0.         0.         0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title_last_layer = f\"news_{test_val[0]}_base_layer_12_only.tex\"\n",
        "generate(all_tokens, (average_attention_final_layer*100), title_last_layer, 'red')"
      ],
      "metadata": {
        "id": "fSl21NvVyW-n"
      },
      "id": "fSl21NvVyW-n",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "Token_attention_with_head_importance_pdf.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a6dce85e86b34a1780bf12086a1ee4f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44dcfd955cdd45fcb5f7143779d1455f",
              "IPY_MODEL_5c28fd290d03480a934176063125314f",
              "IPY_MODEL_726230bdeb7142ce94443bafb3ba2452"
            ],
            "layout": "IPY_MODEL_b6cffa51ee3a4a44810c10aed886f137"
          }
        },
        "44dcfd955cdd45fcb5f7143779d1455f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc200b4e97624419b5e759ff622c07c1",
            "placeholder": "​",
            "style": "IPY_MODEL_dbf09edc15ba40848cad18aeb039b5c8",
            "value": "100%"
          }
        },
        "5c28fd290d03480a934176063125314f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fd43b7d420d4f028668e525c13aa9e6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8397069bae4947538a712460572c9bbe",
            "value": 2
          }
        },
        "726230bdeb7142ce94443bafb3ba2452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67ac7a637cff452b81c183f94eebed0e",
            "placeholder": "​",
            "style": "IPY_MODEL_7859f9b15b094519ac10d52136192331",
            "value": " 2/2 [00:00&lt;00:00, 22.49it/s]"
          }
        },
        "b6cffa51ee3a4a44810c10aed886f137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc200b4e97624419b5e759ff622c07c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbf09edc15ba40848cad18aeb039b5c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fd43b7d420d4f028668e525c13aa9e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8397069bae4947538a712460572c9bbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67ac7a637cff452b81c183f94eebed0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7859f9b15b094519ac10d52136192331": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "839ef042ccef4a2bacdbbe55b67fc786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_806700da0ca246d0a9c50b7595e12d04",
              "IPY_MODEL_ea975d9e3d944bdaaa746b618ff67b16",
              "IPY_MODEL_44a71759146d4ccd8e7bef5ca205e0cd"
            ],
            "layout": "IPY_MODEL_1d635fabe4f242b181df2f3dc1204d09"
          }
        },
        "806700da0ca246d0a9c50b7595e12d04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8be3b02bb62e41fba48bb2f4f6c380e6",
            "placeholder": "​",
            "style": "IPY_MODEL_c3f3f6d559b44f1ca116b267543e0811",
            "value": "100%"
          }
        },
        "ea975d9e3d944bdaaa746b618ff67b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_268e0ec0747b4db7ab878063236f5931",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8f91fbb1bea4016ab5fe5732793a997",
            "value": 3
          }
        },
        "44a71759146d4ccd8e7bef5ca205e0cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0837887b910c433fa680aa969bac9cf4",
            "placeholder": "​",
            "style": "IPY_MODEL_91b2bfc04e32401aadc7f29311cf295a",
            "value": " 3/3 [00:06&lt;00:00,  2.16s/ba]"
          }
        },
        "1d635fabe4f242b181df2f3dc1204d09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8be3b02bb62e41fba48bb2f4f6c380e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3f3f6d559b44f1ca116b267543e0811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "268e0ec0747b4db7ab878063236f5931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8f91fbb1bea4016ab5fe5732793a997": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0837887b910c433fa680aa969bac9cf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91b2bfc04e32401aadc7f29311cf295a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}