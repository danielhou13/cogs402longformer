{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielhou13/cogs402longformer/blob/main/src/Token_attention_with_head_importance_pdf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is primarily the same as the section on converting to a PDF in [Token_attention_with_head_importance](https://colab.research.google.com/drive/1iVojJQp0CZS484tMZqIizosXPLxgKvRX?usp=sharing); however, this notebook solely focuses on converting the attentions into a PDF visualization. This notebook also predicts over the dataset and finds interesting examples to visualize such as false negatives, false postiives, and very confident predictions."
      ],
      "metadata": {
        "id": "t8OGqf7Pl7-h"
      },
      "id": "t8OGqf7Pl7-h"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZTPlUo8Wp1T",
        "outputId": "6c31176e-81ff-4755-f314-19031684e112"
      },
      "id": "kZTPlUo8Wp1T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install and Import Dependencies"
      ],
      "metadata": {
        "id": "XFt7t0wAERQV"
      },
      "id": "XFt7t0wAERQV"
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys\n",
        "# sys.path.append('/content/drive/My Drive/{}'.format(\"cogs402longformer/\"))"
      ],
      "metadata": {
        "id": "AlcBiC0nWtJE"
      },
      "id": "AlcBiC0nWtJE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets --quiet"
      ],
      "metadata": {
        "id": "s_6vceLhTIBf"
      },
      "id": "s_6vceLhTIBf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-qXH2JkTMdA",
        "outputId": "74fcbfe7-93b5-45d7-d868-fe44e1411230"
      },
      "id": "M-qXH2JkTMdA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import Dataset and Model"
      ],
      "metadata": {
        "id": "hSSPoSRn6r9A"
      },
      "id": "hSSPoSRn6r9A"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b774ad0-b725-4910-9050-423edf160ebd",
      "metadata": {
        "id": "9b774ad0-b725-4910-9050-423edf160ebd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the Reserach Papers dataset"
      ],
      "metadata": {
        "id": "hfHRqrpw_VlN"
      },
      "id": "hfHRqrpw_VlN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66cc97f5-7e3a-476c-9858-5643eeaa6675",
      "metadata": {
        "id": "66cc97f5-7e3a-476c-9858-5643eeaa6675"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "model_path = 'danielhou13/longformer-finetuned_papers_v2'\n",
        "model_path2 = 'danielhou13/longformer-finetuned-news-cogs402'\n",
        "model_path3 = 'allenai/longformer-base-4096'\n",
        "\n",
        "def longformer_finetuned_papers(model):\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model, num_labels = 2)\n",
        "    return model\n",
        "\n",
        "def preprocess_function(tokenizer, example, max_length):\n",
        "    example.update(tokenizer(example['text'], padding='max_length', max_length=max_length, truncation=True))\n",
        "    return example\n",
        "\n",
        "def get_papers_dataset(dataset_type):\n",
        "    max_length = 2048\n",
        "    dataset = load_dataset(\"danielhou13/cogs402dataset\")[dataset_type]\n",
        "\n",
        "    # tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "    dataset = dataset.map(lambda x: preprocess_function(tokenizer, x, max_length), batched=True)\n",
        "    setattr(dataset, 'input_columns', ['input_ids', 'attention_mask'])\n",
        "    setattr(dataset, 'target_columns', ['labels'])\n",
        "    setattr(dataset, 'max_length', max_length)\n",
        "    setattr(dataset, 'tokenizer', tokenizer)\n",
        "    return dataset\n",
        "\n",
        "def papers_test_set():\n",
        "    return get_papers_dataset('test')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the news dataset"
      ],
      "metadata": {
        "id": "Jq_wt-jn_Y6m"
      },
      "id": "Jq_wt-jn_Y6m"
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(tokenizer, example, max_length):\n",
        "    example.update(tokenizer(example['text'], max_length=max_length, truncation=True))\n",
        "    return example\n",
        "\n",
        "def longformer_finetuned_news(model):\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model, num_labels = 2)\n",
        "    return model\n",
        "\n",
        "def get_news_dataset(dataset_type):\n",
        "    max_length = 2048\n",
        "    dataset = load_dataset(\"danielhou13/cogs402dataset2\")[dataset_type]\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "    dataset = dataset.map(lambda x: preprocess_function(tokenizer, x, max_length), batched=True)\n",
        "\n",
        "    labels = map(int, dataset['hyperpartisan'])\n",
        "    print(type(dataset['hyperpartisan']))\n",
        "    labels = list(labels)\n",
        "    dataset = dataset.add_column(\"labels\", labels)\n",
        "\n",
        "    dataset = dataset.remove_columns(['title', 'hyperpartisan', 'url', 'published_at', 'bias'])\n",
        "    print(dataset)\n",
        "    setattr(dataset, 'input_columns', ['input_ids', 'attention_mask'])\n",
        "    setattr(dataset, 'target_columns', ['labels'])\n",
        "    setattr(dataset, 'max_length', max_length)\n",
        "    setattr(dataset, 'tokenizer', tokenizer)\n",
        "    return dataset\n",
        "\n",
        "def news_train_set():\n",
        "    return get_news_dataset('train')\n",
        "\n",
        "def news_test_set():\n",
        "    return get_news_dataset('validation')"
      ],
      "metadata": {
        "id": "gEI0AFC5-0qA"
      },
      "id": "gEI0AFC5-0qA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load papers model and dataset and preprocess it"
      ],
      "metadata": {
        "id": "srzj_2BeNGOK"
      },
      "id": "srzj_2BeNGOK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24ad54a3-db97-47e3-8cc7-417d4db2c99b",
      "metadata": {
        "id": "24ad54a3-db97-47e3-8cc7-417d4db2c99b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "93208d29cbda49f492a60bb40c8572a0",
            "23113842920b4ef791e63e134c8508b8",
            "d287f73354194f429be42cb893736dbb",
            "b57c47c498804a26a2b5c12c0428acd0",
            "1d0acc97a0f348a2a9e5b7876bedbf2f",
            "3b2b63159511424681b455b1c7b39e56",
            "ec9fe3a513aa4017bb91fb7d8bbc3f78",
            "066021ffacc84e9380e695f01133d611",
            "4629d3ebb5f64a01bb020ff615fbdfa6",
            "d03fc16604d24cbd92ef6e2e54af0f0b",
            "86b5f2968f244d129f5c467221ceb5ed",
            "686f6c05c4a144cd832710f1c8d71982",
            "090f4c3334584ca2bd8161910a5a58fa",
            "cf392092c87f4845a66617e3fccd303b",
            "b552af5beb3a4722b4716948138f379e",
            "3560d81ee4014a85a8dbb9ad7ac713d0",
            "a4907afbaedf416b96f910ced743fbb9",
            "03595b30669540c39fc0fa3ac3d1d57a",
            "b3b1a5f8c43e4825b3e60b4886a9f7a4",
            "ba7139d1dc974eb3993822526c14fb28",
            "691be492a2e34e24868bc133845f27da",
            "7ecf248008354ca8bed1eaf065982b33"
          ]
        },
        "outputId": "d05fabb7-5749-4048-864d-2a512c892835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration danielhou13--cogs402dataset-144b958ac1a53abb\n",
            "Reusing dataset parquet (/root/.cache/huggingface/datasets/danielhou13___parquet/danielhou13--cogs402dataset-144b958ac1a53abb/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93208d29cbda49f492a60bb40c8572a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Parameter 'function'=<function get_papers_dataset.<locals>.<lambda> at 0x7f9fd017bdd0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "686f6c05c4a144cd832710f1c8d71982"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['input_ids', 'attention_mask', 'labels']\n"
          ]
        }
      ],
      "source": [
        "cogs402_test = papers_test_set()\n",
        "model = longformer_finetuned_papers(model_path)\n",
        "columns = cogs402_test.input_columns + cogs402_test.target_columns\n",
        "print(columns)\n",
        "cogs402_test.set_format(type='torch', columns=columns)\n",
        "cogs402_test=cogs402_test.remove_columns(['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load news model and dataset and preprocess it"
      ],
      "metadata": {
        "id": "22BIYrX8NOVC"
      },
      "id": "22BIYrX8NOVC"
    },
    {
      "cell_type": "code",
      "source": [
        "# cogs402_test = news_test_set()\n",
        "# model = longformer_finetuned_news(model_path2)\n",
        "# columns = cogs402_test.input_columns + cogs402_test.target_columns\n",
        "# print(columns)\n",
        "# cogs402_test.set_format(type='torch', columns=columns)\n",
        "# cogs402_test=cogs402_test.remove_columns(['text'])"
      ],
      "metadata": {
        "id": "xh-YZZyo_eZx"
      },
      "id": "xh-YZZyo_eZx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deaabfa2-0855-41fd-870c-7a8b91e32d44",
      "metadata": {
        "id": "deaabfa2-0855-41fd-870c-7a8b91e32d44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "921f1480-7023-4deb-eeb1-4bcceaa8c45c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "print(model.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict over the dataset"
      ],
      "metadata": {
        "id": "lUXRli8TIIwm"
      },
      "id": "lUXRli8TIIwm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict using the model on the selected dataset using the [Huggingface trainer](https://huggingface.co/docs/transformers/main_classes/trainer) API."
      ],
      "metadata": {
        "id": "IXjbkX-PAGay"
      },
      "id": "IXjbkX-PAGay"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "batch_size = 1\n",
        "gradient_acc = 4\n",
        "model_name = f\"longformer-finetuned_papers\"\n",
        "training_args = TrainingArguments(output_dir=f\"models/{model_name}\",\n",
        "                                  num_train_epochs = 2,\n",
        "                                  learning_rate=2e-5,\n",
        "                                  per_device_train_batch_size=batch_size,\n",
        "                                  per_device_eval_batch_size=batch_size,\n",
        "                                  weight_decay=0.01,\n",
        "                                  evaluation_strategy=\"epoch\",\n",
        "                                  disable_tqdm=False,\n",
        "                                  push_to_hub=False,\n",
        "                                  log_level=\"error\",\n",
        "                                  fp16=True,\n",
        "                                  gradient_accumulation_steps=gradient_acc,\n",
        "                                  gradient_checkpointing=True,\n",
        "                                  save_strategy = \"epoch\")"
      ],
      "metadata": {
        "id": "7PUTFonI_XLM"
      },
      "id": "7PUTFonI_XLM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1 and accuracy are good general metrics for model performance. Recall and precision can be used if desired."
      ],
      "metadata": {
        "id": "NSxE_HDPAKaT"
      },
      "id": "NSxE_HDPAKaT"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"f1\": f1}"
      ],
      "metadata": {
        "id": "65V97tOz_e37"
      },
      "id": "65V97tOz_e37",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Place the finishing touches on our trainer, passing in the arguments, model, metrics, and datacollator (which doesn't really matter here as we pass in one item at a time)."
      ],
      "metadata": {
        "id": "SmeWbe1hEpjD"
      },
      "id": "SmeWbe1hEpjD"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator = data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "TpkwUmWN_lu1"
      },
      "id": "TpkwUmWN_lu1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we predict over the entire validation set."
      ],
      "metadata": {
        "id": "J_rg0KRlE2PU"
      },
      "id": "J_rg0KRlE2PU"
    },
    {
      "cell_type": "code",
      "source": [
        "preds_output = trainer.predict(cogs402_test)"
      ],
      "metadata": {
        "id": "4W9kCODH_wfT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "162abe7d-8b14-4f5a-a0b6-f78cb8da493a"
      },
      "id": "4W9kCODH_wfT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1070' max='1070' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1070/1070 02:31]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Picking Examples"
      ],
      "metadata": {
        "id": "wj5dQazdIbxH"
      },
      "id": "wj5dQazdIbxH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "False negatives and false postives are usually very interesting examples to analyze so to get the list of all false negatives and positives, we get our model's predictions and the list of true labels."
      ],
      "metadata": {
        "id": "wjeyImJmApjd"
      },
      "id": "wjeyImJmApjd"
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = np.argmax(preds_output.predictions, axis=1)\n",
        "y_true = np.array(cogs402_test[\"labels\"])"
      ],
      "metadata": {
        "id": "IyRQ0z-QAzAU"
      },
      "id": "IyRQ0z-QAzAU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can get the list of false negatives and false positives by subtracting the list of labels. \n",
        "\n",
        "\n",
        "If, after subtracting, the list is 0, then we have a correct prediction as the two labels are the same. We can then filter by the value of the labels to get the positive and negative class. \n",
        "\n",
        "\n",
        "If, after subtracting the false label from the true label, we have a negative, then we know that the actual label is 0 while the predicted label is 1 (as 0-1 is -1). Therefore, we get a false positive in that case. \n",
        "\n",
        "\n",
        "On the other hand, if after subtracting the false label from the true label, we get a positive, then we know that the actual label is 1 while the predicted label is 0 (as 1-0 is 1). Therefore, we have a false negative."
      ],
      "metadata": {
        "id": "T9iF_01WFrZL"
      },
      "id": "T9iF_01WFrZL"
    },
    {
      "cell_type": "code",
      "source": [
        "diff = y_true-y_preds\n",
        "correct = np.where(diff == 0)[0]\n",
        "\n",
        "pos = np.where((y_true-y_preds == 0) & (y_true==1))[0]\n",
        "neg = np.where((y_true-y_preds == 0) & (y_true==0))[0]\n",
        "\n",
        "false_pos = np.where(diff == -1)[0]\n",
        "false_neg = np.where(diff == 1)[0]\n",
        "\n",
        "print('Correctly classified: ', correct)\n",
        "\n",
        "print('cor pos: ', pos)\n",
        "print('cor neg: ', neg)\n",
        "\n",
        "print('False positives: ', false_pos)\n",
        "print('False negatives: ', false_neg)"
      ],
      "metadata": {
        "id": "ZoIa9_KIA2rt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a471d173-5e53-4238-9d74-d0ffea37cbac"
      },
      "id": "ZoIa9_KIA2rt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correctly classified:  [   0    1    2 ... 1067 1068 1069]\n",
            "cor pos:  [   0    3    5    7    9   10   12   13   14   16   18   20   26   28\n",
            "   30   32   33   39   40   41   42   43   45   49   53   58   60   62\n",
            "   64   65   68   69   72   75   76   80   81   82   86   87   90   92\n",
            "   93   95   97   98  101  105  107  108  112  113  114  116  118  119\n",
            "  120  122  124  125  126  129  131  132  135  136  141  143  145  146\n",
            "  151  153  154  155  158  160  162  163  164  165  166  167  170  172\n",
            "  174  176  177  178  180  181  182  183  185  187  188  189  192  193\n",
            "  194  195  198  199  201  202  203  204  205  208  212  215  217  218\n",
            "  219  220  224  225  229  230  233  236  238  240  241  244  247  255\n",
            "  256  257  260  261  265  266  267  268  270  273  276  277  278  280\n",
            "  281  283  284  286  287  289  290  291  292  293  296  297  299  300\n",
            "  303  305  307  308  309  312  313  314  315  316  317  318  319  321\n",
            "  327  328  330  333  334  340  342  343  344  346  347  352  353  355\n",
            "  356  360  361  364  365  367  370  372  373  374  380  381  388  389\n",
            "  390  391  396  399  402  403  404  407  411  414  415  416  417  418\n",
            "  419  420  421  422  423  424  425  429  430  431  435  438  439  440\n",
            "  441  442  444  447  448  449  451  452  455  456  458  460  461  464\n",
            "  467  470  471  472  476  479  485  486  488  489  490  491  492  493\n",
            "  495  498  500  502  505  507  511  512  515  516  518  519  522  524\n",
            "  529  530  531  532  533  535  537  539  540  541  542  545  546  548\n",
            "  549  553  554  558  559  560  562  565  567  568  571  577  581  583\n",
            "  584  586  587  588  591  594  595  596  597  598  600  602  604  607\n",
            "  608  613  615  620  622  623  624  625  626  628  629  630  631  633\n",
            "  635  636  638  639  640  642  646  649  655  656  659  660  662  663\n",
            "  666  667  669  671  673  674  675  678  679  680  683  692  693  696\n",
            "  698  699  703  704  706  708  711  715  716  717  718  720  723  724\n",
            "  725  726  727  730  732  735  736  737  738  739  740  746  747  748\n",
            "  749  753  755  759  760  763  764  765  766  767  768  770  772  773\n",
            "  776  779  780  781  782  783  786  787  789  790  791  792  794  795\n",
            "  796  799  801  803  804  809  810  812  814  815  816  817  819  821\n",
            "  822  824  825  827  828  829  830  835  836  839  847  850  853  856\n",
            "  858  859  861  862  867  871  874  875  876  879  883  884  885  886\n",
            "  888  895  897  898  899  900  907  908  912  914  915  917  918  920\n",
            "  922  924  926  930  931  933  936  938  939  940  941  942  943  946\n",
            "  947  948  949  951  952  953  955  956  959  961  963  965  966  968\n",
            "  969  970  972  976  978  979  980  981  984  985  986  987  989  991\n",
            "  996  997  999 1001 1002 1003 1004 1005 1008 1009 1010 1011 1014 1015\n",
            " 1016 1017 1019 1021 1025 1026 1027 1028 1035 1036 1038 1039 1043 1044\n",
            " 1045 1046 1048 1049 1053 1055 1057 1059 1061 1069]\n",
            "cor neg:  [   1    2    4    6    8   11   15   17   19   21   22   24   25   27\n",
            "   29   31   35   36   37   38   44   46   47   48   50   52   54   55\n",
            "   56   57   59   61   66   67   70   73   74   77   78   79   83   84\n",
            "   85   88   89   91   94   96   99  100  102  103  104  106  109  110\n",
            "  111  115  117  121  123  127  128  130  133  134  137  138  139  140\n",
            "  142  144  147  149  150  152  156  157  159  161  168  169  171  173\n",
            "  175  179  184  186  190  191  196  197  200  206  207  209  210  211\n",
            "  213  214  216  221  222  223  226  227  228  231  232  234  235  237\n",
            "  239  242  243  245  246  248  249  250  251  252  253  254  258  259\n",
            "  262  263  264  269  271  272  274  275  282  285  288  294  295  298\n",
            "  301  302  304  306  310  311  320  322  323  324  325  326  329  331\n",
            "  332  335  336  337  338  339  341  345  348  349  350  351  354  357\n",
            "  358  359  362  363  366  368  369  371  375  376  377  378  379  382\n",
            "  383  384  385  386  387  392  393  394  395  397  398  400  401  405\n",
            "  406  408  409  410  412  413  426  427  428  432  433  434  436  437\n",
            "  443  445  446  450  454  457  459  462  463  466  468  469  473  474\n",
            "  475  477  478  480  481  482  483  484  487  494  496  497  499  501\n",
            "  503  504  506  508  509  510  513  514  517  520  521  523  525  526\n",
            "  527  528  534  536  538  543  544  547  550  551  552  555  556  557\n",
            "  561  563  566  569  570  572  573  574  575  576  578  579  580  582\n",
            "  585  589  590  592  593  599  601  603  605  606  609  610  611  612\n",
            "  614  616  617  618  619  621  627  632  634  637  641  643  644  645\n",
            "  647  648  650  651  652  653  654  657  658  661  664  665  668  670\n",
            "  672  676  677  681  682  684  685  686  687  688  689  691  694  695\n",
            "  697  700  701  702  705  707  709  710  712  713  714  719  721  722\n",
            "  729  731  733  734  741  742  743  744  745  750  751  752  754  756\n",
            "  757  758  761  769  771  774  775  777  778  784  785  788  793  797\n",
            "  798  800  805  806  807  808  811  818  820  823  826  831  832  833\n",
            "  837  838  840  841  842  843  844  845  846  848  849  851  852  854\n",
            "  855  857  860  863  864  865  866  868  869  870  872  873  877  878\n",
            "  880  881  882  887  889  890  892  893  894  896  901  902  904  906\n",
            "  909  910  911  913  916  919  921  923  925  927  928  932  934  935\n",
            "  937  944  945  950  954  957  958  960  962  964  967  971  973  974\n",
            "  975  977  982  983  988  990  992  993  994  995  998 1000 1006 1007\n",
            " 1012 1013 1018 1020 1022 1023 1024 1029 1030 1031 1032 1033 1034 1037\n",
            " 1040 1041 1042 1047 1050 1051 1054 1056 1058 1060 1062 1063 1064 1065\n",
            " 1066 1067 1068]\n",
            "False positives:  [  23   34   51   63   71  148  279  453  690  728  762  802  813  834\n",
            "  903  905  929 1052]\n",
            "False negatives:  [465 564 891]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take example for evaluation based on random pick"
      ],
      "metadata": {
        "id": "d4DdhW2T6wHE"
      },
      "id": "d4DdhW2T6wHE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a35e74a3-bd67-4ee2-8e5b-2da01503f27b",
      "metadata": {
        "id": "a35e74a3-bd67-4ee2-8e5b-2da01503f27b"
      },
      "outputs": [],
      "source": [
        "rand_pos = np.random.choice(pos, size=1)\n",
        "rand_neg = np.random.choice(neg, size=1)\n",
        "rand_fp = np.random.choice(false_pos, size=1)\n",
        "rand_fn = np.random.choice(false_neg, size=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(tokenizer.convert_ids_to_tokens(cogs402_test[\"input_ids\"][rand_neg[0]]))"
      ],
      "metadata": {
        "id": "f2TDMpA1nqk_"
      },
      "id": "f2TDMpA1nqk_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some other interesting examples include the examples that are the most confidently predicted to be positive or negative. (i.e. the examples with the highest predicted probability)"
      ],
      "metadata": {
        "id": "kyVEhUfidwRV"
      },
      "id": "kyVEhUfidwRV"
    },
    {
      "cell_type": "code",
      "source": [
        "highest_pos = [np.argmax(preds_output.predictions[:,1])]\n",
        "highest_neg = [np.argmax(preds_output.predictions[:,0])]\n",
        "\n",
        "# for news dataset\n",
        "# highest_neg = [np.argmax(np.delete(preds_output.predictions, 1933, 0)[:,0])]\n",
        "\n",
        "print(highest_pos)\n",
        "print(highest_neg)"
      ],
      "metadata": {
        "id": "6WWpe52Cd3wk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb1dd9dd-dc36-4d1f-dd5c-561fb80071b5"
      },
      "id": "6WWpe52Cd3wk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[976]\n",
            "[605]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting the attention"
      ],
      "metadata": {
        "id": "RIeTsarXI7I9"
      },
      "id": "RIeTsarXI7I9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the example we want to visualize the attentions for, we pass it into the model again in order to obtain the attention output. We stack the attention to get a tensor of shape: (layer, batch, head, seq_len, x + attention_window + 1) and a tensor of shape (layer, batch, head, seq_len, x) where x is the number of global attention tokens."
      ],
      "metadata": {
        "id": "xctV7QJdJEDe"
      },
      "id": "xctV7QJdJEDe"
    },
    {
      "cell_type": "code",
      "source": [
        "test_val = [976]\n",
        "print(test_val)\n",
        "testexam = cogs402_test[test_val]"
      ],
      "metadata": {
        "id": "FrX3LUUxeORB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6510376-eb7c-436e-dae8-28367b98037b"
      },
      "id": "FrX3LUUxeORB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[976]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04c5bcaf-5fe3-4813-8444-5cfb2c63a92b",
      "metadata": {
        "id": "04c5bcaf-5fe3-4813-8444-5cfb2c63a92b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f83a6d2-2554-43a3-b895-d57ba7d141eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output_attention.shape torch.Size([12, 1, 12, 2048, 514])\n",
            "gl_output_attention.shape torch.Size([12, 1, 12, 2048, 1])\n"
          ]
        }
      ],
      "source": [
        "output = model(testexam[\"input_ids\"].cuda(), attention_mask=testexam['attention_mask'].cuda(), labels=testexam['labels'].cuda(), output_attentions = True)\n",
        "batch_attn = output[-2]\n",
        "output_attentions = torch.stack(batch_attn).cpu()\n",
        "global_attention = output[-1]\n",
        "output_global_attentions = torch.stack(global_attention).cpu()\n",
        "print(\"output_attention.shape\", output_attentions.shape)\n",
        "print(\"gl_output_attention.shape\", output_global_attentions.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(testexam['labels'][0])\n",
        "print(output[1].argmax())"
      ],
      "metadata": {
        "id": "SO4yNy98t_UP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4108823-054c-40ac-a02c-b6a1e6ae85de"
      },
      "id": "SO4yNy98t_UP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1)\n",
            "tensor(1, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2467c3d1-fe58-4e6d-aa98-534a6df72fcc",
      "metadata": {
        "id": "2467c3d1-fe58-4e6d-aa98-534a6df72fcc"
      },
      "outputs": [],
      "source": [
        "# print(os.getcwd())\n",
        "# yes = torch.load(\"resources/longformer_test2/epoch_3/aggregate_attn.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert sliding attention matrix to correct seq_len x seq_len matrix. It will change from a tensor of shape (layer, batch, head, seq_len, x + attention_window + 1) to a tensor of shape (layer, batch, head, seq_len, seq_len). More information about the functions can be found [here](https://colab.research.google.com/drive/1Kxx26NtIlUzioRCHpsR8IbSz_DpRFxEZ)."
      ],
      "metadata": {
        "id": "OevnNprR67LK"
      },
      "id": "OevnNprR67LK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0882a3e5-1b0c-4319-92a3-92f5b516d854",
      "metadata": {
        "id": "0882a3e5-1b0c-4319-92a3-92f5b516d854"
      },
      "outputs": [],
      "source": [
        "def create_head_matrix(output_attentions, global_attentions):\n",
        "    new_attention_matrix = torch.zeros((output_attentions.shape[0], \n",
        "                                      output_attentions.shape[0]))\n",
        "    for i in range(output_attentions.shape[0]):\n",
        "        test_non_zeroes = torch.nonzero(output_attentions[i]).squeeze()\n",
        "        test2 = output_attentions[i][test_non_zeroes[1:]]\n",
        "        new_attention_matrix_indices = test_non_zeroes[1:]-257 + i\n",
        "        new_attention_matrix[i][new_attention_matrix_indices] = test2\n",
        "        new_attention_matrix[i][0] = output_attentions[i][0]\n",
        "        new_attention_matrix[0] = global_attentions.squeeze()[:output_attentions.shape[0]]\n",
        "    return new_attention_matrix\n",
        "\n",
        "\n",
        "def attentions_all_heads(output_attentions, global_attentions):\n",
        "    new_matrix = []\n",
        "    for i in range(output_attentions.shape[0]):\n",
        "        matrix = create_head_matrix(output_attentions[i], global_attentions[i])\n",
        "        new_matrix.append(matrix)\n",
        "    return torch.stack(new_matrix)\n",
        "\n",
        "def all_batches(output_attentions, global_attentions):\n",
        "    new_matrix = []\n",
        "    for i in range(output_attentions.shape[0]):\n",
        "        matrix = attentions_all_heads(output_attentions[i], global_attentions[i])\n",
        "        new_matrix.append(matrix)\n",
        "    return torch.stack(new_matrix)\n",
        "\n",
        "def all_layers(output_attentions, global_attentions):\n",
        "    new_matrix = []\n",
        "    for i in range(output_attentions.shape[0]):\n",
        "        matrix = all_batches(output_attentions[i], global_attentions[i])\n",
        "        new_matrix.append(matrix)\n",
        "    return torch.stack(new_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converted_mat = all_layers(output_attentions, output_global_attentions).detach().cpu().numpy()\n",
        "print(converted_mat.shape)"
      ],
      "metadata": {
        "id": "IpdfMEMAuvyR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd271fc3-b03d-4ef4-fea1-7751959e91ca"
      },
      "id": "IpdfMEMAuvyR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12, 1, 12, 2048, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(testexam['input_ids'])"
      ],
      "metadata": {
        "id": "SIwlL_rUIlO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa1bc359-27d9-4efc-cc99-79f74cd09d8b"
      },
      "id": "SIwlL_rUIlO3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0, 29642,    25,  ...,  3156,     6,     2]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Formatting the attentions"
      ],
      "metadata": {
        "id": "OA32VVs6KF-M"
      },
      "id": "OA32VVs6KF-M"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our end goal is to overlay the attentions onto the tokens and produce a PDF of the results, so we need to grab the original tokens from the text. We cant grab the original text as it is one large string, but using the tokenizer function, we can change our input ids back to a list of tokens."
      ],
      "metadata": {
        "id": "Sl4xm-JGKKvt"
      },
      "id": "Sl4xm-JGKKvt"
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = tokenizer.convert_ids_to_tokens(testexam[\"input_ids\"][0])"
      ],
      "metadata": {
        "id": "N-Wr_p4LsTv-"
      },
      "id": "N-Wr_p4LsTv-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8Lb62qWFvwV",
        "outputId": "0af3e57e-15e5-427b-f19b-22d86bd5735b"
      },
      "id": "q8Lb62qWFvwV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', 'Published', 'Ġas', 'Ġa', 'Ġconference', 'Ġpaper', 'Ġin', 'ĠInternational', 'ĠConference', 'Ġof', 'ĠComputer', 'ĠVision', 'Ġ(', 'IC', 'CV', ')', 'Ġ2017', 'Ġ', 'ĠSpeaking', 'Ġthe', 'ĠSame', 'ĠLanguage', ':', 'ĠMatch', 'ing', 'ĠMachine', 'Ġto', 'ĠHuman', 'ĠCapt', 'ions', 'Ġby', 'ĠAd', 'vers', 'arial', 'ĠTraining', 'ĠRak', 'sh', 'ith', 'ĠShe', 'tty', '1', 'Ġ', 'ĠMarcus', 'ĠRoh', 'r', 'bach', '2', ',', '3', 'Ġ', 'Ġar', 'X', 'iv', ':', '17', '03', '.', '10', '476', 'v', '2', 'Ġ[', 'cs', '.', 'CV', ']', 'Ġ6', 'ĠNov', 'Ġ2017', 'Ġ', 'ĠMario', 'ĠFritz', '1', 'Ġ1', 'Ġ', 'ĠLisa', 'ĠAnne', 'ĠHendricks', '2', 'Ġ', 'ĠBer', 'nt', 'ĠS', 'chie', 'le', '1', 'Ġ', 'ĠMax', 'ĠPlan', 'ck', 'ĠInstitute', 'Ġfor', 'ĠIn', 'format', 'ics', ',', 'ĠSa', 'ar', 'land', 'ĠIn', 'format', 'ics', 'ĠCampus', ',', 'ĠSa', 'arb', 'ru', 'Ì', 'Ī', 'ck', 'en', ',', 'ĠGermany', 'Ġ2', 'Ġ3', 'ĠUC', 'ĠBerkeley', 'ĠE', 'EC', 'S', ',', 'ĠCA', ',', 'ĠUnited', 'ĠStates', 'ĠFacebook', 'ĠAI', 'ĠResearch', 'Ġ', 'ĠAbstract', 'ĠWhile', 'Ġstrong', 'Ġprogress', 'Ġhas', 'Ġbeen', 'Ġmade', 'Ġin', 'Ġimage', 'Ġcaption', 'ing', 'Ġrecently', ',', 'Ġmachine', 'Ġand', 'Ġhuman', 'Ġcapt', 'ions', 'Ġare', 'Ġstill', 'Ġquite', 'Ġdistinct', '.', 'ĠThis', 'Ġis', 'Ġprimarily', 'Ġdue', 'Ġto', 'Ġthe', 'Ġdeficiencies', 'Ġin', 'Ġthe', 'Ġgenerated', 'Ġword', 'Ġdistribution', ',', 'Ġvocabulary', 'Ġsize', ',', 'Ġand', 'Ġstrong', 'Ġbias', 'Ġin', 'Ġthe', 'Ġgenerators', 'Ġtowards', 'Ġfrequent', 'Ġcapt', 'ions', '.', 'ĠFurthermore', ',', 'Ġhumans', 'ĠâĢĵ', 'Ġrightfully', 'Ġso', 'ĠâĢĵ', 'Ġgenerate', 'Ġmultiple', ',', 'Ġdiverse', 'Ġcapt', 'ions', ',', 'Ġdue', 'Ġto', 'Ġthe', 'Ġinherent', 'Ġambiguity', 'Ġin', 'Ġthe', 'Ġcaption', 'ing', 'Ġtask', 'Ġwhich', 'Ġis', 'Ġnot', 'Ġexplicitly', 'Ġconsidered', 'Ġin', 'Ġtoday', 'âĢ', 'Ļ', 's', 'Ġsystems', '.', 'ĠTo', 'Ġaddress', 'Ġthese', 'Ġchallenges', ',', 'Ġwe', 'Ġchange', 'Ġthe', 'Ġtraining', 'Ġobjective', 'Ġof', 'Ġthe', 'Ġcaption', 'Ġgenerator', 'Ġfrom', 'Ġreprodu', 'cing', 'Ġground', 'truth', 'Ġcapt', 'ions', 'Ġto', 'Ġgenerating', 'Ġa', 'Ġset', 'Ġof', 'Ġcapt', 'ions', 'Ġthat', 'Ġis', 'Ġindistinguishable', 'Ġfrom', 'Ġhuman', 'Ġwritten', 'Ġcapt', 'ions', '.', 'ĠInstead', 'Ġof', 'Ġhand', 'craft', 'ing', 'Ġsuch', 'Ġa', 'Ġlearning', 'Ġtarget', ',', 'Ġwe', 'Ġemploy', 'Ġadvers', 'arial', 'Ġtraining', 'Ġin', 'Ġcombination', 'Ġwith', 'Ġan', 'Ġapproximate', 'ĠG', 'umb', 'el', 'Ġsam', 'pler', 'Ġto', 'Ġimplicitly', 'Ġmatch', 'Ġthe', 'Ġgenerated', 'Ġdistribution', 'Ġto', 'Ġthe', 'Ġhuman', 'Ġone', '.', 'ĠWhile', 'Ġour', 'Ġmethod', 'Ġachieves', 'Ġcomparable', 'Ġperformance', 'Ġto', 'Ġthe', 'Ġstate', '-', 'of', '-', 'the', '-', 'art', 'Ġin', 'Ġterms', 'Ġof', 'Ġthe', 'Ġcorrectness', 'Ġof', 'Ġthe', 'Ġcapt', 'ions', ',', 'Ġwe', 'Ġgenerate', 'Ġa', 'Ġset', 'Ġof', 'Ġdiverse', 'Ġcapt', 'ions', 'Ġthat', 'Ġare', 'Ġsignificantly', 'Ġless', 'Ġbiased', 'Ġand', 'Ġbetter', 'Ġmatch', 'Ġthe', 'Ġglobal', 'Ġun', 'i', '-,', 'Ġbi', '-', 'Ġand', 'Ġtri', '-', 'gram', 'Ġdistributions', 'Ġof', 'Ġthe', 'Ġhuman', 'Ġcapt', 'ions', '.', 'Ġ', 'ĠO', 'urs', ':', 'Ġa', 'Ġperson', 'Ġon', 'Ġsk', 'is', 'Ġjumping', 'Ġover', 'Ġa', 'Ġramp', 'Ġ', 'ĠO', 'urs', ':', 'Ġa', 'Ġsk', 'ier', 'Ġis', 'Ġmaking', 'Ġa', 'Ġturn', 'Ġon', 'Ġa', 'Ġcourse', 'Ġ', 'ĠO', 'urs', ':', 'Ġa', 'Ġcross', 'Ġcountry', 'Ġsk', 'ier', 'Ġmakes', 'Ġhis', 'Ġway', 'Ġthrough', 'Ġthe', 'Ġsnow', 'Ġ', 'ĠO', 'urs', ':', 'Ġa', 'Ġsk', 'ier', 'Ġis', 'Ġheaded', 'Ġdown', 'Ġa', 'Ġsteep', 'Ġslope', 'Ġ', 'ĠBas', 'eline', ':', 'Ġa', 'Ġman', 'Ġriding', 'Ġsk', 'is', 'Ġdown', 'Ġa', 'Ġsnow', 'Ġcovered', 'Ġslope', 'Ġ', 'ĠFigure', 'Ġ1', ':', 'ĠFour', 'Ġimages', 'Ġfrom', 'Ġthe', 'Ġtest', 'Ġset', ',', 'Ġall', 'Ġrelated', 'Ġto', 'Ġskiing', ',', 'Ġshown', 'Ġwith', 'Ġcapt', 'ions', 'Ġfrom', 'Ġour', 'Ġadvers', 'arial', 'Ġmodel', 'Ġand', 'Ġa', 'Ġbaseline', '.', 'ĠBas', 'eline', 'Ġmodel', 'Ġdescribes', 'Ġall', 'Ġfour', 'Ġimages', 'Ġwith', 'Ġone', 'Ġgeneric', 'Ġcaption', ',', 'Ġwhereas', 'Ġour', 'Ġmodel', 'Ġproduces', 'Ġdiverse', 'Ġand', 'Ġmore', 'Ġimage', 'Ġspecific', 'Ġcapt', 'ions', '.', 'ĠAs', 'Ġwe', 'Ġanalyze', 'Ġin', 'Ġthis', 'Ġpaper', ',', 'Ġthis', 'Ġis', 'Ġlikely', 'Ġdue', 'Ġto', 'Ġartifacts', 'Ġand', 'Ġdeficiencies', 'Ġin', 'Ġthe', 'Ġstatistics', 'Ġof', 'Ġthe', 'Ġgenerated', 'Ġcapt', 'ions', ',', 'Ġwhich', 'Ġis', 'Ġmore', 'Ġapparent', 'Ġwhen', 'Ġobserving', 'Ġmultiple', 'Ġsamples', '.', 'ĠSpecifically', ',', 'Ġwe', 'Ġobserve', 'Ġthat', 'Ġstate', '-', 'of', '-', 'the', '-', 'art', 'Ġsystems', 'Ġfrequently', 'ĠâĢ', 'ľ', 'reve', 'al', 'Ġthemselves', 'âĢ', 'Ŀ', 'Ġby', 'Ġgenerating', 'Ġa', 'Ġdifferent', 'Ġword', 'Ġdistribution', 'Ġand', 'Ġusing', 'Ġsmaller', 'Ġvocabulary', '.', 'ĠFurther', 'Ġscrutiny', 'Ġreveals', 'Ġthat', 'Ġgeneral', 'ization', 'Ġfrom', 'Ġthe', 'Ġtraining', 'Ġset', 'Ġis', 'Ġstill', 'Ġchallenging', 'Ġand', 'Ġgeneration', 'Ġis', 'Ġbiased', 'Ġto', 'Ġfrequent', 'Ġfragments', 'Ġand', 'Ġcapt', 'ions', '.', 'ĠAlso', ',', 'Ġtoday', 'âĢ', 'Ļ', 's', 'Ġsystems', 'Ġare', 'Ġevaluated', 'Ġto', 'Ġproduce', 'Ġa', 'Ġsingle', 'Ġcaption', '.', 'ĠYet', ',', 'Ġmultiple', 'Ġpotentially', 'Ġdistinct', 'Ġcapt', 'ions', 'Ġare', 'Ġtypically', 'Ġcorrect', 'Ġfor', 'Ġa', 'Ġsingle', 'Ġimage', 'ĠâĢĵ', 'Ġa', 'Ġproperty', 'Ġthat', 'Ġis', 'Ġreflected', 'Ġin', 'Ġhuman', 'Ġground', '-', 'truth', '.', 'ĠThis', 'Ġdiversity', 'Ġis', 'Ġnot', 'Ġequally', 'Ġreproduced', 'Ġby', 'Ġstate', '-', 'of', '-', 'the', '-', 'art', 'Ġcaption', 'Ġgenerators', 'Ġ[', '40', ',', 'Ġ23', '].', 'ĠTherefore', ',', 'Ġour', 'Ġgoal', 'Ġis', 'Ġto', 'Ġmake', 'Ġimage', 'Ġcapt', 'ions', 'Ġless', 'Ġdistinguish', 'able', 'Ġfrom', 'Ġhuman', 'Ġones', 'ĠâĢĵ', 'Ġsimilar', 'Ġin', 'Ġthe', 'Ġspirit', 'Ġto', 'Ġa', 'ĠTuring', 'Ġ', 'Ġ1', '.', 'ĠIntroduction', 'ĠImage', 'Ġcaption', 'ing', 'Ġsystems', 'Ġhave', 'Ġa', 'Ġvariety', 'Ġof', 'Ġapplications', 'Ġranging', 'Ġfrom', 'Ġmedia', 'Ġretrieval', 'Ġand', 'Ġtagging', 'Ġto', 'Ġassistance', 'Ġfor', 'Ġthe', 'Ġvisually', 'Ġimpaired', '.', 'ĠIn', 'Ġparticular', ',', 'Ġmodels', 'Ġwhich', 'Ġcombine', 'Ġstate', '-', 'of', '-', 'the', '-', 'art', 'Ġimage', 'Ġrepresentations', 'Ġbased', 'Ġon', 'Ġdeep', 'Ġconv', 'olution', 'al', 'Ġnetworks', 'Ġand', 'Ġdeep', 'Ġrecurrent', 'Ġlanguage', 'Ġmodels', 'Ġhave', 'Ġled', 'Ġto', 'Ġever', 'Ġincreasing', 'Ġperformance', 'Ġon', 'Ġevaluation', 'Ġmetrics', 'Ġsuch', 'Ġas', 'ĠC', 'ID', 'Er', 'Ġ[', '39', ']', 'Ġand', 'ĠMET', 'E', 'OR', 'Ġ[', '8', ']', 'Ġas', 'Ġcan', 'Ġbe', 'Ġseen', 'Ġe', '.', 'g', '.', 'Ġon', 'Ġthe', 'ĠC', 'OC', 'O', 'Ġimage', 'ĠCaption', 'Ġchallenge', 'Ġleader', 'board', 'Ġ[', '6', '].', 'ĠDespite', 'Ġthese', 'Ġadvances', ',', 'Ġit', 'Ġis', 'Ġoften', 'Ġeasy', 'Ġfor', 'Ġhumans', 'Ġto', 'Ġdifferentiate', 'Ġbetween', 'Ġmachine', 'Ġand', 'Ġhuman', 'Ġcapt', 'ions', 'ĠâĢĵ', 'Ġparticularly', 'Ġwhen', 'Ġobserving', 'Ġmultiple', 'Ġcapt', 'ions', 'Ġfor', 'Ġa', 'Ġsingle', 'Ġimage', '.', 'Ġ1', 'Ġ', 'Ġ', 'Č', '2', '.', 'ĠRelated', 'ĠWork', 'Ġ', 'Ġa', 'Ġbus', 'Ġthat', 'Ġhas', 'Ġpulled', 'Ġinto', 'Ġthe', 'Ġside', 'Ġof', 'Ġthe', 'Ġstreet', 'Ġa', 'Ġbus', 'Ġis', 'Ġparked', 'Ġat', 'Ġthe', 'Ġside', 'Ġof', 'Ġthe', 'Ġroad', 'Ġa', 'Ġwhite', 'Ġbus', 'Ġis', 'Ġparked', 'Ġnear', 'Ġa', 'Ġcurb', 'Ġwith', 'Ġpeople', 'Ġwalking', 'Ġby', 'Ġ', 'Ġa', 'Ġgroup', 'Ġof', 'Ġpeople', 'Ġstanding', 'Ġoutside', 'Ġin', 'Ġa', 'Ġold', 'Ġmuseum', 'Ġan', 'Ġairplane', 'Ġshow', 'Ġwhere', 'Ġpeople', 'Ġstand', 'Ġaround', 'Ġa', 'Ġline', 'Ġof', 'Ġplanes', 'Ġparked', 'Ġat', 'Ġan', 'Ġairport', 'Ġshow', 'Ġ', 'ĠBase', 'ĠâĢ¢', 'Ġa', 'Ġbus', 'Ġis', 'Ġparked', 'Ġon', 'Ġthe', 'Ġside', 'Ġof', 'Ġline', 'Ġthe', 'Ġroad', 'ĠâĢ¢', 'Ġa', 'Ġbus', 'Ġthat', 'Ġis', 'Ġparked', 'Ġin', 'Ġthe', 'Ġstreet', 'Ġa', 'Ġbus', 'Ġis', 'Ġparked', 'Ġin', 'Ġthe', 'Ġstreet', 'Ġnext', 'Ġto', 'Ġa', 'Ġbus', 'Ġ', 'Ġa', 'Ġgroup', 'Ġof', 'Ġpeople', 'Ġstanding', 'Ġaround', 'Ġa', 'Ġplane', 'Ġa', 'Ġgroup', 'Ġof', 'Ġpeople', 'Ġstanding', 'Ġaround', 'Ġa', 'Ġplane', 'Ġa', 'Ġgroup', 'Ġof', 'Ġpeople', 'Ġstanding', 'Ġaround', 'Ġa', 'Ġplane', 'Ġ', 'ĠO', 'urs', 'Ġ', 'ĠFigure', 'Ġ2', ':', 'ĠTwo', 'Ġexamples', 'Ġcomparing', 'Ġmultiple', 'Ġcapt', 'ions', 'Ġgenerated', 'Ġby', 'Ġour', 'Ġadvers', 'arial', 'Ġmodel', 'Ġand', 'Ġthe', 'Ġbaseline', '.', 'ĠBi', '-', 'gram', 's', 'Ġwhich', 'Ġare', 'Ġtop', '-', '20', 'Ġfrequent', 'Ġbi', '-', 'gram', 's', 'Ġin', 'Ġthe', 'Ġtraining', 'Ġset', 'Ġare', 'Ġmarked', 'Ġin', 'Ġred', 'Ġ(', 'e', '.', 'g', '.,', 'ĠâĢ', 'ľ', 'a', 'Ġgroup', 'âĢ', 'Ŀ', 'Ġand', 'ĠâĢ', 'ľ', 'group', 'Ġof', 'âĢ', 'Ŀ', ').', 'ĠCapt', 'ions', 'Ġwhich', 'Ġare', 'Ġrepl', 'icas', 'Ġfrom', 'Ġtraining', 'Ġset', 'Ġare', 'Ġmarked', 'Ġwith', 'ĠâĢ¢', 'Ġ.', 'ĠTest', '.', 'ĠWe', 'Ġalso', 'Ġembrace', 'Ġthe', 'Ġambiguity', 'Ġof', 'Ġthe', 'Ġtask', 'Ġand', 'Ġextend', 'Ġour', 'Ġinvestigation', 'Ġto', 'Ġpredicting', 'Ġsets', 'Ġof', 'Ġcapt', 'ions', 'Ġfor', 'Ġa', 'Ġsingle', 'Ġimage', 'Ġand', 'Ġevaluating', 'Ġtheir', 'Ġquality', ',', 'Ġparticularly', 'Ġin', 'Ġterms', 'Ġof', 'Ġthe', 'Ġdiversity', 'Ġin', 'Ġthe', 'Ġgenerated', 'Ġset', '.', 'ĠIn', 'Ġcontrast', ',', 'Ġpopular', 'Ġapproaches', 'Ġto', 'Ġimage', 'Ġcaption', 'ing', 'Ġare', 'Ġtrained', 'Ġwith', 'Ġan', 'Ġobjective', 'Ġto', 'Ġreproduce', 'Ġthe', 'Ġcapt', 'ions', 'Ġas', 'Ġprovided', 'Ġby', 'Ġthe', 'Ġground', '-', 'truth', '.', 'ĠInstead', 'Ġof', 'Ġrelying', 'Ġon', 'Ġhand', 'craft', 'ing', 'Ġloss', '-', 'fun', 'ctions', 'Ġto', 'Ġachieve', 'Ġour', 'Ġgoal', ',', 'Ġwe', 'Ġpropose', 'Ġan', 'Ġadvers', 'arial', 'Ġtraining', 'Ġmechanism', 'Ġfor', 'Ġimage', 'Ġcaption', 'ing', '.', 'ĠFor', 'Ġthis', 'Ġwe', 'Ġbuild', 'Ġon', 'ĠGener', 'ative', 'ĠAd', 'vers', 'arial', 'ĠNetworks', 'Ġ(', 'GAN', 's', ')', 'Ġ[', '14', '],', 'Ġwhich', 'Ġhave', 'Ġbeen', 'Ġsuccessfully', 'Ġused', 'Ġto', 'Ġgenerate', 'Ġmainly', 'Ġcontinuous', 'Ġdata', 'Ġdistributions', 'Ġsuch', 'Ġas', 'Ġimages', 'Ġ[', '9', ',', 'Ġ30', '],', 'Ġalthough', 'Ġexceptions', 'Ġexist', 'Ġ[', '27', '].', 'ĠIn', 'Ġcontrast', 'Ġto', 'Ġimages', ',', 'Ġcapt', 'ions', 'Ġare', 'Ġdiscrete', ',', 'Ġwhich', 'Ġposes', 'Ġa', 'Ġchallenge', 'Ġwhen', 'Ġtrying', 'Ġto', 'Ġback', 'prop', 'agate', 'Ġthrough', 'Ġthe', 'Ġgeneration', 'Ġstep', '.', 'ĠTo', 'Ġovercome', 'Ġthis', 'Ġobstacle', ',', 'Ġwe', 'Ġuse', 'Ġa', 'ĠG', 'umb', 'el', 'Ġsam', 'pler', 'Ġ[', '20', ',', 'Ġ28', ']', 'Ġthat', 'Ġallows', 'Ġfor', 'Ġend', '-', 'to', '-', 'end', 'Ġtraining', '.', 'ĠWe', 'Ġaddress', 'Ġthe', 'Ġproblem', 'Ġof', 'Ġcaption', 'Ġset', 'Ġgeneration', 'Ġfor', 'Ġimages', 'Ġand', 'Ġdiscuss', 'Ġmetrics', 'Ġto', 'Ġmeasure', 'Ġthe', 'Ġcaption', 'Ġdiversity', 'Ġand', 'Ġcompare', 'Ġit', 'Ġto', 'Ġhuman', 'Ġground', '-', 'truth', '.', 'ĠWe', 'Ġcontribute', 'Ġa', 'Ġnovel', 'Ġsolution', 'Ġto', 'Ġthis', 'Ġproblem', 'Ġusing', 'Ġan', 'Ġadvers', 'arial', 'Ġformulation', '.', 'ĠThe', 'Ġevaluation', 'Ġof', 'Ġour', 'Ġmodel', 'Ġshows', 'Ġthat', 'Ġaccuracy', 'Ġof', 'Ġgenerated', 'Ġcapt', 'ions', 'Ġis', 'Ġon', 'Ġpar', 'Ġto', 'Ġthe', 'Ġstate', '-', 'of', '-', 'the', '-', 'art', ',', 'Ġbut', 'Ġwe', 'Ġgreatly', 'Ġincrease', 'Ġthe', 'Ġdiversity', 'Ġof', 'Ġthe', 'Ġcaption', 'Ġsets', 'Ġand', 'Ġbetter', 'Ġmatch', 'Ġthe', 'Ġground', '-', 'truth', 'Ġstatistics', 'Ġin', 'Ġseveral', 'Ġmeasures', '.', 'ĠQual', 'itatively', ',', 'Ġour', 'Ġmodel', 'Ġproduces', 'Ġmore', 'Ġdiverse', 'Ġcapt', 'ions', 'Ġacross', 'Ġimages', 'Ġcontaining', 'Ġsimilar', 'Ġcontent', 'Ġ(', 'Figure', 'Ġ1', ')', 'Ġand', 'Ġwhen', 'Ġsampling', 'Ġmultiple', 'Ġcapt', 'ions', 'Ġfor', 'Ġan', 'Ġimage', 'Ġ(', 'see', 'Ġsupplementary', ')', '1', 'Ġ.', 'Ġ1', 'Ġhttps', '://', 'goo', '.', 'gl', '/', '3', 'y', 'R', 'V', 'n', 'q', 'Ġ', 'ĠImage', 'ĠDescription', '.', 'ĠEarly', 'Ġcaption', 'ing', 'Ġmodels', 'Ġrely', 'Ġon', 'Ġfirst', 'Ġrecognizing', 'Ġvisual', 'Ġelements', ',', 'Ġsuch', 'Ġas', 'Ġobjects', ',', 'Ġattributes', ',', 'Ġand', 'Ġactivities', ',', 'Ġand', 'Ġthen', 'Ġgenerating', 'Ġa', 'Ġsentence', 'Ġusing', 'Ġlanguage', 'Ġmodels', 'Ġsuch', 'Ġas', 'Ġa', 'Ġtemplate', 'Ġmodel', 'Ġ[', '13', '],', 'Ġn', '-', 'gram', 'Ġmodel', 'Ġ[', '22', '],', 'Ġor', 'Ġstatistical', 'Ġmachine', 'Ġtranslation', 'Ġ[', '34', '].', 'ĠAdv', 'ances', 'Ġin', 'Ġdeep', 'Ġlearning', 'Ġhave', 'Ġled', 'Ġto', 'Ġend', '-', 'to', '-', 'end', 'Ġtrain', 'able', 'Ġmodels', 'Ġthat', 'Ġcombine', 'Ġdeep', 'Ġconv', 'olution', 'al', 'Ġnetworks', 'Ġto', 'Ġextract', 'Ġvisual', 'Ġfeatures', 'Ġand', 'Ġrecurrent', 'Ġnetworks', 'Ġto', 'Ġgenerate', 'Ġsentences', 'Ġ[', '11', ',', 'Ġ41', ',', 'Ġ21', '].', 'ĠThough', 'Ġmodern', 'Ġdescription', 'Ġmodels', 'Ġare', 'Ġcapable', 'Ġof', 'Ġproducing', 'Ġcoherent', 'Ġsentences', 'Ġwhich', 'Ġaccurately', 'Ġdescribe', 'Ġan', 'Ġimage', ',', 'Ġthey', 'Ġtend', 'Ġto', 'Ġproduce', 'Ġgeneric', 'Ġsentences', 'Ġwhich', 'Ġare', 'Ġreplicated', 'Ġfrom', 'Ġthe', 'Ġtrain', 'Ġset', 'Ġ[', '10', '].', 'ĠFurthermore', ',', 'Ġan', 'Ġimage', 'Ġcan', 'Ġcorrespond', 'Ġto', 'Ġmany', 'Ġvalid', 'Ġdescriptions', '.', 'ĠHowever', ',', 'Ġat', 'Ġtest', 'Ġtime', ',', 'Ġsentences', 'Ġgenerated', 'Ġwith', 'Ġmethods', 'Ġsuch', 'Ġas', 'Ġbeam', 'Ġsearch', 'Ġare', 'Ġgenerally', 'Ġvery', 'Ġsimilar', '.', 'Ġ[', '40', ',', 'Ġ23', ']', 'Ġfocus', 'Ġon', 'Ġincreasing', 'Ġsentence', 'Ġdiversity', 'Ġby', 'Ġintegrating', 'Ġa', 'Ġdiversity', 'Ġpromoting', 'Ġhe', 'uristic', 'Ġinto', 'Ġbeam', 'Ġsearch', '.', 'Ġ[', '42', ']', 'Ġattempts', 'Ġto', 'Ġincrease', 'Ġthe', 'Ġdiversity', 'Ġin', 'Ġcaption', 'Ġgeneration', 'Ġby', 'Ġtraining', 'Ġan', 'Ġensemble', 'Ġof', 'Ġcaption', 'Ġgenerators', 'Ġeach', 'Ġspecializing', 'Ġin', 'Ġdifferent', 'Ġportions', 'Ġof', 'Ġthe', 'Ġtraining', 'Ġset', '.', 'ĠIn', 'Ġcontrast', ',', 'Ġwe', 'Ġfocus', 'Ġon', 'Ġimproving', 'Ġdiversity', 'Ġof', 'Ġgenerated', 'Ġcapt', 'ions', 'Ġusing', 'Ġa', 'Ġsingle', 'Ġmodel', '.', 'ĠOur', 'Ġmethod', 'Ġachieves', 'Ġthis', 'Ġby', 'Ġlearning', 'Ġa', 'Ġcorresponding', 'Ġmodel', 'Ġusing', 'Ġa', 'Ġdifferent', 'Ġtraining', 'Ġloss', 'Ġas', 'Ġopposed', 'Ġto', 'Ġafter', 'Ġtraining', 'Ġhas', 'Ġcompleted', '.', 'ĠWe', 'Ġnote', 'Ġthat', 'Ġgenerating', 'Ġdiverse', 'Ġsentences', 'Ġis', 'Ġalso', 'Ġa', 'Ġchallenge', 'Ġin', 'Ġvisual', 'Ġquestion', 'Ġgeneration', ',', 'Ġsee', 'Ġconcurrent', 'Ġwork', 'Ġ[', '19', '],', 'Ġand', 'Ġin', 'Ġlanguage', '-', 'only', 'Ġdialogue', 'Ġgeneration', 'Ġstudied', 'Ġin', 'Ġthe', 'Ġlinguistic', 'Ġcommunity', ',', 'Ġsee', 'Ġe', '.', 'g', '.', 'Ġ[', '23', ',', 'Ġ24', '].', 'ĠWhen', 'Ġtraining', 'Ġrecurrent', 'Ġdescription', 'Ġmodels', ',', 'Ġthe', 'Ġmost', 'Ġcommon', 'Ġmethod', 'Ġis', 'Ġto', 'Ġpredict', 'Ġa', 'Ġword', 'Ġw', 't', 'Ġconditioned', 'Ġon', 'Ġan', 'Ġimage', 'Ġand', 'Ġall', 'Ġprevious', 'Ġground', 'Ġtruth', 'Ġwords', '.', 'ĠAt', 'Ġtest', 'Ġtime', ',', 'Ġeach', 'Ġword', 'Ġis', 'Ġpredicted', 'Ġconditioned', 'Ġon', 'Ġan', 'Ġimage', 'Ġand', 'Ġpreviously', 'Ġpredicted', 'Ġwords', '.', 'ĠConsequently', ',', 'Ġat', 'Ġtest', 'Ġtime', 'Ġpredicted', 'Ġwords', 'Ġmay', 'Ġbe', 'Ġconditioned', 'Ġon', 'Ġwords', 'Ġthat', 'Ġwere', 'Ġincorrectly', 'Ġpredicted', 'Ġby', 'Ġthe', 'Ġmodel', '.', 'ĠBy', 'Ġonly', 'Ġtraining', 'Ġon', 'Ġground', 'Ġtruth', 'Ġwords', ',', 'Ġthe', 'Ġmodel', 'Ġsuffers', 'Ġfrom', 'Ġexposure', 'Ġbias', 'Ġ[', '31', ']', 'Ġand', 'Ġcannot', 'Ġeffectively', 'Ġlearn', 'Ġto', 'Ġrecover', 'Ġwhen', 'Ġit', 'Ġpredicts', 'Ġan', 'Ġincorrect', 'Ġword', 'Ġduring', 'Ġtraining', '.', 'ĠTo', 'Ġavoid', 'Ġthis', ',', 'Ġ[', '4', ']', 'Ġproposes', 'Ġa', 'Ġscheduled', 'Ġsampling', 'Ġtraining', 'Ġscheme', 'Ġwhich', 'Ġbegins', 'Ġby', 'Ġtraining', 'Ġwith', 'Ġground', 'Ġtruth', 'Ġwords', ',', 'Ġbut', 'Ġthen', 'Ġslowly', 'Ġconditions', 'Ġgenerated', 'Ġwords', 'Ġon', 'Ġwords', 'Ġpreviously', 'Ġproduced', 'Ġby', 'Ġthe', 'Ġmodel', '.', 'ĠHowever', ',', 'Ġ[', '17', ']', 'Ġshows', 'Ġthat', 'Ġthe', 'Ġscheduled', 'Ġsampling', 'Ġalgorithm', 'Ġis', 'Ġinconsistent', 'Ġand', 'Ġthe', 'Ġoptimal', 'Ġsolution', 'Ġunder', 'Ġthis', 'Ġobjective', 'Ġdoes', 'Ġnot', 'Ġconverge', 'Ġto', 'Ġthe', 'Ġtrue', 'Ġdata', 'Ġdistribution', '.', 'ĠTaking', 'Ġa', 'Ġdifferent', 'Ġdirection', ',', 'Ġ[', '31', ']', 'Ġproposes', 'Ġto', 'Ġaddress', 'Ġthe', 'Ġexposure', 'Ġbias', 'Ġby', 'Ġgradually', 'Ġmixing', 'Ġa', 'Ġsequence', 'Ġlevel', 'Ġloss', 'Ġ(', 'BLE', 'U', 'Ġscore', ')', 'Ġusing', 'ĠRE', 'IN', 'FOR', 'CE', 'Ġrule', 'Ġwith', 'Ġthe', 'Ġstandard', 'Ġmaximum', 'Ġlikelihood', 'Ġtraining', '.', 'ĠSeveral', 'Ġother', 'Ġworks', 'Ġhave', 'Ġfollowed', 'Ġthis', 'Ġup', 'Ġwith', 'Ġusing', 'Ġreinforcement', 'Ġlearning', 'Ġbased', 'Ġapproaches', 'Ġto', 'Ġdirectly', 'Ġoptimize', 'Ġthe', 'Ġevaluation', 'Ġmetrics', 'Ġlike', 'ĠB', 'LE', 'U', ',', 'ĠMET', 'E', 'OR', 'Ġand', 'ĠC', 'IDER', 'Ġ[', '33', ',', 'Ġ25', '].', 'ĠHowever', ',', 'Ġoptimizing', 'Ġthe', 'Ġevaluation', 'Ġmetrics', 'Ġdoes', 'Ġnot', 'Ġdirectly', 'Ġaddress', 'Ġthe', 'Ġdiversity', 'Ġof', 'Ġthe', 'Ġ', 'Ġ', 'Č', 'generated', 'Ġcapt', 'ions', '.', 'ĠSince', 'Ġall', 'Ġcurrent', 'Ġevaluation', 'Ġmetrics', 'Ġuse', 'Ġn', '-', 'gram', 'Ġmatching', 'Ġto', 'Ġscore', 'Ġthe', 'Ġcapt', 'ions', ',', 'Ġcapt', 'ions', 'Ġusing', 'Ġmore', 'Ġfrequent', 'Ġn', '-', 'gram', 's', 'Ġare', 'Ġlikely', 'Ġto', 'Ġachieve', 'Ġbetter', 'Ġscores', 'Ġthan', 'Ġones', 'Ġusing', 'Ġrare', 'r', 'Ġand', 'Ġmore', 'Ġdiverse', 'Ġn', '-', 'gram', 's', '.', 'ĠIn', 'Ġthis', 'Ġwork', ',', 'Ġwe', 'Ġformulate', 'Ġour', 'Ġcaption', 'Ġgenerator', 'Ġas', 'Ġa', 'Ġgener', 'ative', 'Ġadvers', 'arial', 'Ġnetwork', '.', 'ĠWe', 'Ġdesign', 'Ġa', 'Ġdiscrim', 'inator', 'Ġthat', 'Ġexplicitly', 'Ġencourages', 'Ġgenerated', 'Ġcapt', 'ions', 'Ġto', 'Ġbe', 'Ġdiverse', 'Ġand', 'Ġindistinguishable', 'Ġfrom', 'Ġhuman', 'Ġcapt', 'ions', '.', 'ĠThe', 'Ġgenerator', 'Ġis', 'Ġtrained', 'Ġwith', 'Ġan', 'Ġadvers', 'arial', 'Ġloss', 'Ġwith', 'Ġthis', 'Ġdiscrim', 'inator', '.', 'ĠConsequently', ',', 'Ġour', 'Ġmodel', 'Ġgenerates', 'Ġcapt', 'ions', 'Ġthat', 'Ġbetter', 'Ġreflect', 'Ġthe', 'Ġway', 'Ġhumans', 'Ġdescribe', 'Ġimages', 'Ġwhile', 'Ġmaintaining', 'Ġsimilar', 'Ġcorrectness', 'Ġas', 'Ġdetermined', 'Ġby', 'Ġa', 'Ġhuman', 'Ġevaluation', '.', 'ĠGener', 'ative', 'ĠAd', 'vers', 'arial', 'ĠNetworks', '.', 'ĠThe', 'ĠGener', 'ative', 'ĠAd', 'vers', 'arial', 'ĠNetworks', 'Ġ(', 'GAN', 's', ')', 'Ġ[', '14', ']', 'Ġframework', 'Ġlearns', 'Ġgener', 'ative', 'Ġmodels', 'Ġwithout', 'Ġexplicitly', 'Ġdefining', 'Ġa', 'Ġloss', 'Ġfrom', 'Ġa', 'Ġtarget', 'Ġdistribution', '.', 'ĠInstead', ',', 'ĠG', 'AN', 's', 'Ġlearn', 'Ġa', 'Ġgenerator', 'Ġusing', 'Ġa', 'Ġloss', 'Ġfrom', 'Ġa', 'Ġdiscrim', 'inator', 'Ġwhich', 'Ġtries', 'Ġto', 'Ġdifferentiate', 'Ġreal', 'Ġand', 'Ġgenerated', 'Ġsamples', ',', 'Ġwhere', 'Ġthe', 'Ġgenerated', 'Ġsamples', 'Ġcome', 'Ġfrom', 'Ġthe', 'Ġgenerator', '.', 'ĠWhen', 'Ġtraining', 'Ġto', 'Ġgenerate', 'Ġreal', 'Ġimages', ',', '</s>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some heads may be more important than others so we scale each attention matrix by their respective head and layer. The notebook used to get head importance is [here](https://colab.research.google.com/drive/1O4QCi8ewBp7asegKqySRflTQZ9HeH8mQ?usp=sharing)."
      ],
      "metadata": {
        "id": "P-nS_AHa7Hv6"
      },
      "id": "P-nS_AHa7Hv6"
    },
    {
      "cell_type": "code",
      "source": [
        "# head_importance = torch.load(\"/content/drive/MyDrive/cogs402longformer/t3-visapplication/resources/papers/pretrained/head_importance.pt\")\n",
        "head_importance = torch.load(\"/content/drive/MyDrive/cogs402longformer/t3-visapplication/resources/news/head_importance.pt\")"
      ],
      "metadata": {
        "id": "UsAznmcDyBgR"
      },
      "id": "UsAznmcDyBgR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_by_importance(attention_matrix, head_importance):\n",
        "  new_matrix = np.zeros_like(attention_matrix)\n",
        "  for i in range(attention_matrix.shape[0]):\n",
        "    head_importance_layer = head_importance[i]\n",
        "    for j in range(attention_matrix.shape[1]):\n",
        "      new_matrix[i,j] = attention_matrix[i,j] * np.expand_dims(head_importance_layer, axis=(1,2))\n",
        "  return new_matrix"
      ],
      "metadata": {
        "id": "_HFs_vLw0230"
      },
      "id": "_HFs_vLw0230",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converted_mat_importance = scale_by_importance(converted_mat, head_importance)"
      ],
      "metadata": {
        "id": "XUcjPfxeHbqT"
      },
      "id": "XUcjPfxeHbqT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the sum of the attentions for all the tokens (column-wise). In other words, find out how much every word is attended to"
      ],
      "metadata": {
        "id": "u0ViKJAn7Ap0"
      },
      "id": "u0ViKJAn7Ap0"
    },
    {
      "cell_type": "code",
      "source": [
        "attention_matrix_importance = converted_mat_importance.sum(axis=3)\n",
        "print(attention_matrix_importance.shape)"
      ],
      "metadata": {
        "id": "EhMNdupbxFrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7b6d0bf-8644-4b79-f5f5-0d17b3546f0d"
      },
      "id": "EhMNdupbxFrx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12, 1, 12, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A dataframe is good for picking out information from the example, but it isn't the best being a easy to read visualization. Its easier to see how much each word is attended to in an example if we have the actual example, with the words highlighted based on the magnitude of attention.\n",
        "\n",
        "We use https://github.com/jiesutd/Text-Attention-Heatmap-Visualization to show how much each token in the example is attended to, up to the max number of tokens we specified earlier.\n",
        "\n",
        "In short, these functions iterate over the list of attentions and tokens, cleans the tokens to remove special characters, and normalizes the data if you wish for it to."
      ],
      "metadata": {
        "id": "DjTu0_guLI1T"
      },
      "id": "DjTu0_guLI1T"
    },
    {
      "cell_type": "code",
      "source": [
        "## convert the text/attention list to latex code, which will further generates the text heatmap based on attention weights.\n",
        "import numpy as np\n",
        "\n",
        "latex_special_token = [\"!@#$%^&*(){}\"]\n",
        "\n",
        "def generate(text_list, attention_list, latex_file, color='red', rescale_value = True):\n",
        "\tassert(len(text_list) == len(attention_list))\n",
        "\tif rescale_value:\n",
        "\t\tattention_list = rescale(attention_list)\n",
        "\tword_num = len(text_list)\n",
        "\ttext_list = clean_word(text_list)\n",
        "\twith open(latex_file,'w') as f:\n",
        "\t\tf.write(r'''\\documentclass[varwidth]{standalone}\n",
        "\\special{papersize=210mm,297mm}\n",
        "\\usepackage{color}\n",
        "\\usepackage{tcolorbox}\n",
        "\\usepackage{CJK}\n",
        "\\usepackage{adjustbox}\n",
        "\\tcbset{width=0.9\\textwidth,boxrule=0pt,colback=red,arc=0pt,auto outer arc,left=0pt,right=0pt,boxsep=5pt}\n",
        "\\begin{document}\n",
        "\\begin{CJK*}{UTF8}{gbsn}'''+'\\n')\n",
        "\t\tstring = r'''{\\setlength{\\fboxsep}{0pt}\\colorbox{white!0}{\\parbox{0.9\\textwidth}{'''+\"\\n\"\n",
        "\t\tfor idx in range(word_num):\n",
        "\t\t\tstring += \"\\\\colorbox{%s!%s}{\"%(color, attention_list[idx])+\"\\\\strut \" + text_list[idx]+\"} \"\n",
        "\t\tstring += \"\\n}}}\"\n",
        "\t\tf.write(string+'\\n')\n",
        "\t\tf.write(r'''\\end{CJK*}\n",
        "\\end{document}''')\n",
        "\n",
        "def rescale(input_list):\n",
        "\tthe_array = np.asarray(input_list)\n",
        "\tthe_max = np.max(the_array)\n",
        "\tthe_min = np.min(the_array)\n",
        "\trescale = ((the_array - the_min)/(the_max-the_min))*100\n",
        "\treturn rescale.tolist()\n",
        "\n",
        "\n",
        "def clean_word(word_list):\n",
        "\tnew_word_list = []\n",
        "\tfor word in word_list:\n",
        "\t\tfor special_sensitive in [\"\\\\\", \"^\"]:\n",
        "\t\t\tif special_sensitive in word:\n",
        "\t\t\t\tword = word.replace(special_sensitive, '')\n",
        "\t\tfor latex_sensitive in [\"%\", \"&\", \"#\", \"_\",  \"{\", \"}\"]:\n",
        "\t\t\tif latex_sensitive in word:\n",
        "\t\t\t\tword = word.replace(latex_sensitive, '\\\\' +latex_sensitive)\n",
        "\t\tnew_word_list.append(word)\n",
        "\treturn new_word_list"
      ],
      "metadata": {
        "id": "FCsAm5i3jmKA"
      },
      "id": "FCsAm5i3jmKA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we sum get the attentions over all layers and heads."
      ],
      "metadata": {
        "id": "chtfdhR_LmE2"
      },
      "id": "chtfdhR_LmE2"
    },
    {
      "cell_type": "code",
      "source": [
        "average_attention = attention_matrix_importance.squeeze().sum(axis=1)\n",
        "average_attention = average_attention.sum(axis=0)\n",
        "print(average_attention)"
      ],
      "metadata": {
        "id": "goaO9arYjopz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eeb0c8d-0741-4ac4-9202-8266c16e010b"
      },
      "id": "goaO9arYjopz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[604.9671      6.2070427   2.2286723 ...   2.5912647   2.3770938\n",
            "   3.018391 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We call the main function above. Please change \"papers\" to whatever your project requires."
      ],
      "metadata": {
        "id": "Hzic3AuULynV"
      },
      "id": "Hzic3AuULynV"
    },
    {
      "cell_type": "code",
      "source": [
        "title_all = f\"papers_{test_val[0]}.tex\"\n",
        "generate(all_tokens, average_attention, title_all, 'red')"
      ],
      "metadata": {
        "id": "htPtu7kErWfN"
      },
      "id": "htPtu7kErWfN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets suppose you don't want to find out the attentions over all layers, but just one layer. You can do that by doing one less summation and instead picking out the layer you want immediately. Here we are picking out the last layer."
      ],
      "metadata": {
        "id": "TCKn9M3ILsEh"
      },
      "id": "TCKn9M3ILsEh"
    },
    {
      "cell_type": "code",
      "source": [
        "print(attention_matrix_importance[11].squeeze().shape)\n",
        "average_attention_final_layer = attention_matrix_importance[11].squeeze().sum(axis=0)\n",
        "print(average_attention_final_layer)\n",
        "\n",
        "# mean_12 = np.median(average_attention_final_layer)\n",
        "# average_attention_final_layer[average_attention_final_layer < mean_12] = 0\n",
        "# print(average_attention_final_layer)"
      ],
      "metadata": {
        "id": "GaM018NVunZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "687adcc2-1eae-4fd7-9621-52054ae351ce"
      },
      "id": "GaM018NVunZH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12, 2048)\n",
            "[0.30879778 0.10836545 0.05027822 ... 0.09086546 0.03899628 0.03265005]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We call the main function above. Please change \"papers\" to whatever your project requires."
      ],
      "metadata": {
        "id": "Cq8g9U_RML8Y"
      },
      "id": "Cq8g9U_RML8Y"
    },
    {
      "cell_type": "code",
      "source": [
        "title_last_layer = f\"papers_{test_val[0]}_layer_12_only.tex\"\n",
        "generate(all_tokens, average_attention_final_layer, title_last_layer, 'red')"
      ],
      "metadata": {
        "id": "fSl21NvVyW-n"
      },
      "id": "fSl21NvVyW-n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of course, you can experiment with which layers, or heads you want to visualize the attentions for based on what you desire from your own project."
      ],
      "metadata": {
        "id": "46NQc1FGMTf6"
      },
      "id": "46NQc1FGMTf6"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "Token_attention_with_head_importance_pdf.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "93208d29cbda49f492a60bb40c8572a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23113842920b4ef791e63e134c8508b8",
              "IPY_MODEL_d287f73354194f429be42cb893736dbb",
              "IPY_MODEL_b57c47c498804a26a2b5c12c0428acd0"
            ],
            "layout": "IPY_MODEL_1d0acc97a0f348a2a9e5b7876bedbf2f"
          }
        },
        "23113842920b4ef791e63e134c8508b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b2b63159511424681b455b1c7b39e56",
            "placeholder": "​",
            "style": "IPY_MODEL_ec9fe3a513aa4017bb91fb7d8bbc3f78",
            "value": "100%"
          }
        },
        "d287f73354194f429be42cb893736dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_066021ffacc84e9380e695f01133d611",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4629d3ebb5f64a01bb020ff615fbdfa6",
            "value": 2
          }
        },
        "b57c47c498804a26a2b5c12c0428acd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d03fc16604d24cbd92ef6e2e54af0f0b",
            "placeholder": "​",
            "style": "IPY_MODEL_86b5f2968f244d129f5c467221ceb5ed",
            "value": " 2/2 [00:00&lt;00:00, 35.29it/s]"
          }
        },
        "1d0acc97a0f348a2a9e5b7876bedbf2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b2b63159511424681b455b1c7b39e56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec9fe3a513aa4017bb91fb7d8bbc3f78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "066021ffacc84e9380e695f01133d611": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4629d3ebb5f64a01bb020ff615fbdfa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d03fc16604d24cbd92ef6e2e54af0f0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86b5f2968f244d129f5c467221ceb5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "686f6c05c4a144cd832710f1c8d71982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_090f4c3334584ca2bd8161910a5a58fa",
              "IPY_MODEL_cf392092c87f4845a66617e3fccd303b",
              "IPY_MODEL_b552af5beb3a4722b4716948138f379e"
            ],
            "layout": "IPY_MODEL_3560d81ee4014a85a8dbb9ad7ac713d0"
          }
        },
        "090f4c3334584ca2bd8161910a5a58fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4907afbaedf416b96f910ced743fbb9",
            "placeholder": "​",
            "style": "IPY_MODEL_03595b30669540c39fc0fa3ac3d1d57a",
            "value": "100%"
          }
        },
        "cf392092c87f4845a66617e3fccd303b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3b1a5f8c43e4825b3e60b4886a9f7a4",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba7139d1dc974eb3993822526c14fb28",
            "value": 2
          }
        },
        "b552af5beb3a4722b4716948138f379e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_691be492a2e34e24868bc133845f27da",
            "placeholder": "​",
            "style": "IPY_MODEL_7ecf248008354ca8bed1eaf065982b33",
            "value": " 2/2 [00:20&lt;00:00,  8.69s/ba]"
          }
        },
        "3560d81ee4014a85a8dbb9ad7ac713d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4907afbaedf416b96f910ced743fbb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03595b30669540c39fc0fa3ac3d1d57a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3b1a5f8c43e4825b3e60b4886a9f7a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba7139d1dc974eb3993822526c14fb28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "691be492a2e34e24868bc133845f27da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ecf248008354ca8bed1eaf065982b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}