{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "167f6bd9",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/danielhou13/cogs402longformer/blob/main/src/Token_attention_with_head_importance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kZTPlUo8Wp1T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZTPlUo8Wp1T",
    "outputId": "c072f1a9-c2f6-4a9b-977b-e99e94817011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AlcBiC0nWtJE",
   "metadata": {
    "id": "AlcBiC0nWtJE"
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/content/drive/My Drive/{}'.format(\"cogs402longformer/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s_6vceLhTIBf",
   "metadata": {
    "id": "s_6vceLhTIBf"
   },
   "outputs": [],
   "source": [
    "pip install datasets --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M-qXH2JkTMdA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M-qXH2JkTMdA",
    "outputId": "db9a9676-d6fa-4ddc-8706-248cf5f4e907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hSSPoSRn6r9A",
   "metadata": {
    "id": "hSSPoSRn6r9A"
   },
   "source": [
    "Import Dataset and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b774ad0-b725-4910-9050-423edf160ebd",
   "metadata": {
    "id": "9b774ad0-b725-4910-9050-423edf160ebd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hfHRqrpw_VlN",
   "metadata": {
    "id": "hfHRqrpw_VlN"
   },
   "source": [
    "Import the Reserach Papers dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cc97f5-7e3a-476c-9858-5643eeaa6675",
   "metadata": {
    "id": "66cc97f5-7e3a-476c-9858-5643eeaa6675"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "\n",
    "def longformer_finetuned_papers():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained('danielhou13/longformer-finetuned_papers', num_labels = 2)\n",
    "    return model\n",
    "\n",
    "def preprocess_function(tokenizer, example, max_length):\n",
    "    example.update(tokenizer(example['text'], padding='max_length', max_length=max_length, truncation=True))\n",
    "    return example\n",
    "\n",
    "def get_papers_dataset(dataset_type):\n",
    "    max_length = 2048\n",
    "    dataset = load_dataset(\"danielhou13/cogs402dataset\")[dataset_type]\n",
    "\n",
    "    # tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "    dataset = dataset.map(lambda x: preprocess_function(tokenizer, x, max_length), batched=True)\n",
    "    setattr(dataset, 'input_columns', ['input_ids', 'attention_mask'])\n",
    "    setattr(dataset, 'target_columns', ['labels'])\n",
    "    setattr(dataset, 'max_length', max_length)\n",
    "    setattr(dataset, 'tokenizer', tokenizer)\n",
    "    return dataset\n",
    "\n",
    "def papers_test_set():\n",
    "    return get_papers_dataset('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Jq_wt-jn_Y6m",
   "metadata": {
    "id": "Jq_wt-jn_Y6m"
   },
   "source": [
    "Import the news dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gEI0AFC5-0qA",
   "metadata": {
    "id": "gEI0AFC5-0qA"
   },
   "outputs": [],
   "source": [
    "# def preprocess_function(tokenizer, example, max_length):\n",
    "#     example.update(tokenizer(example['text'], padding='max_length', max_length=max_length, truncation=True))\n",
    "#     return example\n",
    "\n",
    "# def longformer_finetuned_news():\n",
    "#     model = AutoModelForSequenceClassification.from_pretrained('danielhou13/longformer-finetuned-news-cogs402', num_labels = 2)\n",
    "#     return model\n",
    "\n",
    "# def get_news_dataset(dataset_type):\n",
    "#     max_length = 2048\n",
    "#     dataset = load_dataset(\"danielhou13/cogs402dataset2\")[dataset_type]\n",
    "\n",
    "#     tokenizer = AutoTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "#     dataset = dataset.map(lambda x: preprocess_function(tokenizer, x, max_length), batched=True)\n",
    "\n",
    "#     labels = map(int, dataset['hyperpartisan'])\n",
    "#     print(type(dataset['hyperpartisan']))\n",
    "#     labels = list(labels)\n",
    "#     dataset = dataset.add_column(\"labels\", labels)\n",
    "\n",
    "#     dataset = dataset.remove_columns(['text', 'title', 'hyperpartisan', 'url', 'published_at', 'bias'])\n",
    "#     print(dataset)\n",
    "#     setattr(dataset, 'input_columns', ['input_ids', 'attention_mask'])\n",
    "#     setattr(dataset, 'target_columns', ['labels'])\n",
    "#     setattr(dataset, 'max_length', max_length)\n",
    "#     setattr(dataset, 'tokenizer', tokenizer)\n",
    "#     return dataset\n",
    "\n",
    "# def news_train_set():\n",
    "#     return get_news_dataset('train')\n",
    "\n",
    "# def news_test_set():\n",
    "#     return get_news_dataset('validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "srzj_2BeNGOK",
   "metadata": {
    "id": "srzj_2BeNGOK"
   },
   "source": [
    "Load papers model and dataset and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad54a3-db97-47e3-8cc7-417d4db2c99b",
   "metadata": {
    "id": "24ad54a3-db97-47e3-8cc7-417d4db2c99b"
   },
   "outputs": [],
   "source": [
    "cogs402_test = papers_test_set()\n",
    "model = longformer_finetuned_papers()\n",
    "columns = cogs402_test.input_columns + cogs402_test.target_columns\n",
    "print(columns)\n",
    "cogs402_test.set_format(type='torch', columns=columns)\n",
    "cogs402_test=cogs402_test.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22BIYrX8NOVC",
   "metadata": {
    "id": "22BIYrX8NOVC"
   },
   "source": [
    "Load news model and dataset and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xh-YZZyo_eZx",
   "metadata": {
    "id": "xh-YZZyo_eZx"
   },
   "outputs": [],
   "source": [
    "# cogs402_test = news_test_set()\n",
    "# model = longformer_finetuned_news()\n",
    "# columns = cogs402_test.input_columns + cogs402_test.target_columns\n",
    "# print(columns)\n",
    "# cogs402_test.set_format(type='torch', columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaabfa2-0855-41fd-870c-7a8b91e32d44",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "deaabfa2-0855-41fd-870c-7a8b91e32d44",
    "outputId": "ae8c4d86-c913-4b8f-9978-fed62f9b10eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4DdhW2T6wHE",
   "metadata": {
    "id": "d4DdhW2T6wHE"
   },
   "source": [
    "Take example for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35e74a3-bd67-4ee2-8e5b-2da01503f27b",
   "metadata": {
    "id": "a35e74a3-bd67-4ee2-8e5b-2da01503f27b"
   },
   "outputs": [],
   "source": [
    "testexam = cogs402_test[923]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abfe181-bc3e-41cb-a56e-30a7cf29d3b7",
   "metadata": {
    "id": "2abfe181-bc3e-41cb-a56e-30a7cf29d3b7"
   },
   "outputs": [],
   "source": [
    "# print(test['labels'][923])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c5bcaf-5fe3-4813-8444-5cfb2c63a92b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04c5bcaf-5fe3-4813-8444-5cfb2c63a92b",
    "outputId": "f8cab6bf-5db0-4d03-91ce-f9eeb73998ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_attention.shape torch.Size([12, 1, 12, 2048, 514])\n",
      "gl_output_attention.shape torch.Size([12, 1, 12, 2048, 1])\n"
     ]
    }
   ],
   "source": [
    "output = model(testexam[\"input_ids\"].unsqueeze(0).cuda(), attention_mask=testexam['attention_mask'].unsqueeze(0).cuda(), labels=testexam['labels'].cuda(), output_attentions = True)\n",
    "batch_attn = output[-2]\n",
    "output_attentions = torch.stack(batch_attn).cpu()\n",
    "global_attention = output[-1]\n",
    "output_global_attentions = torch.stack(global_attention).cpu()\n",
    "print(\"output_attention.shape\", output_attentions.shape)\n",
    "print(\"gl_output_attention.shape\", output_global_attentions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2467c3d1-fe58-4e6d-aa98-534a6df72fcc",
   "metadata": {
    "id": "2467c3d1-fe58-4e6d-aa98-534a6df72fcc"
   },
   "outputs": [],
   "source": [
    "# print(os.getcwd())\n",
    "# yes = torch.load(\"resources/longformer_test2/epoch_3/aggregate_attn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OevnNprR67LK",
   "metadata": {
    "id": "OevnNprR67LK"
   },
   "source": [
    "Convert sliding attention matrix to correct seq_len x seq_len matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0882a3e5-1b0c-4319-92a3-92f5b516d854",
   "metadata": {
    "id": "0882a3e5-1b0c-4319-92a3-92f5b516d854"
   },
   "outputs": [],
   "source": [
    "def create_head_matrix(output_attentions, global_attentions):\n",
    "    new_attention_matrix = torch.zeros((output_attentions.shape[0], \n",
    "                                      output_attentions.shape[0]))\n",
    "    for i in range(output_attentions.shape[0]):\n",
    "        test_non_zeroes = torch.nonzero(output_attentions[i]).squeeze()\n",
    "        test2 = output_attentions[i][test_non_zeroes[1:]]\n",
    "        new_attention_matrix_indices = test_non_zeroes[1:]-257 + i\n",
    "        new_attention_matrix[i][new_attention_matrix_indices] = test2\n",
    "        new_attention_matrix[i][0] = output_attentions[i][0]\n",
    "        new_attention_matrix[0] = global_attentions.squeeze()[:output_attentions.shape[0]]\n",
    "    return new_attention_matrix\n",
    "\n",
    "\n",
    "def attentions_all_heads(output_attentions, global_attentions):\n",
    "    new_matrix = []\n",
    "    for i in range(output_attentions.shape[0]):\n",
    "        matrix = create_head_matrix(output_attentions[i], global_attentions[i])\n",
    "        new_matrix.append(matrix)\n",
    "    return torch.stack(new_matrix)\n",
    "\n",
    "def all_batches(output_attentions, global_attentions):\n",
    "    new_matrix = []\n",
    "    for i in range(output_attentions.shape[0]):\n",
    "        matrix = attentions_all_heads(output_attentions[i], global_attentions[i])\n",
    "        new_matrix.append(matrix)\n",
    "    return torch.stack(new_matrix)\n",
    "\n",
    "def all_layers(output_attentions, global_attentions):\n",
    "    new_matrix = []\n",
    "    for i in range(output_attentions.shape[0]):\n",
    "        matrix = all_batches(output_attentions[i], global_attentions[i])\n",
    "        new_matrix.append(matrix)\n",
    "    return torch.stack(new_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IpdfMEMAuvyR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IpdfMEMAuvyR",
    "outputId": "0fd24eca-07f7-45ba-a9be-34e7fb3986a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 1, 12, 2048, 2048)\n"
     ]
    }
   ],
   "source": [
    "converted_mat = all_layers(output_attentions, output_global_attentions).detach().cpu().numpy()\n",
    "print(converted_mat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u0ViKJAn7Ap0",
   "metadata": {
    "id": "u0ViKJAn7Ap0"
   },
   "source": [
    "Sum over all the tokens (column-wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EhMNdupbxFrx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EhMNdupbxFrx",
    "outputId": "0bdf7788-d195-4b7c-d9b9-eea857b9af35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 1, 12, 2048)\n"
     ]
    }
   ],
   "source": [
    "attention_sum = converted_mat.sum(axis=3)\n",
    "print(attention_sum.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "P-nS_AHa7Hv6",
   "metadata": {
    "id": "P-nS_AHa7Hv6"
   },
   "source": [
    "Load head importance model and scale the attentions by head importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UsAznmcDyBgR",
   "metadata": {
    "id": "UsAznmcDyBgR"
   },
   "outputs": [],
   "source": [
    "head_importance = torch.load(\"/content/drive/MyDrive/cogs402longformer/t3-visapplication/resources/pretrained/head_importance.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x_j_d91mnUhO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x_j_d91mnUhO",
    "outputId": "de8dd119-c1fc-44fd-f47b-fcb5ee629b72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00404374 0.02163236 0.00531127 0.01472499 0.03868961 0.00646301\n",
      " 0.01300004 0.00334545 1.         0.00796655 0.1583804  0.01080081]\n"
     ]
    }
   ],
   "source": [
    "print(head_importance[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_HFs_vLw0230",
   "metadata": {
    "id": "_HFs_vLw0230"
   },
   "outputs": [],
   "source": [
    "def scale_by_importance(attention_matrix, head_importance):\n",
    "  new_matrix = np.zeros_like(attention_matrix)\n",
    "  for i in range(attention_matrix.shape[0]):\n",
    "    head_importance_layer = head_importance[i]\n",
    "    for j in range(attention_matrix.shape[1]):\n",
    "      print(attention_matrix[i][j].shape)\n",
    "      new_matrix[i][j] = attention_matrix[i][j] * np.expand_dims(head_importance_layer, axis=1)\n",
    "  return new_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MtGmU6Ol75E3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MtGmU6Ol75E3",
    "outputId": "f05f421e-ee18-4d73-c3bd-28695693399e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 2048)\n",
      "(12, 2048)\n",
      "(12, 2048)\n",
      "(12, 2048)\n",
      "(12, 2048)\n",
      "(12, 2048)\n",
      "(12, 2048)\n",
      "(12, 2048)\n",
      "(12, 2048)\n",
      "(12, 2048)\n",
      "(12, 2048)\n",
      "(12, 2048)\n",
      "(12, 12, 2048)\n"
     ]
    }
   ],
   "source": [
    "attention_matrix_importance = scale_by_importance(attention_sum, head_importance)\n",
    "print(attention_matrix_importance[:, 0, :, :].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j69lkNxlhu3A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j69lkNxlhu3A",
    "outputId": "c64b1cb3-2b08-4b19-f6bf-b54fa96b4473"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[2.95303911e-01 8.87675881e-02 1.15745710e-02 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [4.36791569e-01 1.14750065e-01 4.10810597e-02 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [2.16136679e-01 8.16718042e-02 5.30701168e-02 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [2.78009102e-04 4.33045533e-03 5.25094569e-02 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [2.50567198e-01 7.70653188e-02 5.28139733e-02 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [6.79462478e-02 6.82771876e-02 6.81128129e-02 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[1.27067053e+00 1.18729367e-03 2.92891893e-03 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.99715662e+00 1.59483515e-02 3.15287593e-03 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [9.76274069e-03 4.11544852e-06 2.69944053e-02 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [2.78178000e+00 1.09189689e-01 3.67725790e-02 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.71019769e+00 7.52029649e-04 1.72021729e-03 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [7.19493341e+00 2.18045339e-02 1.28493132e-02 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[5.58289409e-01 7.41688054e-05 5.02387178e-04 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [8.02812278e-01 2.45666020e-02 1.86015032e-02 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.53032196e+00 4.12510017e-05 5.45522431e-04 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [2.74684727e-01 1.18580123e-04 8.53739027e-03 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.11360226e+01 8.41535777e-02 3.09780035e-02 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.35520887e+00 4.27433662e-03 8.24307266e-04 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[4.18544914e-05 7.17656576e-07 9.07876085e-07 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [6.49838912e-05 4.52683435e-06 5.34365390e-05 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.12093170e-04 7.86450255e-06 8.13231145e-06 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [2.48644847e-05 1.97711915e-06 1.06419602e-05 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [6.75627816e-05 2.60613774e-06 1.28723161e-06 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [4.03609360e-03 2.58882821e-04 5.45468007e-04 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[8.92001146e-04 5.80829437e-05 7.26004364e-05 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [6.83060149e-04 3.80627571e-05 5.63564790e-05 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [3.91521062e-05 2.07930839e-06 5.99217265e-06 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [3.37435980e-04 8.41311994e-05 2.15027161e-04 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [4.23968486e-05 1.47769219e-06 4.70615987e-06 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.21187841e-04 3.33527096e-05 9.31029354e-06 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[3.68221197e-04 3.86257998e-05 1.84933306e-05 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [6.07741647e-04 5.98989282e-05 4.38215611e-05 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.38523428e-05 5.42537528e-05 8.82656095e-05 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [4.94767346e-06 1.58774346e-05 1.67869184e-05 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [8.00318725e-04 2.12760307e-04 2.29875019e-04 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [9.58065575e-05 3.27343005e-05 2.85696005e-05 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]]]\n"
     ]
    }
   ],
   "source": [
    "print(attention_matrix_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0pgucS7OIp",
   "metadata": {
    "id": "cc0pgucS7OIp"
   },
   "source": [
    "Get top k attended words for each head, for each example in batch, for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h6nLRpgBltnk",
   "metadata": {
    "id": "h6nLRpgBltnk"
   },
   "outputs": [],
   "source": [
    "def find_top_attention(scores_mat, axis, k):\n",
    "  indices = scores_mat.argsort(axis=axis)[:, :, :, :-(k+1):-1]\n",
    "  vals = np.take_along_axis(scores_mat, indices, axis=axis)\n",
    "  return indices, vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N-Wr_p4LsTv-",
   "metadata": {
    "id": "N-Wr_p4LsTv-"
   },
   "outputs": [],
   "source": [
    "all_tokens = tokenizer.convert_ids_to_tokens(testexam[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-wAlJI1jrOe",
   "metadata": {
    "id": "c-wAlJI1jrOe"
   },
   "source": [
    "We want the position (index) of the token, the attention value, and the actual token itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iGoppwBFoly4",
   "metadata": {
    "id": "iGoppwBFoly4"
   },
   "outputs": [],
   "source": [
    "indexes, values = find_top_attention(attention_matrix_importance, 3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aRLF1_Td4qvB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aRLF1_Td4qvB",
    "outputId": "2606e7ae-9297-4b16-821e-3d9a11c06d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 1, 12, 10)\n"
     ]
    }
   ],
   "source": [
    "print(indexes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NSv7L_PVvLdZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NSv7L_PVvLdZ",
    "outputId": "bbf17992-6f02-438e-f161-6c87e80e05bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 1, 12, 10)\n"
     ]
    }
   ],
   "source": [
    "def get_tokens(index_matrix):\n",
    "  highest_tokens = []\n",
    "  for i in range(indexes.shape[0]):\n",
    "    row_tokens = []\n",
    "    for j in range(indexes.shape[1]):\n",
    "      batch_tokens = []\n",
    "      for k in range(indexes.shape[2]):\n",
    "        tokens = [all_tokens[idx] for idx in indexes[i][j][k]]\n",
    "        batch_tokens.append(tokens)\n",
    "      row_tokens.append(batch_tokens)\n",
    "    highest_tokens.append(row_tokens)\n",
    "  return np.array(highest_tokens)\n",
    "\n",
    "highest_tokens = get_tokens(indexes)\n",
    "print(highest_tokens.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zZyzrWSgsjNj",
   "metadata": {
    "id": "zZyzrWSgsjNj"
   },
   "source": [
    "Get the attention of a token at a position for each layer and head. Take one example at a time as each example has different tokens. Pros: can isolate for layers and/or heads. Cons: not much context for the attention scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jrjjYyR-siot",
   "metadata": {
    "id": "jrjjYyR-siot"
   },
   "outputs": [],
   "source": [
    "def position_attention(agg_matrix, example, position):\n",
    "  new_mat = agg_matrix[:, example, :]\n",
    "  new_mat = new_mat.squeeze()\n",
    "  print(new_mat.shape)\n",
    "  dataframe=[]\n",
    "  for i in range(new_mat.shape[0]):\n",
    "    for j in range(new_mat.shape[1]):\n",
    "      temp = new_mat[i,j].argsort()[::-1]\n",
    "      temp = np.where(temp==position)[0].squeeze() + 1\n",
    "      d = {\"token\":all_tokens[position], 'position':position, \n",
    "           'attention_scores':new_mat[i,j,position], 'layer':(i+1), 'head':(j+1),\n",
    "           'rank':temp}\n",
    "      dataframe.append(d)\n",
    "  df = pd.DataFrame(dataframe)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "K0djK1yi0GYJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K0djK1yi0GYJ",
    "outputId": "aeaf01ff-739c-4f6c-8b15-45a2fb1ef07d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 12, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(attention_matrix_importance[:,0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YpSZKQ0nvt5T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "YpSZKQ0nvt5T",
    "outputId": "ffeeb7dd-2212-43de-ca97-506f426f30c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 12, 2048)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-65743760-b3fe-4a28-8231-aca0d1370e42\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>position</th>\n",
       "      <th>attention_scores</th>\n",
       "      <th>layer</th>\n",
       "      <th>head</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.295304</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>1.270671</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.558289</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>2.003426</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.072135</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181244</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019496</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.049842</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65743760-b3fe-4a28-8231-aca0d1370e42')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-65743760-b3fe-4a28-8231-aca0d1370e42 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-65743760-b3fe-4a28-8231-aca0d1370e42');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    token  position  attention_scores  layer  head  rank\n",
       "0     <s>         0          0.295304      1     1     1\n",
       "12    <s>         0          1.270671      2     1     1\n",
       "24    <s>         0          0.558289      3     1     1\n",
       "36    <s>         0          2.003426      4     1     1\n",
       "48    <s>         0          0.072135      5     1     2\n",
       "60    <s>         0          0.181244      6     1     8\n",
       "72    <s>         0          0.019496      7     1    94\n",
       "84    <s>         0          0.049842      8     1     1\n",
       "96    <s>         0          0.000346      9     1    15\n",
       "108   <s>         0          0.000042     10     1    90\n",
       "120   <s>         0          0.000892     11     1   150\n",
       "132   <s>         0          0.000368     12     1   189"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_df = position_attention(attention_matrix_importance, 0, 0)\n",
    "position_df[position_df[\"head\"]==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QYwu3xw37k-k",
   "metadata": {
    "id": "QYwu3xw37k-k"
   },
   "source": [
    "If really needed, can just have the full matrix of the position, ranks, attention scores, layers, and heads of each token per example. \n",
    "\n",
    "Tokens are all the tokens in the example. Position is the location of the token with zero-based indexing. Attention scores are the aggregate, scaled attention scores.\n",
    "\n",
    "Layer goes from 1 to 12.\n",
    "Head goes from 1 to 12.\n",
    "\n",
    "Rank is the attention score rank with respect to layer and head. Goes from 1 to number of tokens in the example\n",
    "\n",
    "Pros: can search up whatever is needed. Has access to all the information and can be extracted for comparisons Cons: have to know what you want and manually look it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n8WZcz_w7Chc",
   "metadata": {
    "id": "n8WZcz_w7Chc"
   },
   "outputs": [],
   "source": [
    "def full_matrix(agg_matrix, example):\n",
    "  new_mat = agg_matrix[:, example]\n",
    "  new_mat = new_mat.squeeze()\n",
    "  print(new_mat.shape)\n",
    "  dataframe=[]\n",
    "  for i in range(new_mat.shape[0]):\n",
    "    for j in range(new_mat.shape[1]):\n",
    "      temp = new_mat[i,j].argsort()[::-1]      \n",
    "      for k in range(new_mat.shape[2]):\n",
    "        temp2 = np.where(temp==k)[0].squeeze() + 1\n",
    "        d = {\"token\":all_tokens[k], 'position':k, \n",
    "            'attention_scores':new_mat[i,j,k], 'layer':(i+1), 'head':(j+1),\n",
    "            'rank':temp2}\n",
    "        dataframe.append(d)\n",
    "  df = pd.DataFrame(dataframe)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mn8NifO00kND",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mn8NifO00kND",
    "outputId": "ecb0a761-c62b-4b24-c9fe-8b1b8989ebba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 12, 2048)\n"
     ]
    }
   ],
   "source": [
    "full_mat = full_matrix(attention_matrix_importance,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-kn2bEWf8BN0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "-kn2bEWf8BN0",
    "outputId": "a60ec6f8-abd8-4d59-8ab3-915eeae1490c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-879bead1-f9c0-400e-a650-f15517697a85\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>position</th>\n",
       "      <th>attention_scores</th>\n",
       "      <th>layer</th>\n",
       "      <th>head</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.295304</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;</td>\n",
       "      <td>1</td>\n",
       "      <td>0.088768</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p</td>\n",
       "      <td>2</td>\n",
       "      <td>0.011575</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>0.074105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Episode</td>\n",
       "      <td>4</td>\n",
       "      <td>0.041921</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>2043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>2044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>2045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>2046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>2047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2048 rows × 6 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-879bead1-f9c0-400e-a650-f15517697a85')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-879bead1-f9c0-400e-a650-f15517697a85 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-879bead1-f9c0-400e-a650-f15517697a85');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        token  position  attention_scores  layer  head  rank\n",
       "0         <s>         0          0.295304      1     1     1\n",
       "1           <         1          0.088768      1     1    19\n",
       "2           p         2          0.011575      1     1   429\n",
       "3           >         3          0.074105      1     1    39\n",
       "4     Episode         4          0.041921      1     1   195\n",
       "...       ...       ...               ...    ...   ...   ...\n",
       "2043    <pad>      2043          0.000000      1     1  1373\n",
       "2044    <pad>      2044          0.000000      1     1  1374\n",
       "2045    <pad>      2045          0.000000      1     1  1375\n",
       "2046    <pad>      2046          0.000000      1     1   756\n",
       "2047    <pad>      2047          0.000000      1     1  1025\n",
       "\n",
       "[2048 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_mat[(full_mat['head']==1) & (full_mat['layer']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gczzuFA979sO",
   "metadata": {
    "id": "gczzuFA979sO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Token_attention_with_head_importance.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
