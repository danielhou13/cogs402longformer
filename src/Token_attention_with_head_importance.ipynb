{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielhou13/cogs402longformer/blob/main/src/Token_attention_with_head_importance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A key feature of Transformer neural networks is the attention feature. This attention is generally a sequence length x sequence length matrix output for every layer, batch and head of an input. As such, for every layer, batch, head, we can find out information about each token, whether its about what tokens a particular token attends to, or the most attended to token for each matrix. This notebook takes an example from a dataset, and explores the attentions of each token in depth. Notably, we find out what tokens each token attends to the most and what tokens that get the most attention, across all layers and heads."
      ],
      "metadata": {
        "id": "m1Bc0bw-mNkB"
      },
      "id": "m1Bc0bw-mNkB"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kZTPlUo8Wp1T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff1daa1-965a-42c4-abfd-5439c39bc0d9"
      },
      "id": "kZTPlUo8Wp1T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys\n",
        "# sys.path.append('/content/drive/My Drive/{}'.format(\"cogs402longformer/\"))"
      ],
      "metadata": {
        "id": "AlcBiC0nWtJE"
      },
      "id": "AlcBiC0nWtJE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install and Import Dependencies"
      ],
      "metadata": {
        "id": "-nmZtunIuDIM"
      },
      "id": "-nmZtunIuDIM"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets --quiet"
      ],
      "metadata": {
        "id": "s_6vceLhTIBf"
      },
      "id": "s_6vceLhTIBf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "M-qXH2JkTMdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3cbcef1-0b9e-4048-f130-bf9c1d2db395"
      },
      "id": "M-qXH2JkTMdA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b774ad0-b725-4910-9050-423edf160ebd",
      "metadata": {
        "id": "9b774ad0-b725-4910-9050-423edf160ebd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Import Dataset and Model"
      ],
      "metadata": {
        "id": "hSSPoSRn6r9A"
      },
      "id": "hSSPoSRn6r9A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the Reserach Papers dataset"
      ],
      "metadata": {
        "id": "hfHRqrpw_VlN"
      },
      "id": "hfHRqrpw_VlN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66cc97f5-7e3a-476c-9858-5643eeaa6675",
      "metadata": {
        "id": "66cc97f5-7e3a-476c-9858-5643eeaa6675"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "\n",
        "def longformer_finetuned_papers():\n",
        "    model = AutoModelForSequenceClassification.from_pretrained('danielhou13/longformer-finetuned_papers_v2', num_labels = 2)\n",
        "    return model\n",
        "\n",
        "def preprocess_function(tokenizer, example, max_length):\n",
        "    example.update(tokenizer(example['text'], padding='max_length', max_length=max_length, truncation=True))\n",
        "    return example\n",
        "\n",
        "def get_papers_dataset(dataset_type):\n",
        "    max_length = 2048\n",
        "    dataset = load_dataset(\"danielhou13/cogs402dataset\")[dataset_type]\n",
        "\n",
        "    # tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "    dataset = dataset.map(lambda x: preprocess_function(tokenizer, x, max_length), batched=True)\n",
        "    setattr(dataset, 'input_columns', ['input_ids', 'attention_mask'])\n",
        "    setattr(dataset, 'target_columns', ['labels'])\n",
        "    setattr(dataset, 'max_length', max_length)\n",
        "    setattr(dataset, 'tokenizer', tokenizer)\n",
        "    return dataset\n",
        "\n",
        "def papers_test_set():\n",
        "    return get_papers_dataset('test')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the news dataset"
      ],
      "metadata": {
        "id": "Jq_wt-jn_Y6m"
      },
      "id": "Jq_wt-jn_Y6m"
    },
    {
      "cell_type": "code",
      "source": [
        "# def preprocess_function(tokenizer, example, max_length):\n",
        "#     example.update(tokenizer(example['text'], padding='max_length', max_length=max_length, truncation=True))\n",
        "#     return example\n",
        "\n",
        "# def longformer_finetuned_news():\n",
        "#     model = AutoModelForSequenceClassification.from_pretrained('danielhou13/longformer-finetuned-news-cogs402', num_labels = 2)\n",
        "#     return model\n",
        "\n",
        "# def get_news_dataset(dataset_type):\n",
        "#     max_length = 2048\n",
        "#     dataset = load_dataset(\"danielhou13/cogs402dataset2\")[dataset_type]\n",
        "\n",
        "#     tokenizer = AutoTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "#     dataset = dataset.map(lambda x: preprocess_function(tokenizer, x, max_length), batched=True)\n",
        "\n",
        "#     labels = map(int, dataset['hyperpartisan'])\n",
        "#     print(type(dataset['hyperpartisan']))\n",
        "#     labels = list(labels)\n",
        "#     dataset = dataset.add_column(\"labels\", labels)\n",
        "\n",
        "#     dataset = dataset.remove_columns(['title', 'hyperpartisan', 'url', 'published_at', 'bias'])\n",
        "#     print(dataset)\n",
        "#     setattr(dataset, 'input_columns', ['input_ids', 'attention_mask'])\n",
        "#     setattr(dataset, 'target_columns', ['labels'])\n",
        "#     setattr(dataset, 'max_length', max_length)\n",
        "#     setattr(dataset, 'tokenizer', tokenizer)\n",
        "#     return dataset\n",
        "\n",
        "# def news_train_set():\n",
        "#     return get_news_dataset('train')\n",
        "\n",
        "# def news_test_set():\n",
        "#     return get_news_dataset('validation')"
      ],
      "metadata": {
        "id": "gEI0AFC5-0qA"
      },
      "id": "gEI0AFC5-0qA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load papers model and dataset and preprocess it"
      ],
      "metadata": {
        "id": "srzj_2BeNGOK"
      },
      "id": "srzj_2BeNGOK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24ad54a3-db97-47e3-8cc7-417d4db2c99b",
      "metadata": {
        "id": "24ad54a3-db97-47e3-8cc7-417d4db2c99b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "b5843f6f51414f11ae0fba93e05e6838",
            "3011ced5337d4f21b3064d9cd5f78c82",
            "0ecf4fe838ab46648981646673e15c37",
            "054cc43ef0f14cc2b88f4918705c8ef0",
            "17aeb2d7f36d4141a9dcd2ad00d12730",
            "5bf49a5fdfae4a52a7ab8bede04ce969",
            "174e3b2c34754b19b82b67586e56c600",
            "fad354d7636a4219b39c1d94daef2282",
            "debecac92d2e4509bd6b0c0de0028e00",
            "a0392166405845eba7d84bfc0fce45af",
            "99245def01d74af7bccaaa9ac9411e9b",
            "a03392e53f9b4445a0aa987a6ce26960",
            "554f420e9ac04340b0cc30f2aa0296d4",
            "4bc9f965f829478db5427f82f168b0fc",
            "25d3a7a6bc7b405d8430fe4d54a10aca",
            "43f90d8fdc2948dbaf63f07781212752",
            "b7611b5b75ff4a8abb40fdf13fb4d0a2",
            "48ca80c428e547eab9b2fd93e76f6329",
            "1e4e2a93724c4c27a7349b013b2f4b17",
            "7f4f2c42272d41c496c6d8b94b4038cc",
            "b2da41a572b84b06b80c0a79c85d6e7e",
            "af02e0d2e9b144448e9bd8faac4b212e"
          ]
        },
        "outputId": "d2d51a4a-5dbf-45b0-9d4e-be50fdb93e5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration danielhou13--cogs402dataset-144b958ac1a53abb\n",
            "Reusing dataset parquet (/root/.cache/huggingface/datasets/danielhou13___parquet/danielhou13--cogs402dataset-144b958ac1a53abb/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5843f6f51414f11ae0fba93e05e6838"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Parameter 'function'=<function get_papers_dataset.<locals>.<lambda> at 0x7fcb7be84050> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a03392e53f9b4445a0aa987a6ce26960"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['input_ids', 'attention_mask', 'labels']\n"
          ]
        }
      ],
      "source": [
        "cogs402_test = papers_test_set()\n",
        "model = longformer_finetuned_papers()\n",
        "columns = cogs402_test.input_columns + cogs402_test.target_columns\n",
        "print(columns)\n",
        "cogs402_test.set_format(type='torch', columns=columns)\n",
        "cogs402_test=cogs402_test.remove_columns(['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load news model and dataset and preprocess it"
      ],
      "metadata": {
        "id": "22BIYrX8NOVC"
      },
      "id": "22BIYrX8NOVC"
    },
    {
      "cell_type": "code",
      "source": [
        "# cogs402_test = news_test_set()\n",
        "# model = longformer_finetuned_news()\n",
        "# columns = cogs402_test.input_columns + cogs402_test.target_columns\n",
        "# print(columns)\n",
        "# cogs402_test.set_format(type='torch', columns=columns)"
      ],
      "metadata": {
        "id": "xh-YZZyo_eZx"
      },
      "id": "xh-YZZyo_eZx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get attention output for example"
      ],
      "metadata": {
        "id": "Sxd71xm3nWXj"
      },
      "id": "Sxd71xm3nWXj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Don't forget to allow your model to use your GPU for faster performance."
      ],
      "metadata": {
        "id": "QXqrucXRuJ3I"
      },
      "id": "QXqrucXRuJ3I"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deaabfa2-0855-41fd-870c-7a8b91e32d44",
      "metadata": {
        "id": "deaabfa2-0855-41fd-870c-7a8b91e32d44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd77fbbb-e48c-4fd3-fe49-4f354f197b6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "print(model.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can select any example in your dataset, perferably one where you know it is interesting (like a false negative, a false positive or something that you found from a different part of your project)."
      ],
      "metadata": {
        "id": "89mQ9IyUuQkl"
      },
      "id": "89mQ9IyUuQkl"
    },
    {
      "cell_type": "code",
      "source": [
        "test_val = [976]\n",
        "print(test_val)\n",
        "testexam = cogs402_test[test_val]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnXxTGhFqYG5",
        "outputId": "93da1d2d-8d62-4ed3-f68c-1c07845d6e45"
      },
      "id": "XnXxTGhFqYG5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[976]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We stack the attention results into a tensor. The shape of the tensors are (layer, batch, head, seq_len, x + attention_window + 1) for the sliding attention and (layer, batch, head, seq_len, seq_len) for the global attention. "
      ],
      "metadata": {
        "id": "V2qcIQ6vud3Q"
      },
      "id": "V2qcIQ6vud3Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04c5bcaf-5fe3-4813-8444-5cfb2c63a92b",
      "metadata": {
        "id": "04c5bcaf-5fe3-4813-8444-5cfb2c63a92b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3776c9fb-d26b-47c4-80b3-db74a12a267b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output_attention.shape torch.Size([12, 1, 12, 2048, 514])\n",
            "gl_output_attention.shape torch.Size([12, 1, 12, 2048, 1])\n"
          ]
        }
      ],
      "source": [
        "output = model(testexam[\"input_ids\"].cuda(), attention_mask=testexam['attention_mask'].cuda(), labels=testexam['labels'].cuda(), output_attentions = True)\n",
        "batch_attn = output[-2]\n",
        "output_attentions = torch.stack(batch_attn).cpu()\n",
        "global_attention = output[-1]\n",
        "output_global_attentions = torch.stack(global_attention).cpu()\n",
        "print(\"output_attention.shape\", output_attentions.shape)\n",
        "print(\"gl_output_attention.shape\", output_global_attentions.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(testexam['labels'][0])\n",
        "print(output[1].argmax())"
      ],
      "metadata": {
        "id": "SO4yNy98t_UP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21014437-a04b-4be3-dbf2-43d6b8197abf"
      },
      "id": "SO4yNy98t_UP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1)\n",
            "tensor(1, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2467c3d1-fe58-4e6d-aa98-534a6df72fcc",
      "metadata": {
        "id": "2467c3d1-fe58-4e6d-aa98-534a6df72fcc"
      },
      "outputs": [],
      "source": [
        "# print(os.getcwd())\n",
        "# yes = torch.load(\"resources/longformer_test2/epoch_3/aggregate_attn.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert sliding window attention to traditional format"
      ],
      "metadata": {
        "id": "soutFra9pAsZ"
      },
      "id": "soutFra9pAsZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "A unique property of the longformer model is that the matrix output for the attention is not a seq_len x seq_len output. Each token can only attend to the preceeding w/2 tokens and the succeeding w/2 tokens, dictated by whatever you choose the model's attention window w to be. Another name for this is called the sliding window attention. Therefore, we need to convert sliding attention matrix to correct seq_len x seq_len matrix to remain consistent with other types of Transformer Neural Networks.\n",
        "\n",
        "To do so, we run the following 4 functinos. Our attentions will change from a tensor of shape (layer, batch, head, seq_len, x + attention_window + 1) to a tensor of shape (layer, batch, head, seq_len, seq_len). More information about the functions can be found [here](https://colab.research.google.com/drive/1Kxx26NtIlUzioRCHpsR8IbSz_DpRFxEZ)."
      ],
      "metadata": {
        "id": "OevnNprR67LK"
      },
      "id": "OevnNprR67LK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0882a3e5-1b0c-4319-92a3-92f5b516d854",
      "metadata": {
        "id": "0882a3e5-1b0c-4319-92a3-92f5b516d854"
      },
      "outputs": [],
      "source": [
        "def create_head_matrix(output_attentions, global_attentions):\n",
        "    new_attention_matrix = torch.zeros((output_attentions.shape[0], \n",
        "                                      output_attentions.shape[0]))\n",
        "    for i in range(output_attentions.shape[0]):\n",
        "        test_non_zeroes = torch.nonzero(output_attentions[i]).squeeze()\n",
        "        test2 = output_attentions[i][test_non_zeroes[1:]]\n",
        "        new_attention_matrix_indices = test_non_zeroes[1:]-257 + i\n",
        "        new_attention_matrix[i][new_attention_matrix_indices] = test2\n",
        "        new_attention_matrix[i][0] = output_attentions[i][0]\n",
        "        new_attention_matrix[0] = global_attentions.squeeze()[:output_attentions.shape[0]]\n",
        "    return new_attention_matrix\n",
        "\n",
        "\n",
        "def attentions_all_heads(output_attentions, global_attentions):\n",
        "    new_matrix = []\n",
        "    for i in range(output_attentions.shape[0]):\n",
        "        matrix = create_head_matrix(output_attentions[i], global_attentions[i])\n",
        "        new_matrix.append(matrix)\n",
        "    return torch.stack(new_matrix)\n",
        "\n",
        "def all_batches(output_attentions, global_attentions):\n",
        "    new_matrix = []\n",
        "    for i in range(output_attentions.shape[0]):\n",
        "        matrix = attentions_all_heads(output_attentions[i], global_attentions[i])\n",
        "        new_matrix.append(matrix)\n",
        "    return torch.stack(new_matrix)\n",
        "\n",
        "def all_layers(output_attentions, global_attentions):\n",
        "    new_matrix = []\n",
        "    for i in range(output_attentions.shape[0]):\n",
        "        matrix = all_batches(output_attentions[i], global_attentions[i])\n",
        "        new_matrix.append(matrix)\n",
        "    return torch.stack(new_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converted_mat = all_layers(output_attentions, output_global_attentions).detach().cpu().numpy()\n",
        "print(converted_mat.shape)"
      ],
      "metadata": {
        "id": "IpdfMEMAuvyR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e50e34e-99f2-4a72-9ad7-dea3e49158be"
      },
      "id": "IpdfMEMAuvyR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12, 1, 12, 2048, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(testexam['input_ids'])"
      ],
      "metadata": {
        "id": "SIwlL_rUIlO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "374db459-f08f-4d98-e23d-c9e733babe62"
      },
      "id": "SIwlL_rUIlO3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0, 29642,    25,  ...,  3156,     6,     2]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not all heads have the same impact on the final output. Some heads may be more important than others so we scale each attention matrix by their respective head and layer. The notebook used to get head importance is [here](https://colab.research.google.com/drive/1O4QCi8ewBp7asegKqySRflTQZ9HeH8mQ?usp=sharing)."
      ],
      "metadata": {
        "id": "P-nS_AHa7Hv6"
      },
      "id": "P-nS_AHa7Hv6"
    },
    {
      "cell_type": "code",
      "source": [
        "head_importance = torch.load(\"/content/drive/MyDrive/cogs402longformer/t3-visapplication/resources/papers/pretrained/head_importance.pt\")\n",
        "# head_importance = torch.load(\"/content/drive/MyDrive/cogs402longformer/t3-visapplication/resources/news/head_importance.pt\")"
      ],
      "metadata": {
        "id": "UsAznmcDyBgR"
      },
      "id": "UsAznmcDyBgR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_by_importance(attention_matrix, head_importance):\n",
        "  new_matrix = np.zeros_like(attention_matrix)\n",
        "  for i in range(attention_matrix.shape[0]):\n",
        "    head_importance_layer = head_importance[i]\n",
        "    for j in range(attention_matrix.shape[1]):\n",
        "      new_matrix[i,j] = attention_matrix[i,j] * np.expand_dims(head_importance_layer, axis=(1,2))\n",
        "  return new_matrix"
      ],
      "metadata": {
        "id": "_HFs_vLw0230"
      },
      "id": "_HFs_vLw0230",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converted_mat_importance = scale_by_importance(converted_mat, head_importance)"
      ],
      "metadata": {
        "id": "XUcjPfxeHbqT"
      },
      "id": "XUcjPfxeHbqT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assess Attention Matrix"
      ],
      "metadata": {
        "id": "hYYuWzo2pEdl"
      },
      "id": "hYYuWzo2pEdl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Every token's top attended"
      ],
      "metadata": {
        "id": "drU1Kb4UpPgV"
      },
      "id": "drU1Kb4UpPgV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets suppose we want the topk attended tokens for each token in each head, batch and layer. In other words, we want to know which tokens each token attends TO the most. We first need to grab the list of all tokens in our example from our input_ids as we need to display what the actual tokens are."
      ],
      "metadata": {
        "id": "HkJ9FwzyBgyA"
      },
      "id": "HkJ9FwzyBgyA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following three functions serve to get us our top k attented tokens for each token in our attention matrix. \n",
        "\n",
        "`find_top_attention_unsummed` takes the full attention matrix (layer, batch, head, seq_len, seq_len) obtains the top k values for each token for every head,batch, and layer. Along with the values, it also returns the positions of each of the values so we know what token each value returned corresponds to. In other words, for every layer, for every item in the batch, for every head, it tells us for each token, what the top k tokens it attends to are. The output of the function are two matrices of shape (layer, batch, head, seq_len, k).\n",
        "\n",
        "`get_tokens` takes in three inputs: a matrix of indices with shape (layer, batch, head, seq_len, k), the tensor of input_ids used for prediction, and an example number, and finds the associated token at each index stored in the input matrix. The example number serves only to select an example from the batch. If we do not pass in an example as an input, we will iterate over all of the batches. The output of the function is an array of shape (layer, batch, head, seq_len, k), where each item is a token from their respective example.\n",
        "\n",
        "`highest_attended_tokens` takes in 5 inputs. It takes in a matrix of indicies, matrix of values, matrix of tokens, all with shape (layer, batch, head, seq_len, k), the tensor of input_ids used for prediction, and an example number. The example number again serves only to pick an example from the batch and if not used, will iterate over all batches. We use these matrices to create a Pandas Dataframe, where each row of the dataframe contains the current token, the position of the current token, the attended token, the position of the attended token, the attended value, the rank of the attended token w.r.t the current token, the layer, the head and the batch. "
      ],
      "metadata": {
        "id": "BX9jj2qIv8vK"
      },
      "id": "BX9jj2qIv8vK"
    },
    {
      "cell_type": "code",
      "source": [
        "# get the top k and indexes and values for each row\n",
        "def find_top_attention_unsummed(scores_mat, k):\n",
        "  indices = scores_mat.argsort(axis=4)[:, :, :, :, :-(k+1):-1]\n",
        "  vals = np.take_along_axis(scores_mat, indices, axis=4)  \n",
        "  return indices, vals\n",
        "\n",
        "#find the tokens using the index matrix and the all_tokens list to create a \n",
        "#matrix of tokens \n",
        "def get_tokens(index_matrix, example_ids, example=None):\n",
        "  \n",
        "  # Make sure our example is not out of range.\n",
        "  assert example < index_matrix.shape[1]\n",
        "\n",
        "  highest_tokens = []\n",
        "  #layer\n",
        "  for i in range(index_matrix.shape[0]):\n",
        "    row_tokens = []\n",
        "    #batch\n",
        "    for j in range(index_matrix.shape[1]):\n",
        "      batch_tokens = []\n",
        "\n",
        "      if (example is not None) and (j != example):\n",
        "        continue\n",
        "\n",
        "      all_tokens = tokenizer.convert_ids_to_tokens(example_ids[j])\n",
        "\n",
        "      #head\n",
        "      for k in range(index_matrix.shape[2]):\n",
        "        head_tokens = []\n",
        "\n",
        "        #token\n",
        "        for x in range(index_matrix.shape[3]):\n",
        "          tokens = [all_tokens[idx] for idx in index_matrix[i,j,k,x]]\n",
        "          head_tokens.append(tokens)\n",
        "        batch_tokens.append(head_tokens)\n",
        "      row_tokens.append(batch_tokens)\n",
        "    highest_tokens.append(row_tokens)\n",
        "  return np.array(highest_tokens)\n",
        "\n",
        "#format into a dataframe\n",
        "def highest_attended_tokens(index, values, tokens, example_ids, example=None):\n",
        "    dataframe=[]\n",
        "    for i in range(index.shape[0]):\n",
        "      for j in range(index.shape[1]):\n",
        "\n",
        "        if (example is not None) and (j != example):\n",
        "          continue\n",
        "\n",
        "        all_tokens = tokenizer.convert_ids_to_tokens(example_ids[j])\n",
        "\n",
        "        for k in range(index.shape[2]):\n",
        "          for x in range(index.shape[3]):\n",
        "            for y in range(index.shape[4]):\n",
        "              d = {\"token\":all_tokens[x], 'self_position':x, \n",
        "                  \"attended_token\": tokens[i,j,k,x,y],\n",
        "                  'token_position':index[i,j,k,x,y], \n",
        "                  'attention_scores':values[i,j,k,x,y],\n",
        "                  'layer':(i+1), 'head':(k+1),\n",
        "                  'rank':(y+1),\n",
        "                  'batch':j}\n",
        "              dataframe.append(d)\n",
        "    df = pd.DataFrame(dataframe)\n",
        "    return df"
      ],
      "metadata": {
        "id": "cO9aWGYxCNzu"
      },
      "id": "cO9aWGYxCNzu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combine the previous functions\n",
        "def highest_tokens(matrix, k, example_ids, example=None):\n",
        "  index, values = find_top_attention_unsummed(matrix, k)\n",
        "  highest_tokens = get_tokens(index, example_ids, example)\n",
        "  df = highest_attended_tokens(index, values, highest_tokens, example_ids, example)\n",
        "  return df"
      ],
      "metadata": {
        "id": "-TfHlPuAFALd"
      },
      "id": "-TfHlPuAFALd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus, for every token, we can get the top k tokens that this token attends to. Since it is a Dataframe, we can filter by batch, layer, head, rank, position, etc.,. The downsides are that its not very visually appealing despite being organized."
      ],
      "metadata": {
        "id": "vnhqif_VUqgU"
      },
      "id": "vnhqif_VUqgU"
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = highest_tokens(converted_mat_importance, 10, testexam[\"input_ids\"], 0)\n",
        "df2"
      ],
      "metadata": {
        "id": "5Pl_PhUcFVOb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "bbafc301-b1b9-411c-9c7f-fccf8be45831"
      },
      "id": "5Pl_PhUcFVOb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        token  self_position attended_token  token_position  attention_scores  \\\n",
              "0         <s>              0            <s>               0          0.001840   \n",
              "1         <s>              0              -             512          0.000818   \n",
              "2         <s>              0             Ġa            1536          0.000718   \n",
              "3         <s>              0         Ġimage            1024          0.000706   \n",
              "4         <s>              0       Ġcaption            1309          0.000064   \n",
              "...       ...            ...            ...             ...               ...   \n",
              "2949115  </s>           2047              .            2006          0.000011   \n",
              "2949116  </s>           2047        Ġlearns            1993          0.000011   \n",
              "2949117  </s>           2047              .            1792          0.000011   \n",
              "2949118  </s>           2047              .            1909          0.000011   \n",
              "2949119  </s>           2047              .            1892          0.000011   \n",
              "\n",
              "         layer  head  rank  batch  \n",
              "0            1     1     1      0  \n",
              "1            1     1     2      0  \n",
              "2            1     1     3      0  \n",
              "3            1     1     4      0  \n",
              "4            1     1     5      0  \n",
              "...        ...   ...   ...    ...  \n",
              "2949115     12    12     6      0  \n",
              "2949116     12    12     7      0  \n",
              "2949117     12    12     8      0  \n",
              "2949118     12    12     9      0  \n",
              "2949119     12    12    10      0  \n",
              "\n",
              "[2949120 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ce73290-6aef-4e34-8e78-367701e59b88\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>self_position</th>\n",
              "      <th>attended_token</th>\n",
              "      <th>token_position</th>\n",
              "      <th>attention_scores</th>\n",
              "      <th>layer</th>\n",
              "      <th>head</th>\n",
              "      <th>rank</th>\n",
              "      <th>batch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>0.001840</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "      <td>512</td>\n",
              "      <td>0.000818</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>Ġa</td>\n",
              "      <td>1536</td>\n",
              "      <td>0.000718</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>Ġimage</td>\n",
              "      <td>1024</td>\n",
              "      <td>0.000706</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>Ġcaption</td>\n",
              "      <td>1309</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2949115</th>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "      <td>2047</td>\n",
              "      <td>.</td>\n",
              "      <td>2006</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2949116</th>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "      <td>2047</td>\n",
              "      <td>Ġlearns</td>\n",
              "      <td>1993</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2949117</th>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "      <td>2047</td>\n",
              "      <td>.</td>\n",
              "      <td>1792</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2949118</th>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "      <td>2047</td>\n",
              "      <td>.</td>\n",
              "      <td>1909</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2949119</th>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "      <td>2047</td>\n",
              "      <td>.</td>\n",
              "      <td>1892</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2949120 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ce73290-6aef-4e34-8e78-367701e59b88')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ce73290-6aef-4e34-8e78-367701e59b88 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ce73290-6aef-4e34-8e78-367701e59b88');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Total attention for each word"
      ],
      "metadata": {
        "id": "SppU6voZpLiM"
      },
      "id": "SppU6voZpLiM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the sum of the attentions for all the tokens (column-wise). In other words, find out how much every word is attended to."
      ],
      "metadata": {
        "id": "u0ViKJAn7Ap0"
      },
      "id": "u0ViKJAn7Ap0"
    },
    {
      "cell_type": "code",
      "source": [
        "attention_matrix_importance = converted_mat_importance.sum(axis=3)\n",
        "print(attention_matrix_importance.shape)"
      ],
      "metadata": {
        "id": "EhMNdupbxFrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "921d27ef-3340-40f8-dcdc-4e5dbbc820b3"
      },
      "id": "EhMNdupbxFrx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12, 1, 12, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PDF view"
      ],
      "metadata": {
        "id": "kqgAjuIwph32"
      },
      "id": "kqgAjuIwph32"
    },
    {
      "cell_type": "markdown",
      "source": [
        "A dataframe is good for picking out information from the example, but it isn't the best being a easy to read visualization. Its easier to see how much each word is attended to in an example if we have the actual example, with the words highlighted based on the magnitude of attention.\n",
        "\n",
        "We use https://github.com/jiesutd/Text-Attention-Heatmap-Visualization to show how much each token in the example is attended to, up to the max number of tokens we specified earlier.\n",
        "\n",
        "In short, these functions iterate over the list of attentions and tokens, cleans the tokens to remove special characters, and normalizes the data if you wish for it to.\n",
        "\n",
        "This notebook serves to explore one specific example in detail. If you wish to play around and/or convert multiple examples into PDFs, I recommend going to this [notebook](https://colab.research.google.com/drive/1Gyxj9rP2KnnCzit9zN3h3MeTTiQ13R7B?usp=sharing)"
      ],
      "metadata": {
        "id": "DjTu0_guLI1T"
      },
      "id": "DjTu0_guLI1T"
    },
    {
      "cell_type": "code",
      "source": [
        "## convert the text/attention list to latex code, which will further generates the text heatmap based on attention weights.\n",
        "import numpy as np\n",
        "\n",
        "latex_special_token = [\"!@#$%^&*(){}\"]\n",
        "\n",
        "def generate(text_list, attention_list, latex_file, color='red', rescale_value = True):\n",
        "\tassert(len(text_list) == len(attention_list))\n",
        "\tif rescale_value:\n",
        "\t\tattention_list = rescale(attention_list)\n",
        "\tword_num = len(text_list)\n",
        "\ttext_list = clean_word(text_list)\n",
        "\twith open(latex_file,'w') as f:\n",
        "\t\tf.write(r'''\\documentclass[varwidth]{standalone}\n",
        "\\special{papersize=210mm,297mm}\n",
        "\\usepackage{color}\n",
        "\\usepackage{tcolorbox}\n",
        "\\usepackage{CJK}\n",
        "\\usepackage{adjustbox}\n",
        "\\tcbset{width=0.9\\textwidth,boxrule=0pt,colback=red,arc=0pt,auto outer arc,left=0pt,right=0pt,boxsep=5pt}\n",
        "\\begin{document}\n",
        "\\begin{CJK*}{UTF8}{gbsn}'''+'\\n')\n",
        "\t\tstring = r'''{\\setlength{\\fboxsep}{0pt}\\colorbox{white!0}{\\parbox{0.9\\textwidth}{'''+\"\\n\"\n",
        "\t\tfor idx in range(word_num):\n",
        "\t\t\tstring += \"\\\\colorbox{%s!%s}{\"%(color, attention_list[idx])+\"\\\\strut \" + text_list[idx]+\"} \"\n",
        "\t\tstring += \"\\n}}}\"\n",
        "\t\tf.write(string+'\\n')\n",
        "\t\tf.write(r'''\\end{CJK*}\n",
        "\\end{document}''')\n",
        "\n",
        "def rescale(input_list):\n",
        "\tthe_array = np.asarray(input_list)\n",
        "\tthe_max = np.max(the_array)\n",
        "\tthe_min = np.min(the_array)\n",
        "\trescale = ((the_array - the_min)/(the_max-the_min))*100\n",
        "\treturn rescale.tolist()\n",
        "\n",
        "\n",
        "def clean_word(word_list):\n",
        "\tnew_word_list = []\n",
        "\tfor word in word_list:\n",
        "\t\tfor special_sensitive in [\"\\\\\", \"^\"]:\n",
        "\t\t\tif special_sensitive in word:\n",
        "\t\t\t\tword = word.replace(special_sensitive, '')\n",
        "\t\tfor latex_sensitive in [\"%\", \"&\", \"#\", \"_\",  \"{\", \"}\"]:\n",
        "\t\t\tif latex_sensitive in word:\n",
        "\t\t\t\tword = word.replace(latex_sensitive, '\\\\' +latex_sensitive)\n",
        "\t\tnew_word_list.append(word)\n",
        "\treturn new_word_list"
      ],
      "metadata": {
        "id": "FCsAm5i3jmKA"
      },
      "id": "FCsAm5i3jmKA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens2 = tokenizer.convert_ids_to_tokens(testexam[\"input_ids\"][0])"
      ],
      "metadata": {
        "id": "N-Wr_p4LsTv-"
      },
      "id": "N-Wr_p4LsTv-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change \"papers\" in the following to news/whatever alternative dataset if you change the dataset used"
      ],
      "metadata": {
        "id": "f2EysmpsD0ms"
      },
      "id": "f2EysmpsD0ms"
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_tokens2)\n",
        "average_attention = attention_matrix_importance.squeeze().sum(axis=1)\n",
        "average_attention = average_attention.sum(axis=0)"
      ],
      "metadata": {
        "id": "goaO9arYjopz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d0dcbde-542a-40a1-be08-0e25b2134817"
      },
      "id": "goaO9arYjopz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', 'Published', 'Ġas', 'Ġa', 'Ġconference', 'Ġpaper', 'Ġin', 'ĠInternational', 'ĠConference', 'Ġof', 'ĠComputer', 'ĠVision', 'Ġ(', 'IC', 'CV', ')', 'Ġ2017', 'Ġ', 'ĠSpeaking', 'Ġthe', 'ĠSame', 'ĠLanguage', ':', 'ĠMatch', 'ing', 'ĠMachine', 'Ġto', 'ĠHuman', 'ĠCapt', 'ions', 'Ġby', 'ĠAd', 'vers', 'arial', 'ĠTraining', 'ĠRak', 'sh', 'ith', 'ĠShe', 'tty', '1', 'Ġ', 'ĠMarcus', 'ĠRoh', 'r', 'bach', '2', ',', '3', 'Ġ', 'Ġar', 'X', 'iv', ':', '17', '03', '.', '10', '476', 'v', '2', 'Ġ[', 'cs', '.', 'CV', ']', 'Ġ6', 'ĠNov', 'Ġ2017', 'Ġ', 'ĠMario', 'ĠFritz', '1', 'Ġ1', 'Ġ', 'ĠLisa', 'ĠAnne', 'ĠHendricks', '2', 'Ġ', 'ĠBer', 'nt', 'ĠS', 'chie', 'le', '1', 'Ġ', 'ĠMax', 'ĠPlan', 'ck', 'ĠInstitute', 'Ġfor', 'ĠIn', 'format', 'ics', ',', 'ĠSa', 'ar', 'land', 'ĠIn', 'format', 'ics', 'ĠCampus', ',', 'ĠSa', 'arb', 'ru', 'Ì', 'Ī', 'ck', 'en', ',', 'ĠGermany', 'Ġ2', 'Ġ3', 'ĠUC', 'ĠBerkeley', 'ĠE', 'EC', 'S', ',', 'ĠCA', ',', 'ĠUnited', 'ĠStates', 'ĠFacebook', 'ĠAI', 'ĠResearch', 'Ġ', 'ĠAbstract', 'ĠWhile', 'Ġstrong', 'Ġprogress', 'Ġhas', 'Ġbeen', 'Ġmade', 'Ġin', 'Ġimage', 'Ġcaption', 'ing', 'Ġrecently', ',', 'Ġmachine', 'Ġand', 'Ġhuman', 'Ġcapt', 'ions', 'Ġare', 'Ġstill', 'Ġquite', 'Ġdistinct', '.', 'ĠThis', 'Ġis', 'Ġprimarily', 'Ġdue', 'Ġto', 'Ġthe', 'Ġdeficiencies', 'Ġin', 'Ġthe', 'Ġgenerated', 'Ġword', 'Ġdistribution', ',', 'Ġvocabulary', 'Ġsize', ',', 'Ġand', 'Ġstrong', 'Ġbias', 'Ġin', 'Ġthe', 'Ġgenerators', 'Ġtowards', 'Ġfrequent', 'Ġcapt', 'ions', '.', 'ĠFurthermore', ',', 'Ġhumans', 'ĠâĢĵ', 'Ġrightfully', 'Ġso', 'ĠâĢĵ', 'Ġgenerate', 'Ġmultiple', ',', 'Ġdiverse', 'Ġcapt', 'ions', ',', 'Ġdue', 'Ġto', 'Ġthe', 'Ġinherent', 'Ġambiguity', 'Ġin', 'Ġthe', 'Ġcaption', 'ing', 'Ġtask', 'Ġwhich', 'Ġis', 'Ġnot', 'Ġexplicitly', 'Ġconsidered', 'Ġin', 'Ġtoday', 'âĢ', 'Ļ', 's', 'Ġsystems', '.', 'ĠTo', 'Ġaddress', 'Ġthese', 'Ġchallenges', ',', 'Ġwe', 'Ġchange', 'Ġthe', 'Ġtraining', 'Ġobjective', 'Ġof', 'Ġthe', 'Ġcaption', 'Ġgenerator', 'Ġfrom', 'Ġreprodu', 'cing', 'Ġground', 'truth', 'Ġcapt', 'ions', 'Ġto', 'Ġgenerating', 'Ġa', 'Ġset', 'Ġof', 'Ġcapt', 'ions', 'Ġthat', 'Ġis', 'Ġindistinguishable', 'Ġfrom', 'Ġhuman', 'Ġwritten', 'Ġcapt', 'ions', '.', 'ĠInstead', 'Ġof', 'Ġhand', 'craft', 'ing', 'Ġsuch', 'Ġa', 'Ġlearning', 'Ġtarget', ',', 'Ġwe', 'Ġemploy', 'Ġadvers', 'arial', 'Ġtraining', 'Ġin', 'Ġcombination', 'Ġwith', 'Ġan', 'Ġapproximate', 'ĠG', 'umb', 'el', 'Ġsam', 'pler', 'Ġto', 'Ġimplicitly', 'Ġmatch', 'Ġthe', 'Ġgenerated', 'Ġdistribution', 'Ġto', 'Ġthe', 'Ġhuman', 'Ġone', '.', 'ĠWhile', 'Ġour', 'Ġmethod', 'Ġachieves', 'Ġcomparable', 'Ġperformance', 'Ġto', 'Ġthe', 'Ġstate', '-', 'of', '-', 'the', '-', 'art', 'Ġin', 'Ġterms', 'Ġof', 'Ġthe', 'Ġcorrectness', 'Ġof', 'Ġthe', 'Ġcapt', 'ions', ',', 'Ġwe', 'Ġgenerate', 'Ġa', 'Ġset', 'Ġof', 'Ġdiverse', 'Ġcapt', 'ions', 'Ġthat', 'Ġare', 'Ġsignificantly', 'Ġless', 'Ġbiased', 'Ġand', 'Ġbetter', 'Ġmatch', 'Ġthe', 'Ġglobal', 'Ġun', 'i', '-,', 'Ġbi', '-', 'Ġand', 'Ġtri', '-', 'gram', 'Ġdistributions', 'Ġof', 'Ġthe', 'Ġhuman', 'Ġcapt', 'ions', '.', 'Ġ', 'ĠO', 'urs', ':', 'Ġa', 'Ġperson', 'Ġon', 'Ġsk', 'is', 'Ġjumping', 'Ġover', 'Ġa', 'Ġramp', 'Ġ', 'ĠO', 'urs', ':', 'Ġa', 'Ġsk', 'ier', 'Ġis', 'Ġmaking', 'Ġa', 'Ġturn', 'Ġon', 'Ġa', 'Ġcourse', 'Ġ', 'ĠO', 'urs', ':', 'Ġa', 'Ġcross', 'Ġcountry', 'Ġsk', 'ier', 'Ġmakes', 'Ġhis', 'Ġway', 'Ġthrough', 'Ġthe', 'Ġsnow', 'Ġ', 'ĠO', 'urs', ':', 'Ġa', 'Ġsk', 'ier', 'Ġis', 'Ġheaded', 'Ġdown', 'Ġa', 'Ġsteep', 'Ġslope', 'Ġ', 'ĠBas', 'eline', ':', 'Ġa', 'Ġman', 'Ġriding', 'Ġsk', 'is', 'Ġdown', 'Ġa', 'Ġsnow', 'Ġcovered', 'Ġslope', 'Ġ', 'ĠFigure', 'Ġ1', ':', 'ĠFour', 'Ġimages', 'Ġfrom', 'Ġthe', 'Ġtest', 'Ġset', ',', 'Ġall', 'Ġrelated', 'Ġto', 'Ġskiing', ',', 'Ġshown', 'Ġwith', 'Ġcapt', 'ions', 'Ġfrom', 'Ġour', 'Ġadvers', 'arial', 'Ġmodel', 'Ġand', 'Ġa', 'Ġbaseline', '.', 'ĠBas', 'eline', 'Ġmodel', 'Ġdescribes', 'Ġall', 'Ġfour', 'Ġimages', 'Ġwith', 'Ġone', 'Ġgeneric', 'Ġcaption', ',', 'Ġwhereas', 'Ġour', 'Ġmodel', 'Ġproduces', 'Ġdiverse', 'Ġand', 'Ġmore', 'Ġimage', 'Ġspecific', 'Ġcapt', 'ions', '.', 'ĠAs', 'Ġwe', 'Ġanalyze', 'Ġin', 'Ġthis', 'Ġpaper', ',', 'Ġthis', 'Ġis', 'Ġlikely', 'Ġdue', 'Ġto', 'Ġartifacts', 'Ġand', 'Ġdeficiencies', 'Ġin', 'Ġthe', 'Ġstatistics', 'Ġof', 'Ġthe', 'Ġgenerated', 'Ġcapt', 'ions', ',', 'Ġwhich', 'Ġis', 'Ġmore', 'Ġapparent', 'Ġwhen', 'Ġobserving', 'Ġmultiple', 'Ġsamples', '.', 'ĠSpecifically', ',', 'Ġwe', 'Ġobserve', 'Ġthat', 'Ġstate', '-', 'of', '-', 'the', '-', 'art', 'Ġsystems', 'Ġfrequently', 'ĠâĢ', 'ľ', 'reve', 'al', 'Ġthemselves', 'âĢ', 'Ŀ', 'Ġby', 'Ġgenerating', 'Ġa', 'Ġdifferent', 'Ġword', 'Ġdistribution', 'Ġand', 'Ġusing', 'Ġsmaller', 'Ġvocabulary', '.', 'ĠFurther', 'Ġscrutiny', 'Ġreveals', 'Ġthat', 'Ġgeneral', 'ization', 'Ġfrom', 'Ġthe', 'Ġtraining', 'Ġset', 'Ġis', 'Ġstill', 'Ġchallenging', 'Ġand', 'Ġgeneration', 'Ġis', 'Ġbiased', 'Ġto', 'Ġfrequent', 'Ġfragments', 'Ġand', 'Ġcapt', 'ions', '.', 'ĠAlso', ',', 'Ġtoday', 'âĢ', 'Ļ', 's', 'Ġsystems', 'Ġare', 'Ġevaluated', 'Ġto', 'Ġproduce', 'Ġa', 'Ġsingle', 'Ġcaption', '.', 'ĠYet', ',', 'Ġmultiple', 'Ġpotentially', 'Ġdistinct', 'Ġcapt', 'ions', 'Ġare', 'Ġtypically', 'Ġcorrect', 'Ġfor', 'Ġa', 'Ġsingle', 'Ġimage', 'ĠâĢĵ', 'Ġa', 'Ġproperty', 'Ġthat', 'Ġis', 'Ġreflected', 'Ġin', 'Ġhuman', 'Ġground', '-', 'truth', '.', 'ĠThis', 'Ġdiversity', 'Ġis', 'Ġnot', 'Ġequally', 'Ġreproduced', 'Ġby', 'Ġstate', '-', 'of', '-', 'the', '-', 'art', 'Ġcaption', 'Ġgenerators', 'Ġ[', '40', ',', 'Ġ23', '].', 'ĠTherefore', ',', 'Ġour', 'Ġgoal', 'Ġis', 'Ġto', 'Ġmake', 'Ġimage', 'Ġcapt', 'ions', 'Ġless', 'Ġdistinguish', 'able', 'Ġfrom', 'Ġhuman', 'Ġones', 'ĠâĢĵ', 'Ġsimilar', 'Ġin', 'Ġthe', 'Ġspirit', 'Ġto', 'Ġa', 'ĠTuring', 'Ġ', 'Ġ1', '.', 'ĠIntroduction', 'ĠImage', 'Ġcaption', 'ing', 'Ġsystems', 'Ġhave', 'Ġa', 'Ġvariety', 'Ġof', 'Ġapplications', 'Ġranging', 'Ġfrom', 'Ġmedia', 'Ġretrieval', 'Ġand', 'Ġtagging', 'Ġto', 'Ġassistance', 'Ġfor', 'Ġthe', 'Ġvisually', 'Ġimpaired', '.', 'ĠIn', 'Ġparticular', ',', 'Ġmodels', 'Ġwhich', 'Ġcombine', 'Ġstate', '-', 'of', '-', 'the', '-', 'art', 'Ġimage', 'Ġrepresentations', 'Ġbased', 'Ġon', 'Ġdeep', 'Ġconv', 'olution', 'al', 'Ġnetworks', 'Ġand', 'Ġdeep', 'Ġrecurrent', 'Ġlanguage', 'Ġmodels', 'Ġhave', 'Ġled', 'Ġto', 'Ġever', 'Ġincreasing', 'Ġperformance', 'Ġon', 'Ġevaluation', 'Ġmetrics', 'Ġsuch', 'Ġas', 'ĠC', 'ID', 'Er', 'Ġ[', '39', ']', 'Ġand', 'ĠMET', 'E', 'OR', 'Ġ[', '8', ']', 'Ġas', 'Ġcan', 'Ġbe', 'Ġseen', 'Ġe', '.', 'g', '.', 'Ġon', 'Ġthe', 'ĠC', 'OC', 'O', 'Ġimage', 'ĠCaption', 'Ġchallenge', 'Ġleader', 'board', 'Ġ[', '6', '].', 'ĠDespite', 'Ġthese', 'Ġadvances', ',', 'Ġit', 'Ġis', 'Ġoften', 'Ġeasy', 'Ġfor', 'Ġhumans', 'Ġto', 'Ġdifferentiate', 'Ġbetween', 'Ġmachine', 'Ġand', 'Ġhuman', 'Ġcapt', 'ions', 'ĠâĢĵ', 'Ġparticularly', 'Ġwhen', 'Ġobserving', 'Ġmultiple', 'Ġcapt', 'ions', 'Ġfor', 'Ġa', 'Ġsingle', 'Ġimage', '.', 'Ġ1', 'Ġ', 'Ġ', 'Č', '2', '.', 'ĠRelated', 'ĠWork', 'Ġ', 'Ġa', 'Ġbus', 'Ġthat', 'Ġhas', 'Ġpulled', 'Ġinto', 'Ġthe', 'Ġside', 'Ġof', 'Ġthe', 'Ġstreet', 'Ġa', 'Ġbus', 'Ġis', 'Ġparked', 'Ġat', 'Ġthe', 'Ġside', 'Ġof', 'Ġthe', 'Ġroad', 'Ġa', 'Ġwhite', 'Ġbus', 'Ġis', 'Ġparked', 'Ġnear', 'Ġa', 'Ġcurb', 'Ġwith', 'Ġpeople', 'Ġwalking', 'Ġby', 'Ġ', 'Ġa', 'Ġgroup', 'Ġof', 'Ġpeople', 'Ġstanding', 'Ġoutside', 'Ġin', 'Ġa', 'Ġold', 'Ġmuseum', 'Ġan', 'Ġairplane', 'Ġshow', 'Ġwhere', 'Ġpeople', 'Ġstand', 'Ġaround', 'Ġa', 'Ġline', 'Ġof', 'Ġplanes', 'Ġparked', 'Ġat', 'Ġan', 'Ġairport', 'Ġshow', 'Ġ', 'ĠBase', 'ĠâĢ¢', 'Ġa', 'Ġbus', 'Ġis', 'Ġparked', 'Ġon', 'Ġthe', 'Ġside', 'Ġof', 'Ġline', 'Ġthe', 'Ġroad', 'ĠâĢ¢', 'Ġa', 'Ġbus', 'Ġthat', 'Ġis', 'Ġparked', 'Ġin', 'Ġthe', 'Ġstreet', 'Ġa', 'Ġbus', 'Ġis', 'Ġparked', 'Ġin', 'Ġthe', 'Ġstreet', 'Ġnext', 'Ġto', 'Ġa', 'Ġbus', 'Ġ', 'Ġa', 'Ġgroup', 'Ġof', 'Ġpeople', 'Ġstanding', 'Ġaround', 'Ġa', 'Ġplane', 'Ġa', 'Ġgroup', 'Ġof', 'Ġpeople', 'Ġstanding', 'Ġaround', 'Ġa', 'Ġplane', 'Ġa', 'Ġgroup', 'Ġof', 'Ġpeople', 'Ġstanding', 'Ġaround', 'Ġa', 'Ġplane', 'Ġ', 'ĠO', 'urs', 'Ġ', 'ĠFigure', 'Ġ2', ':', 'ĠTwo', 'Ġexamples', 'Ġcomparing', 'Ġmultiple', 'Ġcapt', 'ions', 'Ġgenerated', 'Ġby', 'Ġour', 'Ġadvers', 'arial', 'Ġmodel', 'Ġand', 'Ġthe', 'Ġbaseline', '.', 'ĠBi', '-', 'gram', 's', 'Ġwhich', 'Ġare', 'Ġtop', '-', '20', 'Ġfrequent', 'Ġbi', '-', 'gram', 's', 'Ġin', 'Ġthe', 'Ġtraining', 'Ġset', 'Ġare', 'Ġmarked', 'Ġin', 'Ġred', 'Ġ(', 'e', '.', 'g', '.,', 'ĠâĢ', 'ľ', 'a', 'Ġgroup', 'âĢ', 'Ŀ', 'Ġand', 'ĠâĢ', 'ľ', 'group', 'Ġof', 'âĢ', 'Ŀ', ').', 'ĠCapt', 'ions', 'Ġwhich', 'Ġare', 'Ġrepl', 'icas', 'Ġfrom', 'Ġtraining', 'Ġset', 'Ġare', 'Ġmarked', 'Ġwith', 'ĠâĢ¢', 'Ġ.', 'ĠTest', '.', 'ĠWe', 'Ġalso', 'Ġembrace', 'Ġthe', 'Ġambiguity', 'Ġof', 'Ġthe', 'Ġtask', 'Ġand', 'Ġextend', 'Ġour', 'Ġinvestigation', 'Ġto', 'Ġpredicting', 'Ġsets', 'Ġof', 'Ġcapt', 'ions', 'Ġfor', 'Ġa', 'Ġsingle', 'Ġimage', 'Ġand', 'Ġevaluating', 'Ġtheir', 'Ġquality', ',', 'Ġparticularly', 'Ġin', 'Ġterms', 'Ġof', 'Ġthe', 'Ġdiversity', 'Ġin', 'Ġthe', 'Ġgenerated', 'Ġset', '.', 'ĠIn', 'Ġcontrast', ',', 'Ġpopular', 'Ġapproaches', 'Ġto', 'Ġimage', 'Ġcaption', 'ing', 'Ġare', 'Ġtrained', 'Ġwith', 'Ġan', 'Ġobjective', 'Ġto', 'Ġreproduce', 'Ġthe', 'Ġcapt', 'ions', 'Ġas', 'Ġprovided', 'Ġby', 'Ġthe', 'Ġground', '-', 'truth', '.', 'ĠInstead', 'Ġof', 'Ġrelying', 'Ġon', 'Ġhand', 'craft', 'ing', 'Ġloss', '-', 'fun', 'ctions', 'Ġto', 'Ġachieve', 'Ġour', 'Ġgoal', ',', 'Ġwe', 'Ġpropose', 'Ġan', 'Ġadvers', 'arial', 'Ġtraining', 'Ġmechanism', 'Ġfor', 'Ġimage', 'Ġcaption', 'ing', '.', 'ĠFor', 'Ġthis', 'Ġwe', 'Ġbuild', 'Ġon', 'ĠGener', 'ative', 'ĠAd', 'vers', 'arial', 'ĠNetworks', 'Ġ(', 'GAN', 's', ')', 'Ġ[', '14', '],', 'Ġwhich', 'Ġhave', 'Ġbeen', 'Ġsuccessfully', 'Ġused', 'Ġto', 'Ġgenerate', 'Ġmainly', 'Ġcontinuous', 'Ġdata', 'Ġdistributions', 'Ġsuch', 'Ġas', 'Ġimages', 'Ġ[', '9', ',', 'Ġ30', '],', 'Ġalthough', 'Ġexceptions', 'Ġexist', 'Ġ[', '27', '].', 'ĠIn', 'Ġcontrast', 'Ġto', 'Ġimages', ',', 'Ġcapt', 'ions', 'Ġare', 'Ġdiscrete', ',', 'Ġwhich', 'Ġposes', 'Ġa', 'Ġchallenge', 'Ġwhen', 'Ġtrying', 'Ġto', 'Ġback', 'prop', 'agate', 'Ġthrough', 'Ġthe', 'Ġgeneration', 'Ġstep', '.', 'ĠTo', 'Ġovercome', 'Ġthis', 'Ġobstacle', ',', 'Ġwe', 'Ġuse', 'Ġa', 'ĠG', 'umb', 'el', 'Ġsam', 'pler', 'Ġ[', '20', ',', 'Ġ28', ']', 'Ġthat', 'Ġallows', 'Ġfor', 'Ġend', '-', 'to', '-', 'end', 'Ġtraining', '.', 'ĠWe', 'Ġaddress', 'Ġthe', 'Ġproblem', 'Ġof', 'Ġcaption', 'Ġset', 'Ġgeneration', 'Ġfor', 'Ġimages', 'Ġand', 'Ġdiscuss', 'Ġmetrics', 'Ġto', 'Ġmeasure', 'Ġthe', 'Ġcaption', 'Ġdiversity', 'Ġand', 'Ġcompare', 'Ġit', 'Ġto', 'Ġhuman', 'Ġground', '-', 'truth', '.', 'ĠWe', 'Ġcontribute', 'Ġa', 'Ġnovel', 'Ġsolution', 'Ġto', 'Ġthis', 'Ġproblem', 'Ġusing', 'Ġan', 'Ġadvers', 'arial', 'Ġformulation', '.', 'ĠThe', 'Ġevaluation', 'Ġof', 'Ġour', 'Ġmodel', 'Ġshows', 'Ġthat', 'Ġaccuracy', 'Ġof', 'Ġgenerated', 'Ġcapt', 'ions', 'Ġis', 'Ġon', 'Ġpar', 'Ġto', 'Ġthe', 'Ġstate', '-', 'of', '-', 'the', '-', 'art', ',', 'Ġbut', 'Ġwe', 'Ġgreatly', 'Ġincrease', 'Ġthe', 'Ġdiversity', 'Ġof', 'Ġthe', 'Ġcaption', 'Ġsets', 'Ġand', 'Ġbetter', 'Ġmatch', 'Ġthe', 'Ġground', '-', 'truth', 'Ġstatistics', 'Ġin', 'Ġseveral', 'Ġmeasures', '.', 'ĠQual', 'itatively', ',', 'Ġour', 'Ġmodel', 'Ġproduces', 'Ġmore', 'Ġdiverse', 'Ġcapt', 'ions', 'Ġacross', 'Ġimages', 'Ġcontaining', 'Ġsimilar', 'Ġcontent', 'Ġ(', 'Figure', 'Ġ1', ')', 'Ġand', 'Ġwhen', 'Ġsampling', 'Ġmultiple', 'Ġcapt', 'ions', 'Ġfor', 'Ġan', 'Ġimage', 'Ġ(', 'see', 'Ġsupplementary', ')', '1', 'Ġ.', 'Ġ1', 'Ġhttps', '://', 'goo', '.', 'gl', '/', '3', 'y', 'R', 'V', 'n', 'q', 'Ġ', 'ĠImage', 'ĠDescription', '.', 'ĠEarly', 'Ġcaption', 'ing', 'Ġmodels', 'Ġrely', 'Ġon', 'Ġfirst', 'Ġrecognizing', 'Ġvisual', 'Ġelements', ',', 'Ġsuch', 'Ġas', 'Ġobjects', ',', 'Ġattributes', ',', 'Ġand', 'Ġactivities', ',', 'Ġand', 'Ġthen', 'Ġgenerating', 'Ġa', 'Ġsentence', 'Ġusing', 'Ġlanguage', 'Ġmodels', 'Ġsuch', 'Ġas', 'Ġa', 'Ġtemplate', 'Ġmodel', 'Ġ[', '13', '],', 'Ġn', '-', 'gram', 'Ġmodel', 'Ġ[', '22', '],', 'Ġor', 'Ġstatistical', 'Ġmachine', 'Ġtranslation', 'Ġ[', '34', '].', 'ĠAdv', 'ances', 'Ġin', 'Ġdeep', 'Ġlearning', 'Ġhave', 'Ġled', 'Ġto', 'Ġend', '-', 'to', '-', 'end', 'Ġtrain', 'able', 'Ġmodels', 'Ġthat', 'Ġcombine', 'Ġdeep', 'Ġconv', 'olution', 'al', 'Ġnetworks', 'Ġto', 'Ġextract', 'Ġvisual', 'Ġfeatures', 'Ġand', 'Ġrecurrent', 'Ġnetworks', 'Ġto', 'Ġgenerate', 'Ġsentences', 'Ġ[', '11', ',', 'Ġ41', ',', 'Ġ21', '].', 'ĠThough', 'Ġmodern', 'Ġdescription', 'Ġmodels', 'Ġare', 'Ġcapable', 'Ġof', 'Ġproducing', 'Ġcoherent', 'Ġsentences', 'Ġwhich', 'Ġaccurately', 'Ġdescribe', 'Ġan', 'Ġimage', ',', 'Ġthey', 'Ġtend', 'Ġto', 'Ġproduce', 'Ġgeneric', 'Ġsentences', 'Ġwhich', 'Ġare', 'Ġreplicated', 'Ġfrom', 'Ġthe', 'Ġtrain', 'Ġset', 'Ġ[', '10', '].', 'ĠFurthermore', ',', 'Ġan', 'Ġimage', 'Ġcan', 'Ġcorrespond', 'Ġto', 'Ġmany', 'Ġvalid', 'Ġdescriptions', '.', 'ĠHowever', ',', 'Ġat', 'Ġtest', 'Ġtime', ',', 'Ġsentences', 'Ġgenerated', 'Ġwith', 'Ġmethods', 'Ġsuch', 'Ġas', 'Ġbeam', 'Ġsearch', 'Ġare', 'Ġgenerally', 'Ġvery', 'Ġsimilar', '.', 'Ġ[', '40', ',', 'Ġ23', ']', 'Ġfocus', 'Ġon', 'Ġincreasing', 'Ġsentence', 'Ġdiversity', 'Ġby', 'Ġintegrating', 'Ġa', 'Ġdiversity', 'Ġpromoting', 'Ġhe', 'uristic', 'Ġinto', 'Ġbeam', 'Ġsearch', '.', 'Ġ[', '42', ']', 'Ġattempts', 'Ġto', 'Ġincrease', 'Ġthe', 'Ġdiversity', 'Ġin', 'Ġcaption', 'Ġgeneration', 'Ġby', 'Ġtraining', 'Ġan', 'Ġensemble', 'Ġof', 'Ġcaption', 'Ġgenerators', 'Ġeach', 'Ġspecializing', 'Ġin', 'Ġdifferent', 'Ġportions', 'Ġof', 'Ġthe', 'Ġtraining', 'Ġset', '.', 'ĠIn', 'Ġcontrast', ',', 'Ġwe', 'Ġfocus', 'Ġon', 'Ġimproving', 'Ġdiversity', 'Ġof', 'Ġgenerated', 'Ġcapt', 'ions', 'Ġusing', 'Ġa', 'Ġsingle', 'Ġmodel', '.', 'ĠOur', 'Ġmethod', 'Ġachieves', 'Ġthis', 'Ġby', 'Ġlearning', 'Ġa', 'Ġcorresponding', 'Ġmodel', 'Ġusing', 'Ġa', 'Ġdifferent', 'Ġtraining', 'Ġloss', 'Ġas', 'Ġopposed', 'Ġto', 'Ġafter', 'Ġtraining', 'Ġhas', 'Ġcompleted', '.', 'ĠWe', 'Ġnote', 'Ġthat', 'Ġgenerating', 'Ġdiverse', 'Ġsentences', 'Ġis', 'Ġalso', 'Ġa', 'Ġchallenge', 'Ġin', 'Ġvisual', 'Ġquestion', 'Ġgeneration', ',', 'Ġsee', 'Ġconcurrent', 'Ġwork', 'Ġ[', '19', '],', 'Ġand', 'Ġin', 'Ġlanguage', '-', 'only', 'Ġdialogue', 'Ġgeneration', 'Ġstudied', 'Ġin', 'Ġthe', 'Ġlinguistic', 'Ġcommunity', ',', 'Ġsee', 'Ġe', '.', 'g', '.', 'Ġ[', '23', ',', 'Ġ24', '].', 'ĠWhen', 'Ġtraining', 'Ġrecurrent', 'Ġdescription', 'Ġmodels', ',', 'Ġthe', 'Ġmost', 'Ġcommon', 'Ġmethod', 'Ġis', 'Ġto', 'Ġpredict', 'Ġa', 'Ġword', 'Ġw', 't', 'Ġconditioned', 'Ġon', 'Ġan', 'Ġimage', 'Ġand', 'Ġall', 'Ġprevious', 'Ġground', 'Ġtruth', 'Ġwords', '.', 'ĠAt', 'Ġtest', 'Ġtime', ',', 'Ġeach', 'Ġword', 'Ġis', 'Ġpredicted', 'Ġconditioned', 'Ġon', 'Ġan', 'Ġimage', 'Ġand', 'Ġpreviously', 'Ġpredicted', 'Ġwords', '.', 'ĠConsequently', ',', 'Ġat', 'Ġtest', 'Ġtime', 'Ġpredicted', 'Ġwords', 'Ġmay', 'Ġbe', 'Ġconditioned', 'Ġon', 'Ġwords', 'Ġthat', 'Ġwere', 'Ġincorrectly', 'Ġpredicted', 'Ġby', 'Ġthe', 'Ġmodel', '.', 'ĠBy', 'Ġonly', 'Ġtraining', 'Ġon', 'Ġground', 'Ġtruth', 'Ġwords', ',', 'Ġthe', 'Ġmodel', 'Ġsuffers', 'Ġfrom', 'Ġexposure', 'Ġbias', 'Ġ[', '31', ']', 'Ġand', 'Ġcannot', 'Ġeffectively', 'Ġlearn', 'Ġto', 'Ġrecover', 'Ġwhen', 'Ġit', 'Ġpredicts', 'Ġan', 'Ġincorrect', 'Ġword', 'Ġduring', 'Ġtraining', '.', 'ĠTo', 'Ġavoid', 'Ġthis', ',', 'Ġ[', '4', ']', 'Ġproposes', 'Ġa', 'Ġscheduled', 'Ġsampling', 'Ġtraining', 'Ġscheme', 'Ġwhich', 'Ġbegins', 'Ġby', 'Ġtraining', 'Ġwith', 'Ġground', 'Ġtruth', 'Ġwords', ',', 'Ġbut', 'Ġthen', 'Ġslowly', 'Ġconditions', 'Ġgenerated', 'Ġwords', 'Ġon', 'Ġwords', 'Ġpreviously', 'Ġproduced', 'Ġby', 'Ġthe', 'Ġmodel', '.', 'ĠHowever', ',', 'Ġ[', '17', ']', 'Ġshows', 'Ġthat', 'Ġthe', 'Ġscheduled', 'Ġsampling', 'Ġalgorithm', 'Ġis', 'Ġinconsistent', 'Ġand', 'Ġthe', 'Ġoptimal', 'Ġsolution', 'Ġunder', 'Ġthis', 'Ġobjective', 'Ġdoes', 'Ġnot', 'Ġconverge', 'Ġto', 'Ġthe', 'Ġtrue', 'Ġdata', 'Ġdistribution', '.', 'ĠTaking', 'Ġa', 'Ġdifferent', 'Ġdirection', ',', 'Ġ[', '31', ']', 'Ġproposes', 'Ġto', 'Ġaddress', 'Ġthe', 'Ġexposure', 'Ġbias', 'Ġby', 'Ġgradually', 'Ġmixing', 'Ġa', 'Ġsequence', 'Ġlevel', 'Ġloss', 'Ġ(', 'BLE', 'U', 'Ġscore', ')', 'Ġusing', 'ĠRE', 'IN', 'FOR', 'CE', 'Ġrule', 'Ġwith', 'Ġthe', 'Ġstandard', 'Ġmaximum', 'Ġlikelihood', 'Ġtraining', '.', 'ĠSeveral', 'Ġother', 'Ġworks', 'Ġhave', 'Ġfollowed', 'Ġthis', 'Ġup', 'Ġwith', 'Ġusing', 'Ġreinforcement', 'Ġlearning', 'Ġbased', 'Ġapproaches', 'Ġto', 'Ġdirectly', 'Ġoptimize', 'Ġthe', 'Ġevaluation', 'Ġmetrics', 'Ġlike', 'ĠB', 'LE', 'U', ',', 'ĠMET', 'E', 'OR', 'Ġand', 'ĠC', 'IDER', 'Ġ[', '33', ',', 'Ġ25', '].', 'ĠHowever', ',', 'Ġoptimizing', 'Ġthe', 'Ġevaluation', 'Ġmetrics', 'Ġdoes', 'Ġnot', 'Ġdirectly', 'Ġaddress', 'Ġthe', 'Ġdiversity', 'Ġof', 'Ġthe', 'Ġ', 'Ġ', 'Č', 'generated', 'Ġcapt', 'ions', '.', 'ĠSince', 'Ġall', 'Ġcurrent', 'Ġevaluation', 'Ġmetrics', 'Ġuse', 'Ġn', '-', 'gram', 'Ġmatching', 'Ġto', 'Ġscore', 'Ġthe', 'Ġcapt', 'ions', ',', 'Ġcapt', 'ions', 'Ġusing', 'Ġmore', 'Ġfrequent', 'Ġn', '-', 'gram', 's', 'Ġare', 'Ġlikely', 'Ġto', 'Ġachieve', 'Ġbetter', 'Ġscores', 'Ġthan', 'Ġones', 'Ġusing', 'Ġrare', 'r', 'Ġand', 'Ġmore', 'Ġdiverse', 'Ġn', '-', 'gram', 's', '.', 'ĠIn', 'Ġthis', 'Ġwork', ',', 'Ġwe', 'Ġformulate', 'Ġour', 'Ġcaption', 'Ġgenerator', 'Ġas', 'Ġa', 'Ġgener', 'ative', 'Ġadvers', 'arial', 'Ġnetwork', '.', 'ĠWe', 'Ġdesign', 'Ġa', 'Ġdiscrim', 'inator', 'Ġthat', 'Ġexplicitly', 'Ġencourages', 'Ġgenerated', 'Ġcapt', 'ions', 'Ġto', 'Ġbe', 'Ġdiverse', 'Ġand', 'Ġindistinguishable', 'Ġfrom', 'Ġhuman', 'Ġcapt', 'ions', '.', 'ĠThe', 'Ġgenerator', 'Ġis', 'Ġtrained', 'Ġwith', 'Ġan', 'Ġadvers', 'arial', 'Ġloss', 'Ġwith', 'Ġthis', 'Ġdiscrim', 'inator', '.', 'ĠConsequently', ',', 'Ġour', 'Ġmodel', 'Ġgenerates', 'Ġcapt', 'ions', 'Ġthat', 'Ġbetter', 'Ġreflect', 'Ġthe', 'Ġway', 'Ġhumans', 'Ġdescribe', 'Ġimages', 'Ġwhile', 'Ġmaintaining', 'Ġsimilar', 'Ġcorrectness', 'Ġas', 'Ġdetermined', 'Ġby', 'Ġa', 'Ġhuman', 'Ġevaluation', '.', 'ĠGener', 'ative', 'ĠAd', 'vers', 'arial', 'ĠNetworks', '.', 'ĠThe', 'ĠGener', 'ative', 'ĠAd', 'vers', 'arial', 'ĠNetworks', 'Ġ(', 'GAN', 's', ')', 'Ġ[', '14', ']', 'Ġframework', 'Ġlearns', 'Ġgener', 'ative', 'Ġmodels', 'Ġwithout', 'Ġexplicitly', 'Ġdefining', 'Ġa', 'Ġloss', 'Ġfrom', 'Ġa', 'Ġtarget', 'Ġdistribution', '.', 'ĠInstead', ',', 'ĠG', 'AN', 's', 'Ġlearn', 'Ġa', 'Ġgenerator', 'Ġusing', 'Ġa', 'Ġloss', 'Ġfrom', 'Ġa', 'Ġdiscrim', 'inator', 'Ġwhich', 'Ġtries', 'Ġto', 'Ġdifferentiate', 'Ġreal', 'Ġand', 'Ġgenerated', 'Ġsamples', ',', 'Ġwhere', 'Ġthe', 'Ġgenerated', 'Ġsamples', 'Ġcome', 'Ġfrom', 'Ġthe', 'Ġgenerator', '.', 'ĠWhen', 'Ġtraining', 'Ġto', 'Ġgenerate', 'Ġreal', 'Ġimages', ',', '</s>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title_all = f\"papers_{test_val[0]}.tex\"\n",
        "generate(all_tokens2, (average_attention*100), title_all, 'red')"
      ],
      "metadata": {
        "id": "htPtu7kErWfN"
      },
      "id": "htPtu7kErWfN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets suppose you don't want to find out the attentions over all layers, but just one layer. You can do that by doing one less summation and instead picking out the layer you want immediately. Here we are picking out the last layer."
      ],
      "metadata": {
        "id": "TCKn9M3ILsEh"
      },
      "id": "TCKn9M3ILsEh"
    },
    {
      "cell_type": "code",
      "source": [
        "print(attention_matrix_importance[11].squeeze().shape)\n",
        "average_attention_final_layer = attention_matrix_importance[11].squeeze().sum(axis=0)"
      ],
      "metadata": {
        "id": "GaM018NVunZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f137e8-d3a7-44ab-b42c-5d0c5bfc2235"
      },
      "id": "GaM018NVunZH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title_last_layer = f\"papers_{test_val[0]}_layer_12_only.tex\"\n",
        "generate(all_tokens2, (average_attention_final_layer*100), title_last_layer, 'red')"
      ],
      "metadata": {
        "id": "fSl21NvVyW-n"
      },
      "id": "fSl21NvVyW-n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Highest attended tokens"
      ],
      "metadata": {
        "id": "F6pfY5SAp2ni"
      },
      "id": "F6pfY5SAp2ni"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are getting the top k attended words for specific example in a batch, over all heads and all layers. These functions are roughly the same as the functions in the section \"Every token's top attended\". Here we have modified the functions as we have one less axis to deal with and rather than getting every token's top attended token, we are finding out which tokens are the most attended TO."
      ],
      "metadata": {
        "id": "c-wAlJI1jrOe"
      },
      "id": "c-wAlJI1jrOe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "`find_top_attention` takes the summed attention matrix (layer, batch, head, seq_len) obtains the top k values for every head, batch, and layer. Along with the values, it also returns the positions of each value so we know what token each value returned corresponds to. The output of the function are two arrays of shape (layer, batch, head, k)."
      ],
      "metadata": {
        "id": "VNQg3Ham5t8L"
      },
      "id": "VNQg3Ham5t8L"
    },
    {
      "cell_type": "code",
      "source": [
        "def find_top_attention(scores_mat, k):\n",
        "  indices = scores_mat.argsort(axis=3)[:, :, :, :-(k+1):-1]\n",
        "  vals = np.take_along_axis(scores_mat, indices, axis=3)\n",
        "  return indices, vals"
      ],
      "metadata": {
        "id": "h6nLRpgBltnk"
      },
      "id": "h6nLRpgBltnk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`get_tokens2` takes in three inputs: a matrix of indices with shape (layer, batch, head, k), the tensor of input_ids used for prediction, and an example number, and finds the associated token at each index stored in the input matrix. The example number serves only to select an example from the batch. If we do not pass in an example as an input, we will iterate over all of the batches. The output of the function is an array of shape (layer, batch, head, k), where each item is a token from the respective example."
      ],
      "metadata": {
        "id": "FD54nkWS6O_H"
      },
      "id": "FD54nkWS6O_H"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tokens2(index_matrix, example_ids, example=None):\n",
        "\n",
        "  # Make sure our example is not out of range.\n",
        "  assert example < index_matrix.shape[1]\n",
        "\n",
        "  highest_tokens = []\n",
        "  #layer\n",
        "  for i in range(index_matrix.shape[0]):\n",
        "    row_tokens = []\n",
        "    #batch\n",
        "    for j in range(index_matrix.shape[1]):\n",
        "      batch_tokens = []\n",
        "\n",
        "      if example is not None and j != example:\n",
        "        continue\n",
        "\n",
        "      all_tokens = tokenizer.convert_ids_to_tokens(example_ids[j])\n",
        "\n",
        "      #head\n",
        "      for k in range(index_matrix.shape[2]):\n",
        "        tokens = [all_tokens[idx] for idx in index_matrix[i,j,k]]\n",
        "        batch_tokens.append(tokens)\n",
        "      row_tokens.append(batch_tokens)\n",
        "    highest_tokens.append(row_tokens)\n",
        "  return np.array(highest_tokens)"
      ],
      "metadata": {
        "id": "NSv7L_PVvLdZ"
      },
      "id": "NSv7L_PVvLdZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`highest_attended_dataframe` takes in 4 inputs. It takes in a matrix of indicies, matrix of values, matrix of tokens, all with shape (layer, batch, head, k), and an example number. The example number again serves only to pick an example from the batch and if not used, will iterate over all batches. We use these matrices to create a Pandas Dataframe, where each row of the dataframe contains the current token, the position of the current token, the value of the current token, and the rank of the token w.r.t. the current layer, head and batch. We also save the layer number, the head number and the batch in the dataframe. "
      ],
      "metadata": {
        "id": "rl2V1kNP6tlE"
      },
      "id": "rl2V1kNP6tlE"
    },
    {
      "cell_type": "code",
      "source": [
        "def highest_attended_dataframe(index, values, tokens, example=None):\n",
        "\n",
        "    dataframe=[]\n",
        "    #layer\n",
        "    for i in range(index.shape[0]):\n",
        "      #batch\n",
        "      for j in range(index.shape[1]):\n",
        "        if example is not None and j != example:\n",
        "          continue\n",
        "        #head\n",
        "        for k in range(index.shape[2]):\n",
        "          #token\n",
        "          for x in range(index.shape[3]):\n",
        "            d = {\"token\":tokens[i,j,k,x], 'position':index[i,j,k,x], \n",
        "                'attention_scores':values[i,j,k,x],\n",
        "                 'layer':(i+1), 'head':(k+1),\n",
        "                 'rank':(x+1),\n",
        "                 'batch':j}\n",
        "            dataframe.append(d)\n",
        "    df = pd.DataFrame(dataframe)\n",
        "    return df"
      ],
      "metadata": {
        "id": "YCWTK-E49C6e"
      },
      "id": "YCWTK-E49C6e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def highest_attentions_summed(matrix, k, example_ids, example=None):\n",
        "  index, values = find_top_attention(matrix, k)\n",
        "  highest_tokens = get_tokens2(index, example_ids, example)\n",
        "  df_highest = highest_attended_dataframe(index, values, highest_tokens, example)\n",
        "  return df_highest"
      ],
      "metadata": {
        "id": "u7XhkMteJGAo"
      },
      "id": "u7XhkMteJGAo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As such, the dataframe should contain rows equal to (num_layers * num_heads * k * num_examples_selected)."
      ],
      "metadata": {
        "id": "NY5brRaq74D6"
      },
      "id": "NY5brRaq74D6"
    },
    {
      "cell_type": "code",
      "source": [
        "df_highest = highest_attentions_summed(attention_matrix_importance, 10, testexam[\"input_ids\"],  0)\n",
        "df_highest"
      ],
      "metadata": {
        "id": "qdnmbBl2_m2p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "4c2e7684-6070-40ff-92e3-6a008409f6f2"
      },
      "id": "qdnmbBl2_m2p",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       token  position  attention_scores  layer  head  rank  batch\n",
              "0        <s>         0          0.828359      1     1     1      0\n",
              "1          -       512          0.197836      1     1     2      0\n",
              "2         Ġa      1536          0.183238      1     1     3      0\n",
              "3     Ġimage      1024          0.176865      1     1     4      0\n",
              "4        ĠAt      1620          0.099787      1     1     5      0\n",
              "...      ...       ...               ...    ...   ...   ...    ...\n",
              "1435       .       598          0.007779     12    12     6      0\n",
              "1436       .       572          0.006871     12    12     7      0\n",
              "1437       .       557          0.006470     12    12     8      0\n",
              "1438       .       533          0.005772     12    12     9      0\n",
              "1439       .      1140          0.005631     12    12    10      0\n",
              "\n",
              "[1440 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db4f4423-277f-4220-805f-2db0683fea81\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>position</th>\n",
              "      <th>attention_scores</th>\n",
              "      <th>layer</th>\n",
              "      <th>head</th>\n",
              "      <th>rank</th>\n",
              "      <th>batch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>0.828359</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-</td>\n",
              "      <td>512</td>\n",
              "      <td>0.197836</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ġa</td>\n",
              "      <td>1536</td>\n",
              "      <td>0.183238</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ġimage</td>\n",
              "      <td>1024</td>\n",
              "      <td>0.176865</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ĠAt</td>\n",
              "      <td>1620</td>\n",
              "      <td>0.099787</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1435</th>\n",
              "      <td>.</td>\n",
              "      <td>598</td>\n",
              "      <td>0.007779</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1436</th>\n",
              "      <td>.</td>\n",
              "      <td>572</td>\n",
              "      <td>0.006871</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1437</th>\n",
              "      <td>.</td>\n",
              "      <td>557</td>\n",
              "      <td>0.006470</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1438</th>\n",
              "      <td>.</td>\n",
              "      <td>533</td>\n",
              "      <td>0.005772</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1439</th>\n",
              "      <td>.</td>\n",
              "      <td>1140</td>\n",
              "      <td>0.005631</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1440 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db4f4423-277f-4220-805f-2db0683fea81')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db4f4423-277f-4220-805f-2db0683fea81 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db4f4423-277f-4220-805f-2db0683fea81');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Selective Information"
      ],
      "metadata": {
        "id": "rL1qTv1W8ugZ"
      },
      "id": "rL1qTv1W8ugZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can get the attention of a token at a position for each layer and head as well as the rank of the token within that head. Take one example at a time as each example has different tokens. \n",
        "\n",
        "Pros: can isolate for layers and/or heads. Cons: not much context for the attention scores"
      ],
      "metadata": {
        "id": "zZyzrWSgsjNj"
      },
      "id": "zZyzrWSgsjNj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "`position_attention` takes in 4 inputs. It takes in a matrix of shape (layer, batch, head, seq_len), the position you wish to look at, the tensor of input_ids used for prediction and an example number. The example number again serves only to pick an example from the batch and if not used, will iterate over all batches. We use these matrices to create a Pandas Dataframe, where each row of the dataframe contains a token, the position the token, the value of the current token, and the rank of the token w.r.t. the current layer, head and batch. We also save the layer number, the head number and the batch in the dataframe for each row. \n",
        "\n",
        "While this looks similar to the previous dataframe, this is restricted to what particular position you pass in as an argument and may show you tokens with a rank number higher than your threshold"
      ],
      "metadata": {
        "id": "OXRpi0V-81A7"
      },
      "id": "OXRpi0V-81A7"
    },
    {
      "cell_type": "code",
      "source": [
        "def position_attention(agg_matrix, position, example_ids, example=None):\n",
        "  dataframe = []\n",
        "  # Make sure our example is not out of range.\n",
        "  if example is not None:\n",
        "    assert example < agg_matrix.shape[1]\n",
        "\n",
        "  if example is not None:\n",
        "    new_mat = agg_matrix[:, example, :]\n",
        "    all_tokens = tokenizer.convert_ids_to_tokens(example_ids[example])\n",
        "    new_mat = new_mat.squeeze()\n",
        "    #layer\n",
        "    for i in range(new_mat.shape[0]):\n",
        "      #head\n",
        "      for j in range(new_mat.shape[1]):\n",
        "        temp = new_mat[i,j].argsort()[::-1]\n",
        "        temp = np.where(temp==position)[0].squeeze() + 1\n",
        "        d = {\"token\":all_tokens[position], 'position':position, \n",
        "            'attention_scores':new_mat[i,j,position], 'layer':(i+1), 'head':(j+1),\n",
        "            'rank':temp, 'batch':example}\n",
        "        dataframe.append(d)\n",
        "  else:\n",
        "    new_mat = agg_matrix\n",
        "    #layer\n",
        "    for i in range(new_mat.shape[0]):\n",
        "      #batch\n",
        "      for j in range(new_mat.shape[1]):\n",
        "        all_tokens = tokenizer.convert_ids_to_tokens(example_ids[j])\n",
        "        #head\n",
        "        for k in range(new_mat.shape[2]):\n",
        "          temp = new_mat[i,j,k].argsort()[::-1]\n",
        "          temp = np.where(temp==position)[0].squeeze() + 1\n",
        "          d = {\"token\":all_tokens[position], 'position':position, \n",
        "              'attention_scores':new_mat[i,j,k,position], 'layer':(i+1), 'head':(k+1),\n",
        "              'rank':temp, 'batch':j}\n",
        "          dataframe.append(d)\n",
        "  df = pd.DataFrame(dataframe)\n",
        "  return df"
      ],
      "metadata": {
        "id": "jrjjYyR-siot"
      },
      "id": "jrjjYyR-siot",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "position_df = position_attention(attention_matrix_importance, 0, testexam[\"input_ids\"], 0)\n",
        "position_df[position_df[\"head\"]==1]"
      ],
      "metadata": {
        "id": "YpSZKQ0nvt5T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "c09d1bc4-7abc-40ad-9829-bd72dc9ac6da"
      },
      "id": "YpSZKQ0nvt5T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    token  position  attention_scores  layer  head  rank  batch\n",
              "0     <s>         0          0.828359      1     1     1      0\n",
              "12    <s>         0          2.288567      2     1     1      0\n",
              "24    <s>         0          2.218063      3     1     1      0\n",
              "36    <s>         0         30.302422      4     1     1      0\n",
              "48    <s>         0          1.400106      5     1     1      0\n",
              "60    <s>         0          1.034880      6     1     1      0\n",
              "72    <s>         0          0.147366      7     1   122      0\n",
              "84    <s>         0          0.106004      8     1     1      0\n",
              "96    <s>         0          0.000766      9     1    38      0\n",
              "108   <s>         0          0.000000     10     1  2048      0\n",
              "120   <s>         0          0.002846     11     1    80      0\n",
              "132   <s>         0          0.001053     12     1   326      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d72d9aa2-596b-41d9-81c2-254dbcf908fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>position</th>\n",
              "      <th>attention_scores</th>\n",
              "      <th>layer</th>\n",
              "      <th>head</th>\n",
              "      <th>rank</th>\n",
              "      <th>batch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>0.828359</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>2.288567</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>2.218063</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>30.302422</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>1.400106</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>1.034880</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>0.147366</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>122</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>0.106004</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000766</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>2048</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>0.002846</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>0.001053</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>326</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d72d9aa2-596b-41d9-81c2-254dbcf908fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d72d9aa2-596b-41d9-81c2-254dbcf908fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d72d9aa2-596b-41d9-81c2-254dbcf908fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Complete Package"
      ],
      "metadata": {
        "id": "XwrbWhoC8bbv"
      },
      "id": "XwrbWhoC8bbv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "If really needed, you can just have the full matrix of the position, ranks, attention scores, layers, and heads of each token per example. \n",
        "\n",
        "Pros: can search up whatever is needed. Has access to all the information and can be extracted for comparisons like the previous two dataframes.\n",
        "\n",
        "Cons: have to know what you want and manually look it up."
      ],
      "metadata": {
        "id": "QYwu3xw37k-k"
      },
      "id": "QYwu3xw37k-k"
    },
    {
      "cell_type": "markdown",
      "source": [
        "`full_matrix` takes in 3 inputs. It takes in a matrix of shape (layer, batch, head, seq_len, k), the tensor of input_ids used for prediction and an example number. The example number again serves only to pick an example from the batch and if not used, will iterate over all batches. We use these matrices to create a Pandas Dataframe, where each row of the dataframe contains a token, the position the token, the value of the current token, and the rank of the token w.r.t. the current layer, head and batch. We also save the layer number, the head number and the batch in the dataframe. "
      ],
      "metadata": {
        "id": "7L4hHC9M-1PL"
      },
      "id": "7L4hHC9M-1PL"
    },
    {
      "cell_type": "code",
      "source": [
        "def full_matrix(agg_matrix, example_ids, example=None):\n",
        "  dataframe=[]\n",
        "\n",
        "  if example is not None:\n",
        "    new_mat = agg_matrix[:, example]\n",
        "    new_mat = new_mat.squeeze()\n",
        "    print(new_mat.shape)\n",
        "    all_tokens = tokenizer.convert_ids_to_tokens(example_ids[example])\n",
        "\n",
        "    #layer\n",
        "    for i in range(new_mat.shape[0]):\n",
        "      #head\n",
        "      for j in range(new_mat.shape[1]):\n",
        "        temp = new_mat[i,j].argsort()[::-1]      \n",
        "        #token\n",
        "        for k in range(new_mat.shape[2]):\n",
        "          temp2 = np.where(temp==k)[0].squeeze() + 1\n",
        "          d = {\"token\":all_tokens[k], 'position':k, \n",
        "              'attention_scores':new_mat[i,j,k], 'layer':(i+1), 'head':(j+1),\n",
        "              'rank':temp2}\n",
        "          dataframe.append(d)\n",
        "  else:\n",
        "    new_mat = agg_matrix\n",
        "    print(new_mat.shape)\n",
        "    \n",
        "    #layer\n",
        "    for i in range(new_mat.shape[0]):\n",
        "      #batch\n",
        "      for j in range(new_mat.shape[1]):\n",
        "\n",
        "        all_tokens = tokenizer.convert_ids_to_tokens(example_ids[j])\n",
        "\n",
        "        #head\n",
        "        for k in range(new_mat.shape[2]):\n",
        "          temp = new_mat[i,j,k].argsort()[::-1]      \n",
        "          #token\n",
        "          for x in range(new_mat.shape[3]):\n",
        "            temp2 = np.where(temp==x)[0].squeeze() + 1\n",
        "            d = {\"token\":all_tokens[x], 'position':x, \n",
        "                'attention_scores':new_mat[i,j,k,x], 'layer':(i+1), 'head':(k+1),\n",
        "                'rank':temp2, 'batch':j}\n",
        "            dataframe.append(d)\n",
        "  df = pd.DataFrame(dataframe)\n",
        "  return df"
      ],
      "metadata": {
        "id": "n8WZcz_w7Chc"
      },
      "id": "n8WZcz_w7Chc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_mat = full_matrix(attention_matrix_importance, testexam[\"input_ids\"])"
      ],
      "metadata": {
        "id": "mn8NifO00kND",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f77619fd-4968-493a-cf33-e77979534b2a"
      },
      "id": "mn8NifO00kND",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12, 1, 12, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_mat[(full_mat['head']==12) & (full_mat['layer']==12)]"
      ],
      "metadata": {
        "id": "-kn2bEWf8BN0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "71a56bdc-7b9e-4566-e430-1a3ce2fdb22e"
      },
      "id": "-kn2bEWf8BN0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              token  position  attention_scores  layer  head  rank  batch\n",
              "292864          <s>         0          0.000676     12    12   152      0\n",
              "292865    Published         1          0.000326     12    12   531      0\n",
              "292866          Ġas         2          0.000182     12    12  1054      0\n",
              "292867           Ġa         3          0.000252     12    12   761      0\n",
              "292868  Ġconference         4          0.000054     12    12  1796      0\n",
              "...             ...       ...               ...    ...   ...   ...    ...\n",
              "294907    Ġgenerate      2043          0.000239     12    12   800      0\n",
              "294908        Ġreal      2044          0.000139     12    12  1252      0\n",
              "294909      Ġimages      2045          0.000191     12    12  1007      0\n",
              "294910            ,      2046          0.000273     12    12   699      0\n",
              "294911         </s>      2047          0.000119     12    12  1354      0\n",
              "\n",
              "[2048 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1bf6f9da-fa20-4990-afc6-31753cfd738b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>position</th>\n",
              "      <th>attention_scores</th>\n",
              "      <th>layer</th>\n",
              "      <th>head</th>\n",
              "      <th>rank</th>\n",
              "      <th>batch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>292864</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000676</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>152</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292865</th>\n",
              "      <td>Published</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000326</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>531</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292866</th>\n",
              "      <td>Ġas</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000182</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>1054</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292867</th>\n",
              "      <td>Ġa</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000252</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>761</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292868</th>\n",
              "      <td>Ġconference</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>1796</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294907</th>\n",
              "      <td>Ġgenerate</td>\n",
              "      <td>2043</td>\n",
              "      <td>0.000239</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>800</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294908</th>\n",
              "      <td>Ġreal</td>\n",
              "      <td>2044</td>\n",
              "      <td>0.000139</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>1252</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294909</th>\n",
              "      <td>Ġimages</td>\n",
              "      <td>2045</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>1007</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294910</th>\n",
              "      <td>,</td>\n",
              "      <td>2046</td>\n",
              "      <td>0.000273</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>699</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294911</th>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "      <td>2047</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>1354</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2048 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1bf6f9da-fa20-4990-afc6-31753cfd738b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1bf6f9da-fa20-4990-afc6-31753cfd738b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1bf6f9da-fa20-4990-afc6-31753cfd738b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of how to get the top k attended tokens"
      ],
      "metadata": {
        "id": "cMgY-RhNGkis"
      },
      "id": "cMgY-RhNGkis"
    },
    {
      "cell_type": "code",
      "source": [
        "full_mat[(full_mat['rank']>=1) & (full_mat['rank'] <= 10)].sort_values(by = ['layer', 'head', 'rank'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "H2LPXz8VGcIT",
        "outputId": "a1971afd-75c8-4670-dd16-79d39944e0c2"
      },
      "id": "H2LPXz8VGcIT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         token  position  attention_scores  layer  head  rank  batch\n",
              "0          <s>         0          0.828359      1     1     1      0\n",
              "512          -       512          0.197836      1     1     2      0\n",
              "1536        Ġa      1536          0.183238      1     1     3      0\n",
              "1024    Ġimage      1024          0.176865      1     1     4      0\n",
              "1620       ĠAt      1620          0.099787      1     1     5      0\n",
              "...        ...       ...               ...    ...   ...   ...    ...\n",
              "293462       .       598          0.007779     12    12     6      0\n",
              "293436       .       572          0.006871     12    12     7      0\n",
              "293421       .       557          0.006470     12    12     8      0\n",
              "293397       .       533          0.005772     12    12     9      0\n",
              "294004       .      1140          0.005631     12    12    10      0\n",
              "\n",
              "[1440 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-454e9273-821b-42eb-902c-9f91c33cb468\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>position</th>\n",
              "      <th>attention_scores</th>\n",
              "      <th>layer</th>\n",
              "      <th>head</th>\n",
              "      <th>rank</th>\n",
              "      <th>batch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "      <td>0.828359</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>-</td>\n",
              "      <td>512</td>\n",
              "      <td>0.197836</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1536</th>\n",
              "      <td>Ġa</td>\n",
              "      <td>1536</td>\n",
              "      <td>0.183238</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1024</th>\n",
              "      <td>Ġimage</td>\n",
              "      <td>1024</td>\n",
              "      <td>0.176865</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1620</th>\n",
              "      <td>ĠAt</td>\n",
              "      <td>1620</td>\n",
              "      <td>0.099787</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293462</th>\n",
              "      <td>.</td>\n",
              "      <td>598</td>\n",
              "      <td>0.007779</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293436</th>\n",
              "      <td>.</td>\n",
              "      <td>572</td>\n",
              "      <td>0.006871</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293421</th>\n",
              "      <td>.</td>\n",
              "      <td>557</td>\n",
              "      <td>0.006470</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293397</th>\n",
              "      <td>.</td>\n",
              "      <td>533</td>\n",
              "      <td>0.005772</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294004</th>\n",
              "      <td>.</td>\n",
              "      <td>1140</td>\n",
              "      <td>0.005631</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1440 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-454e9273-821b-42eb-902c-9f91c33cb468')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-454e9273-821b-42eb-902c-9f91c33cb468 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-454e9273-821b-42eb-902c-9f91c33cb468');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "Token_attention_with_head_importance.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b5843f6f51414f11ae0fba93e05e6838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3011ced5337d4f21b3064d9cd5f78c82",
              "IPY_MODEL_0ecf4fe838ab46648981646673e15c37",
              "IPY_MODEL_054cc43ef0f14cc2b88f4918705c8ef0"
            ],
            "layout": "IPY_MODEL_17aeb2d7f36d4141a9dcd2ad00d12730"
          }
        },
        "3011ced5337d4f21b3064d9cd5f78c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bf49a5fdfae4a52a7ab8bede04ce969",
            "placeholder": "​",
            "style": "IPY_MODEL_174e3b2c34754b19b82b67586e56c600",
            "value": "100%"
          }
        },
        "0ecf4fe838ab46648981646673e15c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fad354d7636a4219b39c1d94daef2282",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_debecac92d2e4509bd6b0c0de0028e00",
            "value": 2
          }
        },
        "054cc43ef0f14cc2b88f4918705c8ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0392166405845eba7d84bfc0fce45af",
            "placeholder": "​",
            "style": "IPY_MODEL_99245def01d74af7bccaaa9ac9411e9b",
            "value": " 2/2 [00:00&lt;00:00, 60.80it/s]"
          }
        },
        "17aeb2d7f36d4141a9dcd2ad00d12730": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bf49a5fdfae4a52a7ab8bede04ce969": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "174e3b2c34754b19b82b67586e56c600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fad354d7636a4219b39c1d94daef2282": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "debecac92d2e4509bd6b0c0de0028e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0392166405845eba7d84bfc0fce45af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99245def01d74af7bccaaa9ac9411e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a03392e53f9b4445a0aa987a6ce26960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_554f420e9ac04340b0cc30f2aa0296d4",
              "IPY_MODEL_4bc9f965f829478db5427f82f168b0fc",
              "IPY_MODEL_25d3a7a6bc7b405d8430fe4d54a10aca"
            ],
            "layout": "IPY_MODEL_43f90d8fdc2948dbaf63f07781212752"
          }
        },
        "554f420e9ac04340b0cc30f2aa0296d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7611b5b75ff4a8abb40fdf13fb4d0a2",
            "placeholder": "​",
            "style": "IPY_MODEL_48ca80c428e547eab9b2fd93e76f6329",
            "value": "100%"
          }
        },
        "4bc9f965f829478db5427f82f168b0fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e4e2a93724c4c27a7349b013b2f4b17",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f4f2c42272d41c496c6d8b94b4038cc",
            "value": 2
          }
        },
        "25d3a7a6bc7b405d8430fe4d54a10aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2da41a572b84b06b80c0a79c85d6e7e",
            "placeholder": "​",
            "style": "IPY_MODEL_af02e0d2e9b144448e9bd8faac4b212e",
            "value": " 2/2 [00:18&lt;00:00,  7.88s/ba]"
          }
        },
        "43f90d8fdc2948dbaf63f07781212752": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7611b5b75ff4a8abb40fdf13fb4d0a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48ca80c428e547eab9b2fd93e76f6329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e4e2a93724c4c27a7349b013b2f4b17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f4f2c42272d41c496c6d8b94b4038cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2da41a572b84b06b80c0a79c85d6e7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af02e0d2e9b144448e9bd8faac4b212e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}