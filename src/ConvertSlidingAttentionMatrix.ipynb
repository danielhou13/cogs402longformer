{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvertSlidingAttentionMatrix.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOKNy2Ufm2TZDoL1DZperMg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "157325f7c0ca4eef97e18c7e577f1981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8950b517bbe64996bfdda43594ad7fc0",
              "IPY_MODEL_b368bea91a3c497fb5d269f33df19ab7",
              "IPY_MODEL_9f70512d5fb04454a9f33c733ad38759"
            ],
            "layout": "IPY_MODEL_aa31e7e0d89042f2887eb324042fdd78"
          }
        },
        "8950b517bbe64996bfdda43594ad7fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6d8348014854f33b3ad00dab8abb19a",
            "placeholder": "​",
            "style": "IPY_MODEL_84744d68a42d4c38b02a09f72f53084b",
            "value": "100%"
          }
        },
        "b368bea91a3c497fb5d269f33df19ab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f2253b69ddb460b99dba6e897ef65f7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0557ad0f1aa4e7ca5ffd09aaab17ac9",
            "value": 2
          }
        },
        "9f70512d5fb04454a9f33c733ad38759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_712cab46a61e49768b5ff8d4c0a93c55",
            "placeholder": "​",
            "style": "IPY_MODEL_f8fbbdd7f3214d54abefb0b0a46cc135",
            "value": " 2/2 [00:00&lt;00:00, 22.24it/s]"
          }
        },
        "aa31e7e0d89042f2887eb324042fdd78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6d8348014854f33b3ad00dab8abb19a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84744d68a42d4c38b02a09f72f53084b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f2253b69ddb460b99dba6e897ef65f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0557ad0f1aa4e7ca5ffd09aaab17ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "712cab46a61e49768b5ff8d4c0a93c55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8fbbdd7f3214d54abefb0b0a46cc135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielhou13/cogs402longformer/blob/main/src/ConvertSlidingAttentionMatrix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ct9kgFC8pI4P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4df29095-95eb-474c-f3fe-1a909b220b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys\n",
        "# sys.path.append('/content/drive/My Drive/{}'.format(\"cogs402longformer/\"))"
      ],
      "metadata": {
        "id": "Ob5nJXXPpK0G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers --quiet"
      ],
      "metadata": {
        "id": "EBuNYVnApMXb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install captum --quiet"
      ],
      "metadata": {
        "id": "R0d1_0znpN46"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets --quiet"
      ],
      "metadata": {
        "id": "uVVwgDLLpPlI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "6st2F25FpRhy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "4HboDwSRpSvL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "cogs402_ds = load_dataset(\"danielhou13/cogs402dataset\")[\"test\"]"
      ],
      "metadata": {
        "id": "DhzILn5zpd_G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "157325f7c0ca4eef97e18c7e577f1981",
            "8950b517bbe64996bfdda43594ad7fc0",
            "b368bea91a3c497fb5d269f33df19ab7",
            "9f70512d5fb04454a9f33c733ad38759",
            "aa31e7e0d89042f2887eb324042fdd78",
            "d6d8348014854f33b3ad00dab8abb19a",
            "84744d68a42d4c38b02a09f72f53084b",
            "2f2253b69ddb460b99dba6e897ef65f7",
            "b0557ad0f1aa4e7ca5ffd09aaab17ac9",
            "712cab46a61e49768b5ff8d4c0a93c55",
            "f8fbbdd7f3214d54abefb0b0a46cc135"
          ]
        },
        "outputId": "0bacfda3-3e84-4cbe-da68-a46e6cddc66b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration danielhou13--cogs402dataset-cc784554b797f843\n",
            "Reusing dataset parquet (/root/.cache/huggingface/datasets/danielhou13___parquet/danielhou13--cogs402dataset-cc784554b797f843/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "157325f7c0ca4eef97e18c7e577f1981"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LongformerForSequenceClassification, LongformerTokenizer, LongformerConfig\n",
        "# replace <PATH-TO-SAVED-MODEL> with the real path of the saved model\n",
        "model_path = 'danielhou13/longformer-finetuned_papers'\n",
        "\n",
        "# load model\n",
        "model = LongformerForSequenceClassification.from_pretrained(model_path, num_labels = 2, output_attentions=True)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "model.zero_grad()\n",
        "\n",
        "# load tokenizer\n",
        "tokenizer = LongformerTokenizer.from_pretrained(\"allenai/longformer-base-4096\")"
      ],
      "metadata": {
        "id": "fcntxtJ5pUo0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(inputs, position_ids=None, attention_mask=None):\n",
        "    output = model(inputs,\n",
        "                   position_ids=position_ids,\n",
        "                   attention_mask=attention_mask)\n",
        "    return output.logits, output.attentions, output.global_attentions"
      ],
      "metadata": {
        "id": "myy1fQGEpWIT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ref_token_id = tokenizer.pad_token_id # A token used for generating token reference\n",
        "sep_token_id = tokenizer.sep_token_id # A token used as a separator between question and text and it is also added to the end of the text.\n",
        "cls_token_id = tokenizer.cls_token_id # A token used for prepending to the concatenated question-text word sequence"
      ],
      "metadata": {
        "id": "RxRUiKoPpXlf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def construct_input_ref_pair(text, ref_token_id, sep_token_id, cls_token_id):\n",
        "\n",
        "    text_ids = tokenizer.encode(text, truncation = True, add_special_tokens=False, max_length = 128)\n",
        "    # construct input token ids\n",
        "    input_ids = [cls_token_id] + text_ids + [sep_token_id]\n",
        "    # construct reference token ids \n",
        "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(text_ids) + [sep_token_id]\n",
        "\n",
        "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(text_ids)\n",
        "\n",
        "def construct_input_ref_pos_id_pair(input_ids):\n",
        "    seq_length = input_ids.size(1)\n",
        "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
        "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
        "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
        "\n",
        "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
        "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
        "    return position_ids, ref_position_ids\n",
        "\n",
        "def construct_attention_mask(input_ids):\n",
        "    return torch.ones_like(input_ids)\n",
        "\n",
        "def construct_whole_longformer_embeddings(input_ids, ref_input_ids, \\\n",
        "                                          token_type_ids=None, ref_token_type_ids=None, \\\n",
        "                                          position_ids=None, ref_position_ids=None):\n",
        "    input_embeddings = model.longformer.embeddings(input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
        "    ref_input_embeddings = model.longformer.embeddings(ref_input_ids, token_type_ids=ref_token_type_ids, position_ids=ref_position_ids)\n",
        "    \n",
        "    print(input_embeddings.shape)\n",
        "    return input_embeddings, ref_input_embeddings"
      ],
      "metadata": {
        "id": "Ni6yfqLxpYwv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.__version__ >= '1.7.0':\n",
        "    norm_fn = torch.linalg.norm\n",
        "else:\n",
        "    norm_fn = torch.norm"
      ],
      "metadata": {
        "id": "b7o81GhqpZyX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testval = 923\n",
        "text = cogs402_ds['text'][testval]\n",
        "label = cogs402_ds['labels'][testval]\n",
        "print(label)"
      ],
      "metadata": {
        "id": "n22zPXQspjdl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89e41a44-8797-477a-80d3-62f2334018a2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids, ref_input_ids, sep_id = construct_input_ref_pair(text, ref_token_id, sep_token_id, cls_token_id)\n",
        "\n",
        "position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
        "attention_mask = construct_attention_mask(input_ids)\n",
        "\n",
        "indices = input_ids[0].detach().tolist()\n",
        "all_tokens = tokenizer.convert_ids_to_tokens(indices)"
      ],
      "metadata": {
        "id": "8p3Zcnp0pkpO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_ids.squeeze().shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLXZInPGHc7l",
        "outputId": "7a5f2589-fd63-4cda-c54a-70d6273b6353"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([130])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score, attention, global_attention = predict(input_ids, position_ids, attention_mask)"
      ],
      "metadata": {
        "id": "bpxmexVYplx7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label=torch.tensor(label)\n",
        "print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QVb581cDwlJ",
        "outputId": "c39ed133-f0a0-41c6-abc2-162eb3d04f57"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(attention[1])\n",
        "# print(attention[1].sum(dim=0))\n",
        "# print(\"non_zero\", torch.nonzero(attention[1] - attention[1].sum(dim=0)))\n",
        "# print(attention[1].sum(dim=0).unsqueeze(0).shape)\n",
        "\n",
        "# batch_attn = torch.cat([l.sum(dim=0).unsqueeze(0) for l in attention], dim=0).detach().cpu().numpy()\n",
        "# print(batch_attn.shape)"
      ],
      "metadata": {
        "id": "FOT4_-Aspmpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape -> layer x batch x head x seq_len x attention_window\n",
        "output_attentions_all = torch.stack(attention).cpu()\n",
        "\n",
        "global_attention_all = torch.stack(global_attention).cpu()"
      ],
      "metadata": {
        "id": "C8NwXXzbpnAZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_attentions_all.device)\n",
        "print(global_attention_all.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VfKt5f53BWT",
        "outputId": "e5638850-bd77-4bcd-d9d8-a7be02c65569"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = output_attentions_all[11][0][11]\n",
        "global_test = global_attention_all[11][0][11]\n",
        "\n",
        "print(len(all_tokens))\n",
        "print(test.shape[0])\n",
        "\n",
        "print(global_test.squeeze().shape)\n",
        "\n",
        "def create_head_matrix(output_attentions, global_attentions):\n",
        "  new_attention_matrix = torch.zeros((output_attentions.shape[0], \n",
        "                                      output_attentions.shape[0]))\n",
        "  for i in range(output_attentions.shape[0]):\n",
        "    test_non_zeroes = torch.nonzero(output_attentions[i]).squeeze()\n",
        "    test2 = output_attentions[i][test_non_zeroes[1:]]\n",
        "    new_attention_matrix_indices = test_non_zeroes[1:]-257 + i\n",
        "    new_attention_matrix[i][new_attention_matrix_indices] = test2\n",
        "    new_attention_matrix[i][0] = output_attentions[i][0]\n",
        "    new_attention_matrix[0] = global_attentions.squeeze()[:output_attentions.shape[0]]\n",
        "  return new_attention_matrix\n",
        "\n",
        "\n",
        "def attentions_all_heads(output_attentions, global_attentions):\n",
        "    new_matrix = []\n",
        "    for i in range(output_attentions.shape[0]):\n",
        "      matrix = create_head_matrix(output_attentions[i], global_attentions[i])\n",
        "      new_matrix.append(matrix)\n",
        "    return torch.stack(new_matrix)\n",
        "\n",
        "def all_batches(output_attentions, global_attentions):\n",
        "    new_matrix = []\n",
        "    for i in range(output_attentions.shape[0]):\n",
        "      matrix = attentions_all_heads(output_attentions[i], global_attentions[i])\n",
        "      new_matrix.append(matrix)\n",
        "    return torch.stack(new_matrix)\n",
        "\n",
        "def all_layers(output_attentions, global_attentions):\n",
        "    new_matrix = []\n",
        "    for i in range(output_attentions.shape[0]):\n",
        "      matrix = all_batches(output_attentions[i], global_attentions[i])\n",
        "      new_matrix.append(matrix)\n",
        "    return torch.stack(new_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sumXFWywvG6",
        "outputId": "29bed24b-3d7d-485b-be97-1854af2ff444"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130\n",
            "130\n",
            "torch.Size([512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_matrix = create_head_matrix(test, global_test)\n",
        "# new_matrix2 = attentions_all_heads(output_attentions_all[11][0], \n",
        "#                                    global_attention_all[11][0])\n",
        "# new_matrix3 = all_batches(output_attentions_all[11], \n",
        "#                           global_attention_all[11])\n",
        "new_matrix4 = all_layers(output_attentions_all, \n",
        "                         global_attention_all)\n",
        "print(new_matrix)\n",
        "# print(new_matrix2.shape)\n",
        "# print(new_matrix3.shape)\n",
        "print(new_matrix4.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo4vQtSOLJdF",
        "outputId": "2298fe7c-739d-4407-d2ec-28407a56ef50"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0087, 0.0061, 0.0082,  ..., 0.0070, 0.0053, 0.0058],\n",
            "        [0.0069, 0.0098, 0.0086,  ..., 0.0084, 0.0057, 0.0072],\n",
            "        [0.0087, 0.0065, 0.0093,  ..., 0.0077, 0.0053, 0.0060],\n",
            "        ...,\n",
            "        [0.0086, 0.0071, 0.0091,  ..., 0.0108, 0.0075, 0.0089],\n",
            "        [0.0095, 0.0071, 0.0098,  ..., 0.0122, 0.0085, 0.0101],\n",
            "        [0.0085, 0.0070, 0.0096,  ..., 0.0107, 0.0074, 0.0095]],\n",
            "       grad_fn=<CopySlices>)\n",
            "torch.Size([12, 1, 12, 130, 130])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_matrix.shape)"
      ],
      "metadata": {
        "id": "0rGk5Lb1OjCG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23ce2c02-3d10-4d65-aa76-f18828a62d19"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([130, 130])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_matrix4[1].shape)\n",
        "batch_attn = torch.cat([l.sum(dim=0).unsqueeze(0) for l in new_matrix4], dim=0).detach().cpu().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "Sl2n6E8rx7bY",
        "outputId": "17581478-4f34-4bbc-a998-82d5ac540dbb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 12, 130, 130])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-3b89eb4548ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_matrix4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_matrix4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_attn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'device'"
          ]
        }
      ]
    }
  ]
}