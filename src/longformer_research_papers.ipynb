{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08bba816-6364-4b40-ba29-a22a8bb9e964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\Documents\\COGS402\\cogs402longformer\\src\n",
      "C:\\Users\\danie\\Documents\\COGS402\\cogs402longformer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "path_parent = os.path.dirname(os.getcwd())\n",
    "os.chdir(path_parent)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d269558-f433-4c28-8ac2-6ede43cb338a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#import huggingface models\n",
    "from transformers import LongformerForSequenceClassification, LongformerTokenizer\n",
    "\n",
    "tokenizer = LongformerTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "model = LongformerForSequenceClassification.from_pretrained(\"allenai/longformer-base-4096\",num_labels=2)\n",
    "model2 = LongformerForSequenceClassification.from_pretrained(\"src/longformer-finetuned/checkpoint-10000\",num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29d4a198-f15b-40c6-b1c2-cbe57d157241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "second_ds = pd.read_csv(\"data/longdoc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e058ac32-773b-4a5d-8994-4e8cb68eb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_ds, test_ds = train_test_split(second_ds, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ce08ccf-9c30-4c5c-8f75-eac961a8d739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "train_dataset = datasets.Dataset.from_pandas(train_ds)\n",
    "val_dataset = datasets.Dataset.from_pandas(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e0ba762-6c42-48de-bb43-fcbed56449a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer API auto uses dynamic padding... supposedly\n",
    "def tokenize(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9b78e6c-12f5-4c58-bfd6-94a820e6ce6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a78902ed2a14ea487b4ae8cd18b29cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8494a29b3649c2ba10cf9fb8511e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tokenize the data\n",
    "train_dataset = train_dataset.map(tokenize, load_from_cache_file=False)\n",
    "val_dataset = val_dataset.map(tokenize, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96ede4fd-0500-455a-8a70-28500c80216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(\"torch\", columns=['input_ids', 'attention_mask', \"labels\"])\n",
    "val_dataset.set_format(\"torch\", columns=['input_ids', 'attention_mask', \"labels\"])\n",
    "\n",
    "train_dataset = train_dataset.remove_columns(['text', '__index_level_0__'])\n",
    "val_dataset = val_dataset.remove_columns(['text', '__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32c110ce-27fe-41aa-adad-78cb3dda5502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 1179\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5dc200b8-0157-4095-99ad-1d0b2298c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"models\"):\n",
    "    os.mkdir(\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a749d43-e2d1-4de8-bbc9-50a5a687c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "batch_size = 1\n",
    "gradient_acc = 4\n",
    "logging_steps = (len(train_dataset) // batch_size) //gradient_acc\n",
    "model_name = f\"longformer-finetuned_v2\"\n",
    "training_args = TrainingArguments(output_dir=f\"models/{model_name}\",\n",
    "                                  num_train_epochs = 2,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  push_to_hub=False,\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  log_level=\"error\",\n",
    "                                  fp16=True,\n",
    "                                  gradient_accumulation_steps=gradient_acc,\n",
    "                                  gradient_checkpointing=True,\n",
    "                                  save_strategy = \"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f6544d7-bffa-4feb-9899-cbecc48f1a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4594f511-2304-492c-ac9c-5b3845e2b6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb9f6cb1-220b-407f-b9fa-43672b117209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "154504ce-d89d-4c03-9978-403b3d7a8a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model2,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator = data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebed74ca-a33a-43f3-b429-764d17260c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\miniconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='2356' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   3/2356 00:03 < 2:10:16, 0.30 it/s, Epoch 0.00/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/5000 03:44 < 03:58, 10.79 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\transformers\\trainer.py:1365\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1363\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1364\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1365\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1368\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1369\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1370\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1371\u001b[0m ):\n\u001b[0;32m   1372\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1373\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\transformers\\trainer.py:1940\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   1937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   1939\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocast_smart_context_manager():\n\u001b[1;32m-> 1940\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1942\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1943\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\transformers\\trainer.py:1972\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   1970\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1971\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1972\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m   1973\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   1974\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   1975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\transformers\\models\\longformer\\modeling_longformer.py:1880\u001b[0m, in \u001b[0;36mLongformerForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, global_attention_mask, head_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1877\u001b[0m     \u001b[38;5;66;03m# global attention on cls token\u001b[39;00m\n\u001b[0;32m   1878\u001b[0m     global_attention_mask[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlongformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobal_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1891\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1892\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1893\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\transformers\\models\\longformer\\modeling_longformer.py:1696\u001b[0m, in \u001b[0;36mLongformerModel.forward\u001b[1;34m(self, input_ids, attention_mask, global_attention_mask, head_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1688\u001b[0m extended_attention_mask: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_extended_attention_mask(attention_mask, input_shape, device)[\n\u001b[0;32m   1689\u001b[0m     :, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, :\n\u001b[0;32m   1690\u001b[0m ]\n\u001b[0;32m   1692\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1693\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids, position_ids\u001b[38;5;241m=\u001b[39mposition_ids, token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids, inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds\n\u001b[0;32m   1694\u001b[0m )\n\u001b[1;32m-> 1696\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1697\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1700\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1701\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1702\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1703\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1704\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1705\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\transformers\\models\\longformer\\modeling_longformer.py:1279\u001b[0m, in \u001b[0;36mLongformerEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1275\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m module(\u001b[38;5;241m*\u001b[39minputs, is_global_attn, output_attentions)\n\u001b[0;32m   1277\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m custom_forward\n\u001b[1;32m-> 1279\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_custom_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_module\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_index_masked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_index_global_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1288\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m   1289\u001b[0m         hidden_states,\n\u001b[0;32m   1290\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1295\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1296\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\checkpoint.py:211\u001b[0m, in \u001b[0;36mcheckpoint\u001b[1;34m(function, *args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected keyword arguments: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(arg \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m kwargs))\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCheckpointFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\checkpoint.py:90\u001b[0m, in \u001b[0;36mCheckpointFunction.forward\u001b[1;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[0;32m     87\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(\u001b[38;5;241m*\u001b[39mtensor_inputs)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 90\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mrun_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\transformers\\models\\longformer\\modeling_longformer.py:1275\u001b[0m, in \u001b[0;36mLongformerEncoder.forward.<locals>.create_custom_forward.<locals>.custom_forward\u001b[1;34m(*inputs)\u001b[0m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom_forward\u001b[39m(\u001b[38;5;241m*\u001b[39minputs):\n\u001b[1;32m-> 1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_global_attn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\transformers\\models\\longformer\\modeling_longformer.py:1213\u001b[0m, in \u001b[0;36mLongformerLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[0m\n\u001b[0;32m   1203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m   1204\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1205\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1211\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1212\u001b[0m ):\n\u001b[1;32m-> 1213\u001b[0m     self_attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_index_masked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_index_masked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_index_global_attn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_index_global_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_global_attn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_global_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1222\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m self_attn_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1223\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m self_attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\transformers\\models\\longformer\\modeling_longformer.py:1149\u001b[0m, in \u001b[0;36mLongformerAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[0m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m   1140\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1141\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1148\u001b[0m ):\n\u001b[1;32m-> 1149\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_index_masked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_index_masked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_index_global_attn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_index_global_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_global_attn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_global_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m   1159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attn_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\transformers\\models\\longformer\\modeling_longformer.py:617\u001b[0m, in \u001b[0;36mLongformerSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;66;03m# compute local attention probs from global attention keys and contact over window dim\u001b[39;00m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_global_attn:\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;66;03m# compute global attn indices required through out forward fn\u001b[39;00m\n\u001b[0;32m    612\u001b[0m     (\n\u001b[0;32m    613\u001b[0m         max_num_global_attn_indices,\n\u001b[0;32m    614\u001b[0m         is_index_global_attn_nonzero,\n\u001b[0;32m    615\u001b[0m         is_local_index_global_attn_nonzero,\n\u001b[0;32m    616\u001b[0m         is_local_index_no_global_attn_nonzero,\n\u001b[1;32m--> 617\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_global_attn_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_index_global_attn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;66;03m# calculate global attn probs from global key\u001b[39;00m\n\u001b[0;32m    620\u001b[0m     global_key_attn_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concat_with_global_key_attn_probs(\n\u001b[0;32m    621\u001b[0m         query_vectors\u001b[38;5;241m=\u001b[39mquery_vectors,\n\u001b[0;32m    622\u001b[0m         key_vectors\u001b[38;5;241m=\u001b[39mkey_vectors,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    626\u001b[0m         is_local_index_no_global_attn_nonzero\u001b[38;5;241m=\u001b[39mis_local_index_no_global_attn_nonzero,\n\u001b[0;32m    627\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\transformers\\models\\longformer\\modeling_longformer.py:930\u001b[0m, in \u001b[0;36mLongformerSelfAttention._get_global_attn_indices\u001b[1;34m(is_index_global_attn)\u001b[0m\n\u001b[0;32m    927\u001b[0m is_local_index_global_attn_nonzero \u001b[38;5;241m=\u001b[39m is_local_index_global_attn\u001b[38;5;241m.\u001b[39mnonzero(as_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;66;03m# location of the padding values within global attention indices\u001b[39;00m\n\u001b[1;32m--> 930\u001b[0m is_local_index_no_global_attn_nonzero \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mis_local_index_global_attn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mas_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    932\u001b[0m     max_num_global_attn_indices,\n\u001b[0;32m    933\u001b[0m     is_index_global_attn_nonzero,\n\u001b[0;32m    934\u001b[0m     is_local_index_global_attn_nonzero,\n\u001b[0;32m    935\u001b[0m     is_local_index_no_global_attn_nonzero,\n\u001b[0;32m    936\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57e2e2f2-646c-4166-ba49-5158a96811a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1179' max='1179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1179/1179 03:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_output = trainer.predict(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19b548e1-058b-47f9-ac6b-bbb0b39ce827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.36536848545074463,\n",
       " 'test_accuracy': 0.9134860050890585,\n",
       " 'test_f1': 0.9133801521326016,\n",
       " 'test_runtime': 215.7157,\n",
       " 'test_samples_per_second': 5.466,\n",
       " 'test_steps_per_second': 5.466}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_output.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f6b0148-92e1-48ec-938d-26c269ee1301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_preds = np.argmax(preds_output.predictions, axis=1)\n",
    "y_true = np.array(val_dataset[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "33b770a6-2a13-4878-b3bf-33b4eaf71159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          PL       0.87      0.97      0.92       568\n",
      "          AI       0.97      0.86      0.91       611\n",
      "\n",
      "    accuracy                           0.91      1179\n",
      "   macro avg       0.92      0.92      0.91      1179\n",
      "weighted avg       0.92      0.91      0.91      1179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\n",
    "    classification_report(\n",
    "        y_true, y_preds, target_names=[\"PL\", \"AI\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ceb13bd-a16c-4c95-a28a-c957b1129478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1179,)\n",
      "(1179,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds)\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"PL\", \"AI\"])\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(y_preds, y_true, labels=[0,1])\n",
    "print(y_true.shape)\n",
    "print(y_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6b3f6a8-ed40-4523-b221-40f4240cf3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset hyperpartisan_news_detection (C:\\Users\\danie\\.cache\\huggingface\\datasets\\hyperpartisan_news_detection\\bypublisher\\1.0.0\\7f4215b0474950ddf516e806400ab81d098b3da3b3a919a13cd1a4cf2c677012)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e322f4ad0688417bbb0044cb1e8fac6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# #load dataset\n",
    "# dataset  = datasets.load_dataset('hyperpartisan_news_detection', 'bypublisher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9d22c55-d447-4276-b5d9-d7c501f8857e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = dataset[\"train\"]\n",
    "# eval_ds = dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57b087cd-017e-4e54-af8d-58abddbab210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = map(int, train_ds['hyperpartisan'])\n",
    "# labels = list(labels)\n",
    "\n",
    "# labels2 = map(int, eval_ds['hyperpartisan'])\n",
    "# labels2 = list(labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71531372-70f9-47ac-809d-85e6790f16c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = train_ds.add_column(\"labels\", labels)\n",
    "# eval_ds = eval_ds.add_column(\"labels\", labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7500c4bf-b060-487f-a78b-d6976a9510f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #trainer API auto uses dynamic padding... supposedly\n",
    "# def tokenize(examples):\n",
    "#     return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2cceeb6-368a-4d25-8ddc-1c1e9729ac47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dccb645693cc4105a3cf4d3f77ca3135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ## Take subset of data\n",
    "# val_size = 5000\n",
    "# import numpy as np\n",
    "\n",
    "# val_indices = np.random.randint(0, len(eval_ds), val_size)\n",
    "# val_ds = eval_ds.select(val_indices)\n",
    "\n",
    "# #tokenize the data\n",
    "# val_dataset2 = val_ds.map(tokenize, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "941126e6-7150-4f10-9102-70c0b61c1413",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# val_dataset2.set_format(\"torch\", columns=['input_ids', 'attention_mask', \"labels\"])\n",
    "\n",
    "# val_dataset2 = val_dataset2.remove_columns(['text', 'title', 'hyperpartisan', 'url', 'published_at', 'bias'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4425e994-93fb-4c1f-8094-17618481026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model3 = LongformerForSequenceClassification.from_pretrained(\"longformer-finetuned_v2/checkpoint-2356\",num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e69c621-e304-4f55-8bb9-cfe4515caf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model3,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=val_dataset,\n",
    "#     compute_metrics=compute_metrics,\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator = data_collator\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d3f39d9-39f7-4379-a90e-e04b6513c04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5000/5000 08:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# preds_output = trainer.predict(val_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ddba2e12-8032-4b35-83f4-10bcd93e9e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.9062917232513428,\n",
       " 'test_accuracy': 0.8492,\n",
       " 'test_f1': 0.8455833788923798,\n",
       " 'test_runtime': 489.2036,\n",
       " 'test_samples_per_second': 10.221,\n",
       " 'test_steps_per_second': 10.221}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preds_output.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b308618-bd2f-47a7-93db-56a3b1a399eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogs402",
   "language": "python",
   "name": "cogs402"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
