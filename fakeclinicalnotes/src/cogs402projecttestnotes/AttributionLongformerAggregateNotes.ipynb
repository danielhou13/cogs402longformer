{"cells":[{"cell_type":"markdown","source":["This notebook performs [Integrated Gradients](https://arxiv.org/abs/1703.01365) over the entire dataset and aggregates all of the attributions with respect to the positive class. We aggregate using either the complete longformer embeddings, or the word and position embeddings. The notebook outputs a csv file containg tokens and the sum of the attributions over the entire dataset and is used in the [longformer embedding](https://colab.research.google.com/drive/15Zquqi72N2NNusEUXRN53bCKE7qj8KAh?usp=sharing) and [word+positon+token_type embeddings](https://colab.research.google.com/drive/1pptTYAJGp7tl0BhVQoTD5RGyQMEVF766) notebooks"],"metadata":{"id":"kEJ0R0uy0l47"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"b_HI-3J_1Gfg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658953261526,"user_tz":420,"elapsed":1027601,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"10725fdd-5181-4d4e-ee7d-d159e549b6da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Import dependencies"],"metadata":{"id":"HkZ5bD2_z-0C"}},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(\"cogs402longformer/\"))"],"metadata":{"id":"Jck92aCS1c3S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install transformers --quiet"],"metadata":{"id":"zMjzQIFJ2P_T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658953271963,"user_tz":420,"elapsed":10439,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"9c375733-15a1-4e07-898f-b2c50d84b710"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 4.7 MB 2.1 MB/s \n","\u001b[K     |████████████████████████████████| 6.6 MB 62.9 MB/s \n","\u001b[K     |████████████████████████████████| 101 kB 13.2 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 87.2 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","source":["pip install captum --quiet"],"metadata":{"id":"Uno0qwr12UTd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658953276453,"user_tz":420,"elapsed":4502,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"0f4f2040-81cd-46b4-f5f1-15b3094b5c56"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l\r\u001b[K     |▎                               | 10 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |▊                               | 30 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 3.9 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51 kB 1.8 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61 kB 2.2 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71 kB 2.2 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81 kB 2.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 92 kB 2.7 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 102 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 112 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 122 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 133 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 143 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 153 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 163 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 174 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 184 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 194 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 204 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 215 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 225 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 235 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 245 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 256 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 266 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 276 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 286 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 296 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 307 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 317 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 327 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 337 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 348 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 358 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 368 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 378 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 389 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 399 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 409 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 419 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 430 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 440 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 450 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 460 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 471 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 481 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 491 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 501 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 512 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 522 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 532 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 542 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 552 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 563 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 573 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 583 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 593 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 604 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 614 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 624 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 634 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 645 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 655 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 665 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 675 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 686 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 696 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 706 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 716 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 727 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 737 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 747 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 757 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 768 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 778 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 788 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 798 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 808 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 819 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 829 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 839 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 849 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 860 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 870 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 880 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 890 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 901 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 911 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 921 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 931 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 942 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 952 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 962 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 972 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 983 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 993 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.0 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.0 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.0 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.0 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.0 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.1 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.1 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.1 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.1 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.1 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.1 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.1 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.2 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.2 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.2 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.3 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.3 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.3 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.3 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.3 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.3 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.3 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.4 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.4 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.4 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.4 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.4 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.4 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4 MB 2.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4 MB 2.1 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","source":["pip install datasets --quiet"],"metadata":{"id":"OaOSPMJE3ONc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658953284205,"user_tz":420,"elapsed":7754,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"297c0850-c860-4296-d3af-1288a9403962"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 365 kB 2.1 MB/s \n","\u001b[K     |████████████████████████████████| 140 kB 54.7 MB/s \n","\u001b[K     |████████████████████████████████| 212 kB 62.5 MB/s \n","\u001b[K     |████████████████████████████████| 127 kB 70.5 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""],"metadata":{"id":"hRSNYTrRIPkr"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wrRRZJ6-0_Il"},"outputs":[],"source":["from captum.attr import visualization as viz\n","from captum.attr import IntegratedGradients, LayerConductance, LayerIntegratedGradients\n","from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer\n","\n","import torch\n","import pandas as pd"]},{"cell_type":"markdown","source":["## Import model"],"metadata":{"id":"USHRv2j70Fb4"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"b5V31lsc0_Il"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9nzBfB-v0_Im","colab":{"base_uri":"https://localhost:8080/","height":256,"referenced_widgets":["a44cebbdc1164013a912ecc9a1189f2d","d69319ff6f57485b84c4d6fa9fd2507a","acfa0706197e421bb1b7bdbe255e8014","1b7beb2afa67415b836bf79eb7096fe9","9f434b761e4941a9a345f2eac2f91e9b","025a88af5b474da599b253ccad88304c","31d682a7714642b8aabcba4121ab97cf","58aad7598acd41b1b91268a094ea1352","a359f73ad7f045a9b037eb1cd878e448","c5c7fa5733194e89a958e5b576a18646","818fbe98502d46f797a86b590c0a7b66","0d37f23dd55e4eb4a4b3bcc408ce2aef","74f5ffbdcb0b400c86d20f477cc71152","d865b1a083e24a15904d9c338a9a6bf5","f1fe40521b44415db63bdd8e901317d9","682f9ebedfee4560beb7859c16d5e80a","255d842779c248f1b15fd217d83dc165","d92ca6d4c0d9411da9f0e1d0e06ac062","e80656f99acf40df8de27079e2505f19","9b952aa20d8c4a788b822f173b12cc6f","1833b17f46974710be7cc4e1141f0866","4ab94d513f8e47938a0172d04a8ff470","1b76b406955541c7acf3af529fc4d3f5","f54f62e954f64b389970ced7f009edfa","35e6f9771bea4f6483b9961ef8ced330","79911cfe39df4522b6d40064cc67a68b","18eafc95e0844ba3a8c0b3a147858935","67f8e26ba9d84c9795122fac9a996581","c35656bb55a6422994c86b1915c09c7b","ea47dfddd7984985aa4f148a41ba433b","b061463d841d4891a5d18595024a3b72","3fe26e4e03574ae3ae46c18f2ddb4e97","d6167b53d4a64eb39e742e3459e39e5c","64c5f036cac942b1b99083ed41d320b7","d7f275a382e8407fa33c42da38b2b81c","3d4da032fdfb4ad290d40c93b344e9a9","def71dfb2ee94f8ab0ef940a5759f88a","268f1da052324841a4b29220ce18f8ac","d30088da53204c15ac197cea33aaccbf","f1515ff8d09c44f6b016607459300226","9cf6623eaf944cd1b6e388f58d459d70","8a470c6f635c40e88275bf3856b2adac","f73f86063f644f519e5382376dac9f3e","6c8e4185f3664073bca248c138c1dec4"]},"executionInfo":{"status":"ok","timestamp":1658953327529,"user_tz":420,"elapsed":39864,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"e621e8dc-c3e7-4b2f-dc19-5002129bf41a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a44cebbdc1164013a912ecc9a1189f2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/570M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d37f23dd55e4eb4a4b3bcc408ce2aef"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['longformer_model.encoder.layer.8.intermediate.dense.weight', 'longformer_model.encoder.layer.10.attention.self.query.bias', 'longformer_model.encoder.layer.6.attention.self.query.bias', 'longformer_model.encoder.layer.5.attention.self.query_global.bias', 'longformer_model.encoder.layer.8.attention.self.value_global.weight', 'longformer_model.encoder.layer.1.attention.self.key.weight', 'longformer_model.encoder.layer.3.attention.output.dense.bias', 'longformer_model.encoder.layer.9.attention.self.query.bias', 'longformer_model.encoder.layer.9.attention.output.dense.weight', 'longformer_model.encoder.layer.2.intermediate.dense.weight', 'longformer_model.encoder.layer.3.attention.self.key_global.bias', 'longformer_model.encoder.layer.6.attention.self.key.weight', 'fc.bias', 'longformer_model.encoder.layer.3.attention.self.query_global.weight', 'longformer_model.encoder.layer.8.attention.self.key_global.bias', 'longformer_model.encoder.layer.7.attention.self.value.weight', 'longformer_model.encoder.layer.11.intermediate.dense.bias', 'longformer_model.encoder.layer.2.attention.self.value_global.weight', 'dense.bias', 'longformer_model.encoder.layer.0.attention.self.key_global.bias', 'longformer_model.encoder.layer.2.output.dense.bias', 'longformer_model.encoder.layer.11.output.dense.bias', 'longformer_model.encoder.layer.11.attention.self.query.weight', 'longformer_model.encoder.layer.10.attention.self.query_global.weight', 'longformer_model.encoder.layer.10.attention.self.value.weight', 'longformer_model.encoder.layer.6.attention.self.value.weight', 'longformer_model.embeddings.token_type_embeddings.weight', 'longformer_model.encoder.layer.2.attention.self.value.bias', 'longformer_model.encoder.layer.5.attention.self.query_global.weight', 'longformer_model.encoder.layer.8.attention.self.query.weight', 'longformer_model.encoder.layer.4.intermediate.dense.bias', 'longformer_model.encoder.layer.8.attention.self.key.bias', 'longformer_model.encoder.layer.9.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.0.attention.output.dense.weight', 'longformer_model.encoder.layer.0.output.LayerNorm.weight', 'longformer_model.encoder.layer.3.attention.self.query.bias', 'longformer_model.encoder.layer.3.attention.self.value_global.bias', 'longformer_model.encoder.layer.9.intermediate.dense.bias', 'longformer_model.encoder.layer.3.attention.self.key.weight', 'dense.weight', 'longformer_model.encoder.layer.4.attention.self.key_global.bias', 'longformer_model.encoder.layer.0.intermediate.dense.bias', 'longformer_model.encoder.layer.1.intermediate.dense.bias', 'longformer_model.encoder.layer.4.attention.self.value.weight', 'longformer_model.encoder.layer.6.attention.self.value_global.bias', 'longformer_model.encoder.layer.1.attention.self.key_global.weight', 'longformer_model.encoder.layer.7.attention.output.dense.bias', 'longformer_model.encoder.layer.9.attention.self.value.bias', 'longformer_model.encoder.layer.1.attention.self.key.bias', 'longformer_model.encoder.layer.7.attention.self.query_global.weight', 'longformer_model.encoder.layer.6.attention.self.query.weight', 'longformer_model.encoder.layer.11.attention.self.query_global.weight', 'longformer_model.encoder.layer.6.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.0.attention.output.dense.bias', 'longformer_model.encoder.layer.4.attention.self.key.weight', 'longformer_model.encoder.layer.1.output.LayerNorm.weight', 'longformer_model.encoder.layer.2.intermediate.dense.bias', 'longformer_model.encoder.layer.1.attention.self.value_global.weight', 'longformer_model.encoder.layer.3.attention.self.key_global.weight', 'longformer_model.encoder.layer.2.attention.output.dense.weight', 'longformer_model.encoder.layer.5.output.LayerNorm.weight', 'longformer_model.encoder.layer.1.attention.self.query.weight', 'longformer_model.encoder.layer.2.attention.self.query_global.bias', 'longformer_model.encoder.layer.4.attention.self.value_global.weight', 'longformer_model.encoder.layer.0.output.LayerNorm.bias', 'longformer_model.encoder.layer.5.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.9.attention.self.value_global.bias', 'longformer_model.encoder.layer.6.intermediate.dense.weight', 'longformer_model.encoder.layer.11.attention.self.value.bias', 'longformer_model.embeddings.position_ids', 'longformer_model.encoder.layer.1.intermediate.dense.weight', 'longformer_model.encoder.layer.2.attention.self.query.weight', 'longformer_model.encoder.layer.8.attention.self.query_global.weight', 'longformer_model.encoder.layer.2.attention.self.value.weight', 'longformer_model.encoder.layer.7.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.3.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.9.attention.self.query.weight', 'longformer_model.encoder.layer.10.attention.self.key_global.bias', 'longformer_model.encoder.layer.9.output.dense.weight', 'longformer_model.encoder.layer.4.attention.self.query.bias', 'longformer_model.encoder.layer.5.attention.self.query.weight', 'longformer_model.encoder.layer.11.intermediate.dense.weight', 'longformer_model.encoder.layer.8.attention.self.value.bias', 'longformer_model.encoder.layer.9.output.LayerNorm.bias', 'longformer_model.encoder.layer.1.attention.self.value_global.bias', 'longformer_model.encoder.layer.5.attention.self.value_global.bias', 'longformer_model.embeddings.position_embeddings.weight', 'longformer_model.encoder.layer.1.output.dense.bias', 'longformer_model.encoder.layer.4.output.LayerNorm.bias', 'longformer_model.encoder.layer.11.output.LayerNorm.bias', 'longformer_model.encoder.layer.3.attention.self.value.weight', 'longformer_model.encoder.layer.7.attention.self.key.bias', 'longformer_model.encoder.layer.7.attention.self.key_global.bias', 'longformer_model.encoder.layer.3.attention.self.key.bias', 'longformer_model.encoder.layer.3.attention.self.query_global.bias', 'longformer_model.encoder.layer.10.attention.output.dense.bias', 'longformer_model.encoder.layer.4.output.dense.weight', 'longformer_model.encoder.layer.9.attention.self.key_global.bias', 'longformer_model.embeddings.word_embeddings.weight', 'longformer_model.encoder.layer.3.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.2.output.LayerNorm.bias', 'longformer_model.encoder.layer.5.attention.self.value.weight', 'longformer_model.encoder.layer.5.output.dense.bias', 'longformer_model.encoder.layer.3.intermediate.dense.weight', 'longformer_model.encoder.layer.7.attention.self.value_global.weight', 'longformer_model.encoder.layer.8.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.6.attention.self.query_global.weight', 'longformer_model.encoder.layer.8.attention.self.query_global.bias', 'longformer_model.encoder.layer.10.intermediate.dense.weight', 'longformer_model.encoder.layer.8.output.LayerNorm.weight', 'longformer_model.encoder.layer.10.attention.self.key.weight', 'longformer_model.encoder.layer.10.output.dense.weight', 'longformer_model.encoder.layer.1.output.dense.weight', 'longformer_model.encoder.layer.2.attention.output.dense.bias', 'longformer_model.encoder.layer.0.attention.self.value_global.weight', 'longformer_model.encoder.layer.7.attention.self.query.bias', 'longformer_model.encoder.layer.2.attention.self.key.weight', 'longformer_model.encoder.layer.0.attention.self.key.bias', 'longformer_model.encoder.layer.3.output.LayerNorm.weight', 'longformer_model.encoder.layer.10.attention.self.value_global.weight', 'longformer_model.encoder.layer.3.output.LayerNorm.bias', 'longformer_model.encoder.layer.4.intermediate.dense.weight', 'longformer_model.encoder.layer.7.output.LayerNorm.bias', 'longformer_model.encoder.layer.2.attention.self.query.bias', 'longformer_model.encoder.layer.7.intermediate.dense.weight', 'longformer_model.encoder.layer.9.attention.self.query_global.bias', 'longformer_model.encoder.layer.6.attention.self.key_global.bias', 'longformer_model.encoder.layer.1.attention.self.query_global.weight', 'longformer_model.encoder.layer.7.output.dense.bias', 'longformer_model.encoder.layer.6.intermediate.dense.bias', 'longformer_model.encoder.layer.0.output.dense.weight', 'longformer_model.encoder.layer.8.attention.self.key.weight', 'longformer_model.encoder.layer.6.output.dense.bias', 'longformer_model.encoder.layer.9.attention.self.query_global.weight', 'longformer_model.encoder.layer.9.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.7.attention.self.query.weight', 'longformer_model.encoder.layer.10.output.dense.bias', 'longformer_model.encoder.layer.2.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.11.output.LayerNorm.weight', 'longformer_model.encoder.layer.2.attention.self.key_global.weight', 'longformer_model.encoder.layer.2.attention.self.query_global.weight', 'longformer_model.encoder.layer.10.output.LayerNorm.weight', 'longformer_model.encoder.layer.11.attention.self.key.bias', 'longformer_model.encoder.layer.7.attention.self.key.weight', 'longformer_model.encoder.layer.3.attention.self.value_global.weight', 'longformer_model.encoder.layer.2.attention.self.key.bias', 'longformer_model.encoder.layer.10.attention.self.key_global.weight', 'longformer_model.encoder.layer.2.output.dense.weight', 'fc.weight', 'longformer_model.encoder.layer.2.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.5.attention.self.key.weight', 'longformer_model.encoder.layer.7.intermediate.dense.bias', 'longformer_model.encoder.layer.10.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.4.output.LayerNorm.weight', 'longformer_model.encoder.layer.0.attention.self.key.weight', 'longformer_model.encoder.layer.6.output.LayerNorm.bias', 'longformer_model.encoder.layer.10.attention.self.query.weight', 'longformer_model.encoder.layer.1.attention.output.dense.weight', 'longformer_model.encoder.layer.9.attention.self.value_global.weight', 'longformer_model.encoder.layer.6.attention.output.dense.bias', 'longformer_model.encoder.layer.7.output.LayerNorm.weight', 'longformer_model.encoder.layer.7.attention.self.value_global.bias', 'longformer_model.encoder.layer.6.attention.self.key_global.weight', 'longformer_model.encoder.layer.8.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.8.output.dense.bias', 'longformer_model.encoder.layer.6.output.LayerNorm.weight', 'longformer_model.encoder.layer.11.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.5.attention.self.value.bias', 'longformer_model.encoder.layer.6.attention.self.value.bias', 'longformer_model.encoder.layer.0.attention.self.value.bias', 'longformer_model.encoder.layer.0.output.dense.bias', 'longformer_model.encoder.layer.10.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.0.attention.self.query.weight', 'longformer_model.encoder.layer.5.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.3.intermediate.dense.bias', 'longformer_model.encoder.layer.5.attention.output.dense.bias', 'longformer_model.encoder.layer.10.attention.output.dense.weight', 'longformer_model.encoder.layer.5.attention.self.key_global.weight', 'longformer_model.encoder.layer.7.attention.self.key_global.weight', 'longformer_model.encoder.layer.3.output.dense.bias', 'longformer_model.encoder.layer.11.output.dense.weight', 'longformer_model.encoder.layer.4.attention.self.query_global.bias', 'longformer_model.encoder.layer.4.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.3.output.dense.weight', 'longformer_model.encoder.layer.10.attention.self.value_global.bias', 'longformer_model.encoder.layer.9.attention.self.key_global.weight', 'longformer_model.encoder.layer.8.attention.output.dense.weight', 'longformer_model.encoder.layer.2.attention.self.value_global.bias', 'longformer_model.encoder.layer.5.intermediate.dense.bias', 'longformer_model.encoder.layer.3.attention.output.dense.weight', 'longformer_model.encoder.layer.4.output.dense.bias', 'longformer_model.encoder.layer.0.attention.self.value.weight', 'longformer_model.encoder.layer.11.attention.self.key_global.weight', 'longformer_model.encoder.layer.0.attention.self.query_global.weight', 'longformer_model.embeddings.LayerNorm.weight', 'longformer_model.encoder.layer.8.output.LayerNorm.bias', 'longformer_model.encoder.layer.1.attention.self.query.bias', 'longformer_model.encoder.layer.1.attention.output.dense.bias', 'longformer_model.encoder.layer.1.attention.self.value.weight', 'longformer_model.encoder.layer.4.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.5.attention.self.key_global.bias', 'longformer_model.encoder.layer.4.attention.self.key_global.weight', 'longformer_model.encoder.layer.2.output.LayerNorm.weight', 'longformer_model.encoder.layer.11.attention.self.value_global.bias', 'longformer_model.encoder.layer.6.attention.output.dense.weight', 'longformer_model.encoder.layer.11.attention.self.key_global.bias', 'longformer_model.encoder.layer.9.intermediate.dense.weight', 'longformer_model.encoder.layer.0.attention.self.value_global.bias', 'longformer_model.encoder.layer.0.attention.self.query_global.bias', 'longformer_model.encoder.layer.4.attention.self.query_global.weight', 'longformer_model.encoder.layer.5.output.dense.weight', 'longformer_model.encoder.layer.9.attention.self.key.weight', 'longformer_model.encoder.layer.10.intermediate.dense.bias', 'longformer_model.encoder.layer.6.output.dense.weight', 'longformer_model.encoder.layer.0.intermediate.dense.weight', 'longformer_model.embeddings.LayerNorm.bias', 'longformer_model.encoder.layer.5.attention.self.query.bias', 'longformer_model.encoder.layer.8.attention.self.key_global.weight', 'longformer_model.encoder.layer.3.attention.self.value.bias', 'longformer_model.encoder.layer.11.attention.self.query.bias', 'longformer_model.encoder.layer.11.attention.self.query_global.bias', 'longformer_model.encoder.layer.5.attention.output.dense.weight', 'longformer_model.encoder.layer.4.attention.self.key.bias', 'longformer_model.encoder.layer.2.attention.self.key_global.bias', 'longformer_model.encoder.layer.11.attention.output.dense.bias', 'longformer_model.encoder.layer.10.output.LayerNorm.bias', 'longformer_model.encoder.layer.8.intermediate.dense.bias', 'longformer_model.encoder.layer.1.attention.self.value.bias', 'longformer_model.encoder.layer.1.attention.self.key_global.bias', 'longformer_model.encoder.layer.7.output.dense.weight', 'longformer_model.encoder.layer.8.attention.output.dense.bias', 'longformer_model.encoder.layer.1.attention.self.query_global.bias', 'longformer_model.encoder.layer.6.attention.self.query_global.bias', 'longformer_model.encoder.layer.5.output.LayerNorm.bias', 'longformer_model.encoder.layer.7.attention.output.dense.weight', 'longformer_model.encoder.layer.9.attention.self.value.weight', 'longformer_model.encoder.layer.5.attention.self.key.bias', 'longformer_model.encoder.layer.7.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.11.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.8.output.dense.weight', 'longformer_model.encoder.layer.4.attention.self.value.bias', 'longformer_model.encoder.layer.6.attention.self.value_global.weight', 'longformer_model.encoder.layer.4.attention.output.dense.weight', 'longformer_model.encoder.layer.11.attention.self.value.weight', 'longformer_model.encoder.layer.10.attention.self.key.bias', 'longformer_model.encoder.layer.11.attention.self.key.weight', 'longformer_model.encoder.layer.1.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.5.attention.self.value_global.weight', 'longformer_model.encoder.layer.4.attention.self.value_global.bias', 'longformer_model.encoder.layer.6.attention.self.key.bias', 'longformer_model.encoder.layer.1.output.LayerNorm.bias', 'longformer_model.encoder.layer.4.attention.output.dense.bias', 'longformer_model.encoder.layer.6.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.9.attention.output.dense.bias', 'longformer_model.encoder.layer.11.attention.output.dense.weight', 'longformer_model.encoder.layer.8.attention.self.value.weight', 'longformer_model.encoder.layer.11.attention.self.value_global.weight', 'longformer_model.encoder.layer.0.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.7.attention.self.value.bias', 'longformer_model.encoder.layer.8.attention.self.value_global.bias', 'longformer_model.encoder.layer.0.attention.self.key_global.weight', 'longformer_model.encoder.layer.7.attention.self.query_global.bias', 'longformer_model.encoder.layer.9.output.dense.bias', 'longformer_model.encoder.layer.1.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.9.output.LayerNorm.weight', 'longformer_model.encoder.layer.3.attention.self.query.weight', 'longformer_model.encoder.layer.5.intermediate.dense.weight', 'longformer_model.encoder.layer.8.attention.self.query.bias', 'longformer_model.encoder.layer.10.attention.self.value.bias', 'longformer_model.encoder.layer.4.attention.self.query.weight', 'longformer_model.encoder.layer.10.attention.self.query_global.bias', 'longformer_model.encoder.layer.0.attention.self.query.bias', 'longformer_model.encoder.layer.0.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.9.attention.self.key.bias']\n","- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['longformer.encoder.layer.5.attention.self.value.bias', 'longformer.encoder.layer.0.attention.self.value_global.weight', 'longformer.encoder.layer.2.attention.output.LayerNorm.bias', 'longformer.embeddings.position_embeddings.weight', 'longformer.encoder.layer.7.attention.output.LayerNorm.bias', 'longformer.encoder.layer.5.attention.self.query_global.bias', 'longformer.encoder.layer.8.attention.self.value.bias', 'longformer.encoder.layer.6.output.LayerNorm.bias', 'longformer.encoder.layer.10.attention.self.key_global.bias', 'longformer.encoder.layer.1.attention.output.LayerNorm.bias', 'longformer.encoder.layer.8.intermediate.dense.weight', 'longformer.encoder.layer.11.attention.output.dense.weight', 'longformer.encoder.layer.6.output.dense.bias', 'longformer.encoder.layer.2.attention.self.key_global.weight', 'longformer.encoder.layer.1.output.dense.weight', 'longformer.encoder.layer.1.output.dense.bias', 'longformer.encoder.layer.0.attention.output.dense.weight', 'longformer.encoder.layer.6.attention.self.query_global.weight', 'longformer.encoder.layer.6.attention.self.query_global.bias', 'longformer.encoder.layer.5.attention.self.query.bias', 'longformer.encoder.layer.7.output.LayerNorm.weight', 'longformer.encoder.layer.11.attention.output.dense.bias', 'longformer.encoder.layer.2.attention.self.query.bias', 'longformer.encoder.layer.8.attention.output.dense.weight', 'longformer.encoder.layer.2.attention.self.query.weight', 'longformer.encoder.layer.5.intermediate.dense.weight', 'longformer.encoder.layer.9.attention.self.key_global.weight', 'longformer.encoder.layer.8.attention.output.dense.bias', 'longformer.encoder.layer.6.attention.self.value_global.weight', 'longformer.encoder.layer.9.attention.output.dense.bias', 'longformer.encoder.layer.3.attention.self.key_global.bias', 'longformer.encoder.layer.6.attention.self.key.weight', 'longformer.encoder.layer.2.attention.self.query_global.weight', 'longformer.encoder.layer.5.attention.output.LayerNorm.weight', 'longformer.encoder.layer.6.attention.self.value_global.bias', 'longformer.encoder.layer.10.attention.self.key.bias', 'longformer.encoder.layer.10.output.LayerNorm.bias', 'longformer.encoder.layer.6.output.LayerNorm.weight', 'longformer.encoder.layer.7.attention.self.value_global.weight', 'longformer.encoder.layer.8.attention.self.query.weight', 'longformer.encoder.layer.0.attention.self.query_global.weight', 'longformer.encoder.layer.1.attention.self.value.weight', 'longformer.encoder.layer.2.attention.output.LayerNorm.weight', 'longformer.encoder.layer.6.attention.self.key.bias', 'longformer.encoder.layer.7.attention.self.key.bias', 'longformer.encoder.layer.10.attention.self.value.weight', 'classifier.out_proj.weight', 'longformer.encoder.layer.10.output.dense.weight', 'longformer.encoder.layer.0.attention.self.query.bias', 'longformer.encoder.layer.4.attention.self.value.bias', 'longformer.encoder.layer.2.attention.output.dense.weight', 'longformer.encoder.layer.3.attention.self.key_global.weight', 'longformer.encoder.layer.4.attention.self.key.bias', 'longformer.encoder.layer.5.output.dense.weight', 'longformer.encoder.layer.5.output.LayerNorm.weight', 'longformer.encoder.layer.2.output.dense.bias', 'longformer.encoder.layer.1.attention.self.key.bias', 'longformer.encoder.layer.11.attention.self.key.weight', 'longformer.encoder.layer.1.intermediate.dense.bias', 'longformer.encoder.layer.8.attention.self.value_global.bias', 'longformer.encoder.layer.0.output.dense.bias', 'longformer.encoder.layer.1.attention.output.dense.bias', 'longformer.encoder.layer.8.attention.self.key_global.weight', 'longformer.encoder.layer.5.intermediate.dense.bias', 'longformer.encoder.layer.6.intermediate.dense.weight', 'longformer.encoder.layer.3.attention.self.query_global.weight', 'longformer.encoder.layer.6.intermediate.dense.bias', 'longformer.encoder.layer.9.attention.output.dense.weight', 'longformer.encoder.layer.8.attention.self.value_global.weight', 'longformer.encoder.layer.11.attention.self.key_global.weight', 'longformer.encoder.layer.9.output.LayerNorm.bias', 'longformer.encoder.layer.1.attention.output.LayerNorm.weight', 'longformer.encoder.layer.11.attention.self.key.bias', 'longformer.encoder.layer.3.output.LayerNorm.bias', 'longformer.encoder.layer.4.attention.output.LayerNorm.bias', 'longformer.encoder.layer.7.output.dense.bias', 'longformer.encoder.layer.11.intermediate.dense.bias', 'longformer.encoder.layer.9.output.dense.weight', 'longformer.encoder.layer.9.attention.self.query_global.weight', 'longformer.encoder.layer.11.attention.self.query.weight', 'longformer.encoder.layer.10.attention.self.value.bias', 'longformer.encoder.layer.5.attention.self.query.weight', 'longformer.encoder.layer.4.output.dense.weight', 'longformer.encoder.layer.9.attention.self.key_global.bias', 'longformer.encoder.layer.1.attention.self.query.bias', 'longformer.encoder.layer.4.attention.self.key.weight', 'longformer.encoder.layer.2.intermediate.dense.bias', 'longformer.encoder.layer.5.attention.self.key.weight', 'longformer.encoder.layer.2.output.dense.weight', 'longformer.encoder.layer.3.attention.output.LayerNorm.weight', 'longformer.encoder.layer.6.attention.output.LayerNorm.weight', 'longformer.encoder.layer.3.attention.self.key.bias', 'longformer.encoder.layer.1.attention.self.query.weight', 'longformer.embeddings.LayerNorm.bias', 'longformer.encoder.layer.0.attention.self.key_global.bias', 'longformer.encoder.layer.3.attention.output.dense.bias', 'longformer.encoder.layer.9.attention.self.query_global.bias', 'longformer.encoder.layer.3.intermediate.dense.bias', 'longformer.encoder.layer.2.attention.output.dense.bias', 'longformer.encoder.layer.8.attention.self.query.bias', 'longformer.encoder.layer.9.attention.self.value.bias', 'longformer.encoder.layer.3.attention.self.key.weight', 'longformer.embeddings.token_type_embeddings.weight', 'longformer.encoder.layer.11.intermediate.dense.weight', 'longformer.encoder.layer.8.attention.output.LayerNorm.bias', 'longformer.encoder.layer.8.output.LayerNorm.bias', 'longformer.encoder.layer.4.attention.output.dense.weight', 'longformer.encoder.layer.9.attention.self.query.weight', 'longformer.encoder.layer.7.attention.self.query.weight', 'longformer.encoder.layer.1.attention.self.value_global.weight', 'longformer.encoder.layer.11.output.dense.bias', 'longformer.encoder.layer.1.attention.self.key.weight', 'longformer.encoder.layer.1.attention.self.query_global.weight', 'longformer.encoder.layer.11.output.dense.weight', 'longformer.encoder.layer.11.attention.self.value_global.weight', 'longformer.encoder.layer.9.attention.self.value_global.weight', 'longformer.encoder.layer.2.attention.self.value.weight', 'longformer.encoder.layer.1.attention.self.key_global.weight', 'longformer.encoder.layer.4.output.LayerNorm.weight', 'classifier.dense.weight', 'longformer.encoder.layer.3.attention.self.value.bias', 'longformer.encoder.layer.8.attention.self.key_global.bias', 'longformer.encoder.layer.3.attention.self.query.weight', 'longformer.encoder.layer.7.attention.output.LayerNorm.weight', 'longformer.encoder.layer.2.attention.self.query_global.bias', 'longformer.encoder.layer.6.attention.self.query.bias', 'longformer.encoder.layer.7.attention.self.value.weight', 'longformer.encoder.layer.10.output.LayerNorm.weight', 'longformer.encoder.layer.9.output.LayerNorm.weight', 'longformer.encoder.layer.11.output.LayerNorm.weight', 'longformer.encoder.layer.8.attention.self.key.bias', 'longformer.encoder.layer.0.attention.self.value.bias', 'longformer.encoder.layer.1.output.LayerNorm.bias', 'longformer.encoder.layer.0.attention.output.LayerNorm.bias', 'longformer.encoder.layer.2.attention.self.value.bias', 'longformer.encoder.layer.3.attention.self.value.weight', 'longformer.encoder.layer.4.attention.self.value.weight', 'longformer.encoder.layer.4.output.LayerNorm.bias', 'longformer.encoder.layer.1.attention.self.key_global.bias', 'longformer.encoder.layer.10.attention.self.value_global.bias', 'longformer.encoder.layer.0.attention.output.dense.bias', 'longformer.encoder.layer.5.attention.self.key_global.weight', 'longformer.encoder.layer.7.attention.self.key_global.bias', 'longformer.encoder.layer.0.attention.self.key_global.weight', 'longformer.embeddings.LayerNorm.weight', 'longformer.encoder.layer.4.attention.self.query_global.bias', 'longformer.encoder.layer.3.attention.self.query_global.bias', 'longformer.encoder.layer.2.attention.self.value_global.weight', 'longformer.encoder.layer.8.output.LayerNorm.weight', 'longformer.encoder.layer.11.attention.output.LayerNorm.bias', 'longformer.encoder.layer.6.output.dense.weight', 'longformer.encoder.layer.7.attention.self.query.bias', 'longformer.encoder.layer.9.intermediate.dense.bias', 'longformer.encoder.layer.0.attention.self.value_global.bias', 'longformer.encoder.layer.6.attention.self.key_global.weight', 'longformer.encoder.layer.7.attention.self.key.weight', 'classifier.dense.bias', 'longformer.encoder.layer.5.output.LayerNorm.bias', 'longformer.encoder.layer.10.attention.self.query_global.weight', 'longformer.encoder.layer.8.attention.self.value.weight', 'longformer.encoder.layer.3.intermediate.dense.weight', 'longformer.embeddings.word_embeddings.weight', 'longformer.encoder.layer.8.attention.self.key.weight', 'longformer.encoder.layer.0.attention.self.query.weight', 'longformer.encoder.layer.2.intermediate.dense.weight', 'longformer.encoder.layer.9.attention.self.query.bias', 'classifier.out_proj.bias', 'longformer.encoder.layer.7.attention.self.query_global.weight', 'longformer.encoder.layer.3.attention.self.value_global.weight', 'longformer.encoder.layer.5.attention.self.value_global.bias', 'longformer.encoder.layer.10.attention.self.key_global.weight', 'longformer.encoder.layer.3.attention.output.LayerNorm.bias', 'longformer.encoder.layer.5.attention.self.value.weight', 'longformer.encoder.layer.0.intermediate.dense.weight', 'longformer.encoder.layer.4.output.dense.bias', 'longformer.encoder.layer.4.intermediate.dense.bias', 'longformer.encoder.layer.5.attention.self.key.bias', 'longformer.encoder.layer.5.attention.output.dense.weight', 'longformer.encoder.layer.0.output.LayerNorm.weight', 'longformer.encoder.layer.9.attention.output.LayerNorm.weight', 'longformer.encoder.layer.10.intermediate.dense.weight', 'longformer.encoder.layer.11.attention.self.query_global.bias', 'longformer.encoder.layer.11.attention.output.LayerNorm.weight', 'longformer.encoder.layer.10.attention.output.dense.bias', 'longformer.encoder.layer.4.attention.output.dense.bias', 'longformer.encoder.layer.5.output.dense.bias', 'longformer.encoder.layer.4.attention.self.query.bias', 'longformer.encoder.layer.5.attention.output.dense.bias', 'longformer.encoder.layer.9.attention.self.value.weight', 'longformer.encoder.layer.8.attention.output.LayerNorm.weight', 'longformer.encoder.layer.10.output.dense.bias', 'longformer.encoder.layer.11.attention.self.value_global.bias', 'longformer.encoder.layer.11.attention.self.value.weight', 'longformer.encoder.layer.10.attention.self.key.weight', 'longformer.encoder.layer.4.attention.self.key_global.bias', 'longformer.encoder.layer.6.attention.output.LayerNorm.bias', 'longformer.encoder.layer.9.attention.self.key.bias', 'longformer.encoder.layer.3.attention.output.dense.weight', 'longformer.encoder.layer.0.attention.self.query_global.bias', 'longformer.encoder.layer.1.attention.output.dense.weight', 'longformer.encoder.layer.10.attention.self.value_global.weight', 'longformer.encoder.layer.6.attention.self.value.weight', 'longformer.encoder.layer.2.attention.self.key.weight', 'longformer.encoder.layer.11.attention.self.query_global.weight', 'longformer.encoder.layer.10.attention.self.query.bias', 'longformer.encoder.layer.11.attention.self.value.bias', 'longformer.encoder.layer.7.attention.output.dense.weight', 'longformer.encoder.layer.0.attention.self.value.weight', 'longformer.encoder.layer.1.intermediate.dense.weight', 'longformer.encoder.layer.2.attention.self.value_global.bias', 'longformer.encoder.layer.7.intermediate.dense.weight', 'longformer.encoder.layer.5.attention.self.query_global.weight', 'longformer.encoder.layer.8.output.dense.weight', 'longformer.encoder.layer.9.attention.output.LayerNorm.bias', 'longformer.encoder.layer.11.attention.self.key_global.bias', 'longformer.encoder.layer.2.attention.self.key.bias', 'longformer.encoder.layer.5.attention.self.key_global.bias', 'longformer.encoder.layer.4.attention.self.value_global.weight', 'longformer.encoder.layer.4.attention.self.query.weight', 'longformer.encoder.layer.6.attention.self.query.weight', 'longformer.encoder.layer.8.intermediate.dense.bias', 'longformer.encoder.layer.9.attention.self.value_global.bias', 'longformer.encoder.layer.9.output.dense.bias', 'longformer.encoder.layer.10.attention.output.LayerNorm.bias', 'longformer.encoder.layer.7.output.LayerNorm.bias', 'longformer.encoder.layer.0.attention.output.LayerNorm.weight', 'longformer.encoder.layer.7.attention.output.dense.bias', 'longformer.encoder.layer.1.attention.self.query_global.bias', 'longformer.encoder.layer.11.output.LayerNorm.bias', 'longformer.encoder.layer.3.attention.self.query.bias', 'longformer.encoder.layer.6.attention.self.value.bias', 'longformer.encoder.layer.7.attention.self.value.bias', 'longformer.encoder.layer.3.output.dense.bias', 'longformer.encoder.layer.4.attention.output.LayerNorm.weight', 'longformer.encoder.layer.4.intermediate.dense.weight', 'longformer.encoder.layer.8.attention.self.query_global.bias', 'longformer.encoder.layer.10.intermediate.dense.bias', 'longformer.encoder.layer.1.attention.self.value.bias', 'longformer.encoder.layer.10.attention.self.query.weight', 'longformer.encoder.layer.3.output.dense.weight', 'longformer.encoder.layer.11.attention.self.query.bias', 'longformer.encoder.layer.1.attention.self.value_global.bias', 'longformer.encoder.layer.6.attention.output.dense.weight', 'longformer.encoder.layer.6.attention.output.dense.bias', 'longformer.encoder.layer.0.intermediate.dense.bias', 'longformer.encoder.layer.7.attention.self.key_global.weight', 'longformer.encoder.layer.3.output.LayerNorm.weight', 'longformer.encoder.layer.4.attention.self.value_global.bias', 'longformer.encoder.layer.0.attention.self.key.weight', 'longformer.encoder.layer.6.attention.self.key_global.bias', 'longformer.encoder.layer.7.attention.self.value_global.bias', 'longformer.encoder.layer.7.intermediate.dense.bias', 'longformer.encoder.layer.10.attention.self.query_global.bias', 'longformer.encoder.layer.4.attention.self.query_global.weight', 'longformer.encoder.layer.4.attention.self.key_global.weight', 'longformer.encoder.layer.10.attention.output.dense.weight', 'longformer.encoder.layer.1.output.LayerNorm.weight', 'longformer.encoder.layer.8.attention.self.query_global.weight', 'longformer.encoder.layer.2.output.LayerNorm.bias', 'longformer.encoder.layer.0.output.LayerNorm.bias', 'longformer.encoder.layer.2.output.LayerNorm.weight', 'longformer.encoder.layer.0.attention.self.key.bias', 'longformer.encoder.layer.0.output.dense.weight', 'longformer.encoder.layer.5.attention.self.value_global.weight', 'longformer.encoder.layer.2.attention.self.key_global.bias', 'longformer.encoder.layer.8.output.dense.bias', 'longformer.encoder.layer.7.output.dense.weight', 'longformer.encoder.layer.9.attention.self.key.weight', 'longformer.encoder.layer.10.attention.output.LayerNorm.weight', 'longformer.encoder.layer.5.attention.output.LayerNorm.bias', 'longformer.encoder.layer.7.attention.self.query_global.bias', 'longformer.encoder.layer.3.attention.self.value_global.bias', 'longformer.encoder.layer.9.intermediate.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading vocab.json:   0%|          | 0.00/878k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b76b406955541c7acf3af529fc4d3f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64c5f036cac942b1b99083ed41d320b7"}},"metadata":{}}],"source":["from transformers import LongformerForSequenceClassification, LongformerTokenizer, LongformerConfig\n","# replace <PATH-TO-SAVED-MODEL> with the real path of the saved model\n","model_path = 'danielhou13/longformer-finetuned_papers_v2'\n","# model_path = 'danielhou13/longformer-finetuned-news-cogs402'\n","\n","# load model\n","test = torch.load(\"/content/drive/MyDrive/fakeclinicalnotes/models/full_augmented_lr2e-5_dropout3_10_trained_threshold.pt\")\n","model = LongformerForSequenceClassification.from_pretrained('allenai/longformer-base-4096', state_dict=test['state_dict'], num_labels = 2)\n","model.to(device)\n","model.eval()\n","model.zero_grad()\n","\n","# load tokenizer\n","tokenizer = LongformerTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n"]},{"cell_type":"markdown","source":["## Import Dataset"],"metadata":{"id":"BdY6GsO00RG_"}},{"cell_type":"markdown","source":["Here we import the papers dataset"],"metadata":{"id":"e_gGIPpwkmbH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6aQM9nM0_Ip","colab":{"base_uri":"https://localhost:8080/","height":252,"referenced_widgets":["c16635239a46469c9026c05f4d21cbe8","38942eb3767a4e769d3cd2074fc0aae2","2f2017cb5a6a4147b4faf2b01c96364e","a58ebc6f6d46400b91f8b0a3d49e88b2","fc602c76a6ac438cb63dbdc819b59c2b","7eb92a073e194b09b977c73f5d8daf6c","5a8206b4356547189d230771d263720b","6ddf3f5fc5d64b148eb57f5f44b9370f","5fb133b3de0c4a03b5c7380d089fc061","d9ae0f64d82a468db6a5f229e421b4d7","f262b48d6d564bcc991ebc32d7037ad5","793a013fb0e24bcd8a2db194769b62ca","24159558d5d747ad883b359d1ad45151","da31972ada4e4be095e2e897f2363d18","0a426c1ac93346c38cd6d106b1a225ad","93ee51ecd025466dba5335f87424f668","2c1426c098204f8ba4b6dba953dcb241","115bfb8b317c455f80f8eb008491a922","d155889944304c37a5649f39b4b3b795","6249a6a1d7c34b408289c6a40891f54d","cf0f4e792ac544639daae630cedc6dab","43fbba667d384e42931c89a211f86573","cf41fbc1ba3b44bf813c26af9f3dea35","9d356ef06dd7487484dbdba440d818df","cf90a53300164c8c9eadeeaae02401ea","0aa3405159d74b99b574280680a16839","b4e36e54dca84381afb7c8f03cf757aa","4b2d179fed1e4636a4882d63290e43a9","932ea05f6ee244448462647ca84ab8a3","13e3398cf0e949e0a5aad4dc393c4752","2b11149bf931417694d72c8189321d27","b20e7adba444477fa26ed26bc8336efb","3b28d60243ad460299f91593099aca98","069f4a30024444b78d33ecde0bf0c703","c208df88858144fe84420d71c194ac24","5ff692bcabfa4e8b8266cd561a148687","1f81c83bf21a49a1881c85311e433898","6620529a9d714c458dc067db4c9b3ddb","21d7f0761a674251ab93d2733eb70a21","d5d4ebe675c64ee49cd9b25dddd8a382","d1ccdf4a554b4c7780440d33cf6924cb","2288ac8b5a0849ff8481f1f41f1d652a","39a9ff0abcf344d7bd89d4bc0103e59e","c22746e16fe948c997194ea0b492b7fb","505a8fe8b23342859028f6f4b88966d6","ea200c7139fe4f558b332ff99897f6e4","240bc18fd8194dacb80d72e1ed8e9e05","fa1a5b9b3d54440d860125efafe7f4e4","006910b188714070813124e9030208b5","07efc63aa0ce47648f5ac0a6d6315df6","3427fa43e0bf4850aeec60494bce1861","54f75b2ea1a646c6a387ca662812cd0a","c0776b4635db4cc6a582c67956f75d99","84014bf389fa453cb4942aae0899bc67","2de3b8dd1a3a4bc19340e12b58c871d9","b9189ba7ede8487a98734fd563df1fa4","92de11632ffa4cc09c6bf3fcd2963153","329b25146aa14f81ba5a299104b9de68","52cebbcc30144191b97304f36d4656bc","f0244612d7504c399981671287577e70","c3ffbd442d704daca9f4cc5a9896c472","68df5f49d45c4304bd30ba261d3a14d2","9b3c6d1004fd4ead807fdfc4087ad9a9","6501db91a5634362af03a2c45d83ba6c","9275fe134eba495f93a7c774da9867be","a86e1d28d0c54115b3f2975031bc8ae4"]},"executionInfo":{"status":"ok","timestamp":1658953334691,"user_tz":420,"elapsed":7170,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"37bd4cb4-9431-42f0-8aa0-32fa9d990ce0"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/613 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c16635239a46469c9026c05f4d21cbe8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Using custom data configuration danielhou13--cogs402datafake-f5349e6cf83e41d8\n"]},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset None/None (download: 59.78 KiB, generated: 114.45 KiB, post-processed: Unknown size, total: 174.22 KiB) to /root/.cache/huggingface/datasets/danielhou13___parquet/danielhou13--cogs402datafake-f5349e6cf83e41d8/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"793a013fb0e24bcd8a2db194769b62ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/61.2k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf41fbc1ba3b44bf813c26af9f3dea35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"069f4a30024444b78d33ecde0bf0c703"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["0 tables [00:00, ? tables/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"505a8fe8b23342859028f6f4b88966d6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/danielhou13___parquet/danielhou13--cogs402datafake-f5349e6cf83e41d8/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9189ba7ede8487a98734fd563df1fa4"}},"metadata":{}}],"source":["from datasets import load_dataset\n","import numpy as np\n","cogs402_ds = load_dataset(\"danielhou13/cogs402datafake\")[\"train\"]"]},{"cell_type":"markdown","source":["Here we import the news dataset"],"metadata":{"id":"oLMmOW7Lm40A"}},{"cell_type":"code","source":["# cogs402_ds = load_dataset(\"danielhou13/cogs402dataset2\")[\"validation\"]"],"metadata":{"id":"58zzpZYRWRDj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Getting the Attributions"],"metadata":{"id":"-IMLrVRDP3CP"}},{"cell_type":"markdown","source":["For our Integrated Gradients, we need to create a custom forward pass of our model. Specifically we want the softmaxed logits which represent the probability of predicting that class."],"metadata":{"id":"uX2TF2ayP6X_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"y5-heo2y0_Im"},"outputs":[],"source":["def predict(inputs, position_ids=None, token_type_ids=None, attention_mask=None):\n","    output = model(inputs,\n","                   position_ids=position_ids,\n","                   token_type_ids=token_type_ids,\n","                   attention_mask=attention_mask)\n","    return output.logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"axwpHq-y0_Io"},"outputs":[],"source":["#set 1 if we are dealing with a positive class, and 0 if dealing with negative class\n","def custom_forward(inputs, position_ids=None, token_type_ids=None, attention_mask=None):\n","    preds = predict(inputs,\n","                   position_ids=position_ids,\n","                   token_type_ids=token_type_ids,\n","                   attention_mask=attention_mask)\n","    return torch.softmax(preds, dim = 1)"]},{"cell_type":"markdown","source":["Create functions that give us the input ids, position ids and token_type_ids for the text we want to examine. It also creates a baseline for use in our integrated gradients.\n","\n","**Note: The function used to create the token type ids is the exact same as the longformer implementation when no token type ids. It is not necessary to create token_type_ids unless you are doing Integrated Gradients using multi-embedding as we need the baselines.**"],"metadata":{"id":"bqbvfvXv0VTp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vAAjmDRl0_In"},"outputs":[],"source":["ref_token_id = tokenizer.pad_token_id # A token used for generating token reference\n","sep_token_id = tokenizer.sep_token_id # A token used as a separator between question and text and it is also added to the end of the text.\n","cls_token_id = tokenizer.cls_token_id # A token used for prepending to the concatenated question-text word sequence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UgBSBpz-0_In"},"outputs":[],"source":["max_length = 2046\n","def construct_input_ref_pair(text, ref_token_id, sep_token_id, cls_token_id):\n","\n","    text_ids = tokenizer.encode(text, truncation = True, add_special_tokens=False, max_length = max_length)\n","    # construct input token ids\n","    input_ids = [cls_token_id] + text_ids + [sep_token_id]\n","    # construct reference token ids \n","    ref_input_ids = [cls_token_id] + [ref_token_id] * len(text_ids) + [sep_token_id]\n","\n","    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(text_ids)\n","\n","def construct_input_ref_pos_id_pair(input_ids):\n","    seq_length = input_ids.size(1)\n","\n","    #taken from the longformer implementation\n","    mask = input_ids.ne(ref_token_id).int()\n","    incremental_indices = torch.cumsum(mask, dim=1).type_as(mask) * mask\n","    position_ids = incremental_indices.long().squeeze() + ref_token_id\n","\n","    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n","    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n","\n","    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n","    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n","    return position_ids, ref_position_ids\n","\n","def construct_input_ref_token_type_pair(input_ids):\n","    seq_len = input_ids.size(1)\n","\n","    # same as the tensor the model creates when you do not pass in token_type_ids as input.\n","    token_type_ids = torch.zeros(seq_len, dtype=torch.long, device=device).unsqueeze(0).expand_as(input_ids)\n","    \n","    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)\n","\n","    return token_type_ids, ref_token_type_ids\n","    \n","def construct_attention_mask(input_ids):\n","    return torch.ones_like(input_ids)"]},{"cell_type":"markdown","source":["Perform Layer Integrated Gradients using the longformer's embeddings. This can easily be adjusted to use longformer word embeddings, position and token_type embeddings."],"metadata":{"id":"bQaYaSDf0buh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4uDuDrip0_Ip","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658953334693,"user_tz":420,"elapsed":7,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"302575ec-74e7-4268-a1cb-93853bc0046c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/captum/attr/_core/layer/layer_integrated_gradients.py:103: UserWarning: Multiple layers provided. Please ensure that each layer is**not** solely solely dependent on the outputs ofanother layer. Please refer to the documentation for moredetail.\n","  \"Multiple layers provided. Please ensure that each layer is\"\n"]}],"source":["lig = LayerIntegratedGradients(custom_forward, model.longformer.embeddings)\n","lig2 = LayerIntegratedGradients(custom_forward, \\\n","                                [model.longformer.embeddings.word_embeddings, \\\n","                                 model.longformer.embeddings.position_embeddings,\\\n","                                 model.longformer.embeddings.token_type_embeddings])"]},{"cell_type":"markdown","source":["Helper function to sum the attributions and normalize into an array of length (seq_len)."],"metadata":{"id":"TYWjb7C2QTvJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lIeE9P7b0_Ir"},"outputs":[],"source":["def summarize_attributions(attributions):\n","    attributions = attributions.sum(dim=-1).squeeze(0)\n","    attributions = attributions / torch.linalg.norm(attributions)\n","    return attributions"]},{"cell_type":"markdown","source":["We iterate over the entire dataset, getting the input_ids, position_ids and their baselines, performing integrated gradients, summing the attributions, and finally creating a dataframe to store the attributions and respective tokens. After we create the dataframe, get the aggregate attributions for each token in the example and save it in a list of dataframes."],"metadata":{"id":"bqYiK1U9IOeP"}},{"cell_type":"code","source":["from tqdm import tqdm\n","aggregate_attrib = []\n","aggregation_function = {'attribution': 'sum'}\n","\n","for i in tqdm(range(len(cogs402_ds))):\n","\n","  #get input ids, position ids and attention mask for integrated gradients\n","  text = cogs402_ds[i]['text']\n","  input_ids, ref_input_ids, sep_id = construct_input_ref_pair(text, ref_token_id, sep_token_id, cls_token_id)\n","  position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n","  attention_mask = construct_attention_mask(input_ids)\n","\n","  indices = input_ids[0].detach().tolist()\n","  all_tokens = tokenizer.convert_ids_to_tokens(indices)\n","\n","  # perform integrated gradients\n","  attributions = lig.attribute(inputs=input_ids,\n","                                    baselines=ref_input_ids,\n","                                    additional_forward_args=(position_ids, None, attention_mask),\n","                                    target=1,\n","                                    n_steps=75,\n","                                    internal_batch_size = 2)\n","  \n","  #get the attributions\n","  attributions_sum = summarize_attributions(attributions)\n","  \n","  #convert into dataframe\n","  d = {\"tokens\":all_tokens, \"attribution\":attributions_sum[:len(all_tokens)].cpu()}  \n","  df_attrib = pd.DataFrame(d)\n","\n","  #aggregate the duplicate tokens\n","  df_attrib = df_attrib.groupby(df_attrib['tokens']).aggregate(aggregation_function)\n","\n","  #add to list of dataframes\n","  aggregate_attrib.append(df_attrib)"],"metadata":{"id":"CjL5YobvYmNr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658953792173,"user_tz":420,"elapsed":457486,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"86297743-1038-453b-b6f6-ef5c152fcd0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 12/12 [07:37<00:00, 38.10s/it]\n"]}]},{"cell_type":"markdown","source":["Here we have the implementation for the multi-embedding version. The only difference is that we have two attributions that we want to find the aggregate for, the position and word embeddings. \n","\n","**Note: despite passing in the token_type_ids and the baseline as inputs, we will not be able to get attributions for it as the input and the baseline are the same. It returns a tensor of nan values.**\n","\n","We create dataframes for both the word and position attributions to store the attributions and their respective token. We then aggregate the attributions based on the token for both dataframes. Finally, we append the position and word dataframes in their own separate list of dataframes."],"metadata":{"id":"DDFBPe2C4Vtk"}},{"cell_type":"code","source":["from tqdm import tqdm\n","# aggregate_attrib = []\n","# aggregate_pos = []\n","\n","# aggregation_function = {'attribution': 'sum'}\n","\n","# for i in tqdm(range(len(cogs402_ds)), position = 0, leave = True):\n","  \n","#   #get input_ids, position_ids, and the attention masks for the integrated gradients\n","#   text = cogs402_ds[i]['text']\n","\n","#   input_ids, ref_input_ids, sep_id = construct_input_ref_pair(text, ref_token_id, sep_token_id, cls_token_id)\n","#   token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids)\n","#   position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n","#   attention_mask = construct_attention_mask(input_ids)\n","\n","#   indices = input_ids[0].detach().tolist()\n","#   all_tokens = tokenizer.convert_ids_to_tokens(indices)\n","\n","#   # compute integrated gradients\n","#   attributions2 = lig2.attribute(inputs=(input_ids, position_ids, token_type_ids),\n","#                                baselines=(ref_input_ids, ref_position_ids, ref_token_type_ids),\n","#                                target=1,\n","#                                additional_forward_args=attention_mask,\n","#                                n_steps=20,\n","#                                internal_batch_size = 2)\n","  \n","#   # get the attributions for the words and position ids\n","#   attributions_word = summarize_attributions(attributions2[0])\n","#   attributions_position = summarize_attributions(attributions2[1])\n","\n","#   # convert them both into dataframes \n","#   d = {\"tokens\":all_tokens, \"attribution\":attributions_word[:len(all_tokens)].cpu()}  \n","#   d2 = {\"tokens\":all_tokens, \"attribution\":attributions_position[:len(all_tokens)].cpu()}  \n","  \n","#   df_attrib = pd.DataFrame(d)\n","#   df_attrib2 = pd.DataFrame(d2)\n","\n","#   #aggregate the attributions for duplicate tokens\n","#   df_attrib = df_attrib.groupby(df_attrib['tokens']).aggregate(aggregation_function)\n","#   df_attrib2 = df_attrib2.groupby(df_attrib2['tokens']).aggregate(aggregation_function)\n","\n","#   aggregate_attrib.append(df_attrib)\n","#   aggregate_pos.append(df_attrib2)"],"metadata":{"id":"EMuSIP5D4UIC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["To get the aggregate attributions for every token over the entire dataset, we concatenate the list of dataframes we stored, sum up the attributions of duplicate tokens and divide by the number of items in each list."],"metadata":{"id":"_g6kqbTXCS-C"}},{"cell_type":"code","source":["def combinedataframe(listframes, aggregation_func):\n","  df_attrib = pd.concat(listframes)\n","  df_attrib = df_attrib.reset_index(level=0)\n","  df_attrib = df_attrib.groupby(df_attrib['tokens']).aggregate(aggregation_func)\n","  df_attrib['attribution'] = df_attrib['attribution'].div(len(listframes))\n","  highest_attrib_tokens_all = df_attrib.sort_values(by=['attribution'], ascending=False).reset_index()\n","  return highest_attrib_tokens_all"],"metadata":{"id":"JgulY85m4dOU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_attrib = combinedataframe(aggregate_attrib, aggregation_function)\n","# df_attrib_pos = combinedataframe(aggregate_pos, aggregation_function)"],"metadata":{"id":"AH_T49HMF6Cn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Masking the Tokens"],"metadata":{"id":"q6EV8v8DN0mo"}},{"cell_type":"code","source":["import nltk\n","nltk.download('stopwords')\n","tokenizer2 = AutoTokenizer.from_pretrained('allenai/longformer-base-4096', add_prefix_space=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-LB4-lD6MURA","executionInfo":{"status":"ok","timestamp":1659478703465,"user_tz":420,"elapsed":8444,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"ab6c1c88-f1c5-47ae-c04e-7b998fbded23"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","all_stopwords = stopwords.words('english')\n","all_stopwords.append(\" \")\n","stopwords = set(tokenizer2.tokenize(all_stopwords, is_split_into_words =True))\n","stopwords.update(all_stopwords)\n","print(stopwords)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CxOWzlq2MWu3","executionInfo":{"status":"ok","timestamp":1659478703465,"user_tz":420,"elapsed":4,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"f9b18c98-1fb2-436f-e641-1a2ffb5009e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Ġthrough', 'both', 'Ġits', 'Ġdidn', 'Ġtheir', 'Ġmust', 'Ġsuch', 'own', \"you'd\", \"hasn't\", \"won't\", 'Ġhas', 'i', 'y', 'Ġam', 'Ġagainst', 'Ġyou', 'you', 'Ġo', 'Ġre', 'so', 'it', 'Ġand', \"should've\", 'most', 'who', 'an', 'Ġs', 'Ġas', 'Ġwere', 'Ġthose', 'has', 'Ġwhy', 'too', \"you've\", 'Ġthis', 'now', 'Ġsh', 'Ġout', 'Ġnor', 'won', 'only', 'Ġyour', 'we', 'been', 'aren', 'a', 'Ġthe', 'doesn', 'wouldn', 'Ġthere', \"mightn't\", 'Ġwill', 'them', 'Ġweren', 'Ġhad', 'there', \"'t\", 'other', \"you're\", 'whom', \"'ll\", 'such', 'Ġof', 'himself', 'nor', 'Ġwhen', 'not', 'had', 'Ġ', 'Ġbeing', 'Ġwon', 'Ġwasn', 'Ġwhat', 'out', 'will', 'Ġmyself', 'each', 'for', 'Ġthemselves', 'into', 'Ġthese', 'Ġno', 'Ġwe', 'Ġbetween', 'mustn', 'on', 'having', 'haven', 'Ġwhom', 'from', 'Ġwhich', 'Ġbe', 'Ġhaven', 'Ġdoing', 're', 'Ġafter', 'where', 'Ġthey', 'Ġjust', 'Ġfrom', 'while', \"'s\", 'Ġy', 'Ġhave', 'through', 'Ġwho', 'Ġve', 'wasn', 'between', \"haven't\", 'Ġdoes', \"didn't\", 'hadn', 'ma', 'Ġthan', 'Ġthem', 'Ġyours', 'down', 'hers', 'few', \"weren't\", 'd', 'Ġonly', 'Ġbecause', 'Ġourselves', 'over', 'Ġdo', 'Ġhimself', 'Ġm', 'Ġdoesn', 'this', 'can', \"hadn't\", 'Ġso', 'Ġhers', 'further', 'her', 'to', 'Ġonce', 'just', 'about', 'Ġours', \"'re\", 'its', 'then', 'Ġif', 'Ġshe', 'Ġsome', 'Ġbefore', 'Ġmight', 'Ġa', 'herself', 'Ġwas', 'ourselves', 'Ġwith', 'Ġis', 'our', 'Ġtoo', \"it's\", 'Ġabove', \"aren't\", \"needn't\", 'Ġd', 'Ġany', 'Ġi', 'Ġwouldn', 'Ġhere', 'Ġwhile', 'Ġbeen', 'Ġher', 'Ġfor', 'Ġll', 'of', 'ain', 'below', 'his', 'o', 'was', 'Ġdid', 'Ġall', 'Ġhasn', 'Ġshould', 'that', 'Ġmost', 'up', 'again', 'Ġnow', 'and', 'n', 'here', 'the', 'hasn', 'be', 'Ġinto', 'Ġbut', 'don', 'needn', 'Ġt', 'Ġover', 'Ġthat', \"mustn't\", 'Ġmore', 'ours', ' ', 'how', 'Ġhim', \"'ve\", 'Ġagain', 'Ġshouldn', 'at', 'Ġtheirs', 'all', 'mightn', 'Ġcouldn', 'my', \"wasn't\", 'have', \"you'll\", 'no', 'with', 'those', 'is', 'some', 'Ġunder', 'Ġhadn', 'Ġdown', 'after', 'Ġwhere', 'do', 'Ġme', 've', 'same', 'yourselves', 'did', 'Ġduring', 'themselves', 'Ġan', 'does', 'your', 'itself', 'Ġneed', 'Ġin', 'Ġoff', \"'d\", 'Ġour', 'were', 'what', 'Ġyourselves', 'Ġother', \"shan't\", 'Ġboth', 'above', \"she's\", 'Ġat', 'these', 'Ġhaving', 'until', 'weren', 'Ġvery', 'more', 'Ġon', 'they', 'Ġabout', 'he', 'didn', 'Ġisn', \"couldn't\", 'him', 'Ġbelow', 'Ġsame', 'Ġhis', 'Ġaren', 'theirs', 'Ġfurther', 'in', 'Ġit', 'she', 'yourself', 'Ġfew', 'myself', 'why', 'yours', 'once', 'Ġcan', 's', 'being', 'shan', 'against', 'Ġdon', 'are', 'doing', 'Ġhow', 'Ġor', 'but', \"shouldn't\", 'Ġare', 'Ġby', 'if', \"isn't\", 'Ġuntil', 'as', 'should', 'Ġup', 'than', 'which', 'during', \"that'll\", \"don't\", 'll', 'Ġeach', 'off', 'Ġthen', 'when', \"wouldn't\", 'Ġto', 'under', 'isn', 'Ġyourself', 'Ġain', 'because', 'their', \"doesn't\", 'Ġherself', 'couldn', 'me', 'or', 'Ġitself', 't', 'Ġma', 'am', 'Ġown', 'by', 'Ġnot', 'Ġhe', 'shouldn', 'any', 'm', 'very', 'Ġmy', 'before'}\n"]}]},{"cell_type":"markdown","source":["Here we are only showing the top 15 highest attributions, in other words, the tokens that have the most influence in the model predicting positive. If you are running integrated gradients using the longformer embeddings, this will be attributions for those embeddings. If you are running Integrated Gradients using word, position, and token_type embeddings, these will be the word embeddings."],"metadata":{"id":"kxj_mmUxlx0c"}},{"cell_type":"code","source":["df_attrib[:20]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":707},"id":"1bXA7aeS5AWx","executionInfo":{"status":"ok","timestamp":1658953792175,"user_tz":420,"elapsed":21,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"d3018de3-4c32-4ed1-eabf-f9f9ac7d76df"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        attribution\n","tokens             \n","Ġto        1.200098\n",",          1.027586\n",".          1.027102\n","Ġas        0.584305\n","Ġ[         0.463468\n","Ġand       0.440593\n","Ġ          0.261086\n","Ġis        0.256762\n","Ġthis      0.193093\n","Ġwith      0.157940\n","-          0.156006\n","Ġher       0.151310\n","Ġhas       0.140729\n","/          0.137805\n","Ġany       0.129645\n","Ġbut       0.119077\n","YY         0.117357\n","Name       0.115948\n","ĠShe       0.100873\n","ST         0.081583"],"text/html":["\n","  <div id=\"df-2d77cdf9-6e5d-4fe0-9575-2896814796fb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>attribution</th>\n","    </tr>\n","    <tr>\n","      <th>tokens</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Ġto</th>\n","      <td>1.200098</td>\n","    </tr>\n","    <tr>\n","      <th>,</th>\n","      <td>1.027586</td>\n","    </tr>\n","    <tr>\n","      <th>.</th>\n","      <td>1.027102</td>\n","    </tr>\n","    <tr>\n","      <th>Ġas</th>\n","      <td>0.584305</td>\n","    </tr>\n","    <tr>\n","      <th>Ġ[</th>\n","      <td>0.463468</td>\n","    </tr>\n","    <tr>\n","      <th>Ġand</th>\n","      <td>0.440593</td>\n","    </tr>\n","    <tr>\n","      <th>Ġ</th>\n","      <td>0.261086</td>\n","    </tr>\n","    <tr>\n","      <th>Ġis</th>\n","      <td>0.256762</td>\n","    </tr>\n","    <tr>\n","      <th>Ġthis</th>\n","      <td>0.193093</td>\n","    </tr>\n","    <tr>\n","      <th>Ġwith</th>\n","      <td>0.157940</td>\n","    </tr>\n","    <tr>\n","      <th>-</th>\n","      <td>0.156006</td>\n","    </tr>\n","    <tr>\n","      <th>Ġher</th>\n","      <td>0.151310</td>\n","    </tr>\n","    <tr>\n","      <th>Ġhas</th>\n","      <td>0.140729</td>\n","    </tr>\n","    <tr>\n","      <th>/</th>\n","      <td>0.137805</td>\n","    </tr>\n","    <tr>\n","      <th>Ġany</th>\n","      <td>0.129645</td>\n","    </tr>\n","    <tr>\n","      <th>Ġbut</th>\n","      <td>0.119077</td>\n","    </tr>\n","    <tr>\n","      <th>YY</th>\n","      <td>0.117357</td>\n","    </tr>\n","    <tr>\n","      <th>Name</th>\n","      <td>0.115948</td>\n","    </tr>\n","    <tr>\n","      <th>ĠShe</th>\n","      <td>0.100873</td>\n","    </tr>\n","    <tr>\n","      <th>ST</th>\n","      <td>0.081583</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d77cdf9-6e5d-4fe0-9575-2896814796fb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2d77cdf9-6e5d-4fe0-9575-2896814796fb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2d77cdf9-6e5d-4fe0-9575-2896814796fb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["df_attrib[(df_attrib['tokens'].str.isalpha()) & ~(df_attrib['tokens'].isin(stopwords)) & ~(df_attrib['tokens']==0)][:20].reset_index(drop=True)"],"metadata":{"id":"qzNbPyTYO8X7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here we are showing the 15 highest attributions for the position embeddings. Note that running integrated gradients using the longformer embeddings rather than the word, position and token_type embeddings will not have this output."],"metadata":{"id":"EpF2ZfDBRssb"}},{"cell_type":"code","source":["# df_attrib_pos[:15]"],"metadata":{"id":"UgvpXJBMb84H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here we are only showing the top 15 lowest attributions, in other words, the tokens that have the most influence in the model predicting negative. If you are running integrated gradients using the longformer embeddings, this will be attributions for those embeddings. If you are running Integrated Gradients using word, position and token_type embeddings, these will be the word embeddings."],"metadata":{"id":"94_GDXHsl0vs"}},{"cell_type":"code","source":["df_attrib[:-19:-1]"],"metadata":{"id":"T7mHIG0NuG0X","colab":{"base_uri":"https://localhost:8080/","height":645},"executionInfo":{"status":"ok","timestamp":1658953792175,"user_tz":420,"elapsed":17,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"3f6cac68-9b99-4ad4-a606-33f6c41d0ba2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        attribution\n","tokens             \n","Ġthe      -1.515250\n","**        -0.875966\n","un        -0.789090\n","Ġof       -0.754745\n","Ġthat     -0.508071\n",")         -0.405730\n","Ġ(        -0.397495\n","Ġon       -0.367771\n",":         -0.360354\n","Ġin       -0.350545\n","Ġhis      -0.326558\n","Ġwas      -0.322760\n","Ġhe       -0.283016\n","Ġ2        -0.260835\n","Ġwell     -0.235223\n","Ġshe      -0.211275\n","Ġhave     -0.206652\n","Ġa        -0.161463"],"text/html":["\n","  <div id=\"df-a954db86-a619-4afc-b18d-468caac97431\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>attribution</th>\n","    </tr>\n","    <tr>\n","      <th>tokens</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Ġthe</th>\n","      <td>-1.515250</td>\n","    </tr>\n","    <tr>\n","      <th>**</th>\n","      <td>-0.875966</td>\n","    </tr>\n","    <tr>\n","      <th>un</th>\n","      <td>-0.789090</td>\n","    </tr>\n","    <tr>\n","      <th>Ġof</th>\n","      <td>-0.754745</td>\n","    </tr>\n","    <tr>\n","      <th>Ġthat</th>\n","      <td>-0.508071</td>\n","    </tr>\n","    <tr>\n","      <th>)</th>\n","      <td>-0.405730</td>\n","    </tr>\n","    <tr>\n","      <th>Ġ(</th>\n","      <td>-0.397495</td>\n","    </tr>\n","    <tr>\n","      <th>Ġon</th>\n","      <td>-0.367771</td>\n","    </tr>\n","    <tr>\n","      <th>:</th>\n","      <td>-0.360354</td>\n","    </tr>\n","    <tr>\n","      <th>Ġin</th>\n","      <td>-0.350545</td>\n","    </tr>\n","    <tr>\n","      <th>Ġhis</th>\n","      <td>-0.326558</td>\n","    </tr>\n","    <tr>\n","      <th>Ġwas</th>\n","      <td>-0.322760</td>\n","    </tr>\n","    <tr>\n","      <th>Ġhe</th>\n","      <td>-0.283016</td>\n","    </tr>\n","    <tr>\n","      <th>Ġ2</th>\n","      <td>-0.260835</td>\n","    </tr>\n","    <tr>\n","      <th>Ġwell</th>\n","      <td>-0.235223</td>\n","    </tr>\n","    <tr>\n","      <th>Ġshe</th>\n","      <td>-0.211275</td>\n","    </tr>\n","    <tr>\n","      <th>Ġhave</th>\n","      <td>-0.206652</td>\n","    </tr>\n","    <tr>\n","      <th>Ġa</th>\n","      <td>-0.161463</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a954db86-a619-4afc-b18d-468caac97431')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a954db86-a619-4afc-b18d-468caac97431 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a954db86-a619-4afc-b18d-468caac97431');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["df_attrib[(df_attrib['tokens'].str.isalpha()) & ~(df_attrib['tokens'].isin(stopwords)) & ~(df_attrib['tokens']==0)][:-19:-1].reset_index(drop=True)"],"metadata":{"id":"Pe1rbT6EPBhV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here we are showing the 15 lowest attributions for the position embeddings. Note that running integrated gradients using the longformer embeddings rather than the word, position and token_type embeddings will not have this output."],"metadata":{"id":"tKusjNjBStgY"}},{"cell_type":"code","source":["# df_attrib_pos[:-14:-1]"],"metadata":{"id":"bzhn7k4zcDHg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Save the pandas dataframe into a csv to access it in the future without having to run through the entire dataset. Change the path and file name to one fitting your project."],"metadata":{"id":"RgPYHilmlsGh"}},{"cell_type":"code","source":["# # longformer embeddings\n","# df_attrib.to_csv('/content/drive/MyDrive/cogs402longformer/results/papers/papers_attributions/longformer_emb_papers.csv')\n","# df_attrib.to_csv('/content/drive/MyDrive/cogs402longformer/results/news/news_attributions/longformer_emb_news.csv')\n","\n","# Word + position embeddings for the papers dataset\n","# df_attrib.to_csv('/content/drive/MyDrive/cogs402longformer/results/papers/papers_attributions/word_emb_papers.csv')\n","# df_attrib_pos.to_csv('/content/drive/MyDrive/cogs402longformer/results/papers/papers_attributions/pos_emb_papers.csv')\n","\n","# # # Word + position embeddings for the news dataset\n","# df_attrib.to_csv('/content/drive/MyDrive/cogs402longformer/results/news/news_attributions/word_emb_news.csv')\n","# df_attrib_pos.to_csv('/content/drive/MyDrive/cogs402longformer/results/news/news_attributions/pos_emb_news.csv')"],"metadata":{"id":"6WTv-OJrGKvF"},"execution_count":null,"outputs":[]}],"metadata":{"file_extension":".py","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3,"colab":{"name":"AttributionLongformerAggregateNotes.ipynb","provenance":[{"file_id":"1lktilbL1IY4nBanlzCdP8TLsBNfUsl_U","timestamp":1658452082765},{"file_id":"15Zquqi72N2NNusEUXRN53bCKE7qj8KAh","timestamp":1656810812588},{"file_id":"1-zUACrWJtGVU71pkZ-kswoaOj6bn93RG","timestamp":1654732006544}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a44cebbdc1164013a912ecc9a1189f2d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d69319ff6f57485b84c4d6fa9fd2507a","IPY_MODEL_acfa0706197e421bb1b7bdbe255e8014","IPY_MODEL_1b7beb2afa67415b836bf79eb7096fe9"],"layout":"IPY_MODEL_9f434b761e4941a9a345f2eac2f91e9b"}},"d69319ff6f57485b84c4d6fa9fd2507a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_025a88af5b474da599b253ccad88304c","placeholder":"​","style":"IPY_MODEL_31d682a7714642b8aabcba4121ab97cf","value":"Downloading config.json: 100%"}},"acfa0706197e421bb1b7bdbe255e8014":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_58aad7598acd41b1b91268a094ea1352","max":694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a359f73ad7f045a9b037eb1cd878e448","value":694}},"1b7beb2afa67415b836bf79eb7096fe9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5c7fa5733194e89a958e5b576a18646","placeholder":"​","style":"IPY_MODEL_818fbe98502d46f797a86b590c0a7b66","value":" 694/694 [00:00&lt;00:00, 22.1kB/s]"}},"9f434b761e4941a9a345f2eac2f91e9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"025a88af5b474da599b253ccad88304c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31d682a7714642b8aabcba4121ab97cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58aad7598acd41b1b91268a094ea1352":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a359f73ad7f045a9b037eb1cd878e448":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c5c7fa5733194e89a958e5b576a18646":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"818fbe98502d46f797a86b590c0a7b66":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d37f23dd55e4eb4a4b3bcc408ce2aef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_74f5ffbdcb0b400c86d20f477cc71152","IPY_MODEL_d865b1a083e24a15904d9c338a9a6bf5","IPY_MODEL_f1fe40521b44415db63bdd8e901317d9"],"layout":"IPY_MODEL_682f9ebedfee4560beb7859c16d5e80a"}},"74f5ffbdcb0b400c86d20f477cc71152":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_255d842779c248f1b15fd217d83dc165","placeholder":"​","style":"IPY_MODEL_d92ca6d4c0d9411da9f0e1d0e06ac062","value":"Downloading pytorch_model.bin: 100%"}},"d865b1a083e24a15904d9c338a9a6bf5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e80656f99acf40df8de27079e2505f19","max":597257159,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9b952aa20d8c4a788b822f173b12cc6f","value":597257159}},"f1fe40521b44415db63bdd8e901317d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1833b17f46974710be7cc4e1141f0866","placeholder":"​","style":"IPY_MODEL_4ab94d513f8e47938a0172d04a8ff470","value":" 570M/570M [00:09&lt;00:00, 65.4MB/s]"}},"682f9ebedfee4560beb7859c16d5e80a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"255d842779c248f1b15fd217d83dc165":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d92ca6d4c0d9411da9f0e1d0e06ac062":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e80656f99acf40df8de27079e2505f19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b952aa20d8c4a788b822f173b12cc6f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1833b17f46974710be7cc4e1141f0866":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ab94d513f8e47938a0172d04a8ff470":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b76b406955541c7acf3af529fc4d3f5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f54f62e954f64b389970ced7f009edfa","IPY_MODEL_35e6f9771bea4f6483b9961ef8ced330","IPY_MODEL_79911cfe39df4522b6d40064cc67a68b"],"layout":"IPY_MODEL_18eafc95e0844ba3a8c0b3a147858935"}},"f54f62e954f64b389970ced7f009edfa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67f8e26ba9d84c9795122fac9a996581","placeholder":"​","style":"IPY_MODEL_c35656bb55a6422994c86b1915c09c7b","value":"Downloading vocab.json: 100%"}},"35e6f9771bea4f6483b9961ef8ced330":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea47dfddd7984985aa4f148a41ba433b","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b061463d841d4891a5d18595024a3b72","value":898823}},"79911cfe39df4522b6d40064cc67a68b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fe26e4e03574ae3ae46c18f2ddb4e97","placeholder":"​","style":"IPY_MODEL_d6167b53d4a64eb39e742e3459e39e5c","value":" 878k/878k [00:01&lt;00:00, 1.24MB/s]"}},"18eafc95e0844ba3a8c0b3a147858935":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67f8e26ba9d84c9795122fac9a996581":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c35656bb55a6422994c86b1915c09c7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea47dfddd7984985aa4f148a41ba433b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b061463d841d4891a5d18595024a3b72":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3fe26e4e03574ae3ae46c18f2ddb4e97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6167b53d4a64eb39e742e3459e39e5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64c5f036cac942b1b99083ed41d320b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d7f275a382e8407fa33c42da38b2b81c","IPY_MODEL_3d4da032fdfb4ad290d40c93b344e9a9","IPY_MODEL_def71dfb2ee94f8ab0ef940a5759f88a"],"layout":"IPY_MODEL_268f1da052324841a4b29220ce18f8ac"}},"d7f275a382e8407fa33c42da38b2b81c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d30088da53204c15ac197cea33aaccbf","placeholder":"​","style":"IPY_MODEL_f1515ff8d09c44f6b016607459300226","value":"Downloading merges.txt: 100%"}},"3d4da032fdfb4ad290d40c93b344e9a9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cf6623eaf944cd1b6e388f58d459d70","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8a470c6f635c40e88275bf3856b2adac","value":456318}},"def71dfb2ee94f8ab0ef940a5759f88a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f73f86063f644f519e5382376dac9f3e","placeholder":"​","style":"IPY_MODEL_6c8e4185f3664073bca248c138c1dec4","value":" 446k/446k [00:00&lt;00:00, 627kB/s]"}},"268f1da052324841a4b29220ce18f8ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d30088da53204c15ac197cea33aaccbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1515ff8d09c44f6b016607459300226":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9cf6623eaf944cd1b6e388f58d459d70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a470c6f635c40e88275bf3856b2adac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f73f86063f644f519e5382376dac9f3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c8e4185f3664073bca248c138c1dec4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c16635239a46469c9026c05f4d21cbe8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_38942eb3767a4e769d3cd2074fc0aae2","IPY_MODEL_2f2017cb5a6a4147b4faf2b01c96364e","IPY_MODEL_a58ebc6f6d46400b91f8b0a3d49e88b2"],"layout":"IPY_MODEL_fc602c76a6ac438cb63dbdc819b59c2b"}},"38942eb3767a4e769d3cd2074fc0aae2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7eb92a073e194b09b977c73f5d8daf6c","placeholder":"​","style":"IPY_MODEL_5a8206b4356547189d230771d263720b","value":"Downloading: 100%"}},"2f2017cb5a6a4147b4faf2b01c96364e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ddf3f5fc5d64b148eb57f5f44b9370f","max":613,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5fb133b3de0c4a03b5c7380d089fc061","value":613}},"a58ebc6f6d46400b91f8b0a3d49e88b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9ae0f64d82a468db6a5f229e421b4d7","placeholder":"​","style":"IPY_MODEL_f262b48d6d564bcc991ebc32d7037ad5","value":" 613/613 [00:00&lt;00:00, 19.8kB/s]"}},"fc602c76a6ac438cb63dbdc819b59c2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7eb92a073e194b09b977c73f5d8daf6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a8206b4356547189d230771d263720b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ddf3f5fc5d64b148eb57f5f44b9370f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fb133b3de0c4a03b5c7380d089fc061":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d9ae0f64d82a468db6a5f229e421b4d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f262b48d6d564bcc991ebc32d7037ad5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"793a013fb0e24bcd8a2db194769b62ca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_24159558d5d747ad883b359d1ad45151","IPY_MODEL_da31972ada4e4be095e2e897f2363d18","IPY_MODEL_0a426c1ac93346c38cd6d106b1a225ad"],"layout":"IPY_MODEL_93ee51ecd025466dba5335f87424f668"}},"24159558d5d747ad883b359d1ad45151":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c1426c098204f8ba4b6dba953dcb241","placeholder":"​","style":"IPY_MODEL_115bfb8b317c455f80f8eb008491a922","value":"Downloading data files: 100%"}},"da31972ada4e4be095e2e897f2363d18":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d155889944304c37a5649f39b4b3b795","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6249a6a1d7c34b408289c6a40891f54d","value":1}},"0a426c1ac93346c38cd6d106b1a225ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf0f4e792ac544639daae630cedc6dab","placeholder":"​","style":"IPY_MODEL_43fbba667d384e42931c89a211f86573","value":" 1/1 [00:01&lt;00:00,  1.74s/it]"}},"93ee51ecd025466dba5335f87424f668":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c1426c098204f8ba4b6dba953dcb241":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"115bfb8b317c455f80f8eb008491a922":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d155889944304c37a5649f39b4b3b795":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6249a6a1d7c34b408289c6a40891f54d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf0f4e792ac544639daae630cedc6dab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43fbba667d384e42931c89a211f86573":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf41fbc1ba3b44bf813c26af9f3dea35":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9d356ef06dd7487484dbdba440d818df","IPY_MODEL_cf90a53300164c8c9eadeeaae02401ea","IPY_MODEL_0aa3405159d74b99b574280680a16839"],"layout":"IPY_MODEL_b4e36e54dca84381afb7c8f03cf757aa"}},"9d356ef06dd7487484dbdba440d818df":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b2d179fed1e4636a4882d63290e43a9","placeholder":"​","style":"IPY_MODEL_932ea05f6ee244448462647ca84ab8a3","value":"Downloading data: 100%"}},"cf90a53300164c8c9eadeeaae02401ea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_13e3398cf0e949e0a5aad4dc393c4752","max":61212,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2b11149bf931417694d72c8189321d27","value":61212}},"0aa3405159d74b99b574280680a16839":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b20e7adba444477fa26ed26bc8336efb","placeholder":"​","style":"IPY_MODEL_3b28d60243ad460299f91593099aca98","value":" 61.2k/61.2k [00:00&lt;00:00, 1.76MB/s]"}},"b4e36e54dca84381afb7c8f03cf757aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b2d179fed1e4636a4882d63290e43a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"932ea05f6ee244448462647ca84ab8a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13e3398cf0e949e0a5aad4dc393c4752":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b11149bf931417694d72c8189321d27":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b20e7adba444477fa26ed26bc8336efb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b28d60243ad460299f91593099aca98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"069f4a30024444b78d33ecde0bf0c703":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c208df88858144fe84420d71c194ac24","IPY_MODEL_5ff692bcabfa4e8b8266cd561a148687","IPY_MODEL_1f81c83bf21a49a1881c85311e433898"],"layout":"IPY_MODEL_6620529a9d714c458dc067db4c9b3ddb"}},"c208df88858144fe84420d71c194ac24":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21d7f0761a674251ab93d2733eb70a21","placeholder":"​","style":"IPY_MODEL_d5d4ebe675c64ee49cd9b25dddd8a382","value":"Extracting data files: 100%"}},"5ff692bcabfa4e8b8266cd561a148687":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1ccdf4a554b4c7780440d33cf6924cb","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2288ac8b5a0849ff8481f1f41f1d652a","value":1}},"1f81c83bf21a49a1881c85311e433898":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39a9ff0abcf344d7bd89d4bc0103e59e","placeholder":"​","style":"IPY_MODEL_c22746e16fe948c997194ea0b492b7fb","value":" 1/1 [00:00&lt;00:00, 26.87it/s]"}},"6620529a9d714c458dc067db4c9b3ddb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21d7f0761a674251ab93d2733eb70a21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5d4ebe675c64ee49cd9b25dddd8a382":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1ccdf4a554b4c7780440d33cf6924cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2288ac8b5a0849ff8481f1f41f1d652a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"39a9ff0abcf344d7bd89d4bc0103e59e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c22746e16fe948c997194ea0b492b7fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"505a8fe8b23342859028f6f4b88966d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ea200c7139fe4f558b332ff99897f6e4","IPY_MODEL_240bc18fd8194dacb80d72e1ed8e9e05","IPY_MODEL_fa1a5b9b3d54440d860125efafe7f4e4"],"layout":"IPY_MODEL_006910b188714070813124e9030208b5"}},"ea200c7139fe4f558b332ff99897f6e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07efc63aa0ce47648f5ac0a6d6315df6","placeholder":"​","style":"IPY_MODEL_3427fa43e0bf4850aeec60494bce1861","value":""}},"240bc18fd8194dacb80d72e1ed8e9e05":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_54f75b2ea1a646c6a387ca662812cd0a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0776b4635db4cc6a582c67956f75d99","value":1}},"fa1a5b9b3d54440d860125efafe7f4e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84014bf389fa453cb4942aae0899bc67","placeholder":"​","style":"IPY_MODEL_2de3b8dd1a3a4bc19340e12b58c871d9","value":" 0/? [00:00&lt;?, ? tables/s]"}},"006910b188714070813124e9030208b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07efc63aa0ce47648f5ac0a6d6315df6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3427fa43e0bf4850aeec60494bce1861":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54f75b2ea1a646c6a387ca662812cd0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c0776b4635db4cc6a582c67956f75d99":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"84014bf389fa453cb4942aae0899bc67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2de3b8dd1a3a4bc19340e12b58c871d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9189ba7ede8487a98734fd563df1fa4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_92de11632ffa4cc09c6bf3fcd2963153","IPY_MODEL_329b25146aa14f81ba5a299104b9de68","IPY_MODEL_52cebbcc30144191b97304f36d4656bc"],"layout":"IPY_MODEL_f0244612d7504c399981671287577e70"}},"92de11632ffa4cc09c6bf3fcd2963153":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3ffbd442d704daca9f4cc5a9896c472","placeholder":"​","style":"IPY_MODEL_68df5f49d45c4304bd30ba261d3a14d2","value":"100%"}},"329b25146aa14f81ba5a299104b9de68":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b3c6d1004fd4ead807fdfc4087ad9a9","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6501db91a5634362af03a2c45d83ba6c","value":1}},"52cebbcc30144191b97304f36d4656bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9275fe134eba495f93a7c774da9867be","placeholder":"​","style":"IPY_MODEL_a86e1d28d0c54115b3f2975031bc8ae4","value":" 1/1 [00:00&lt;00:00, 33.47it/s]"}},"f0244612d7504c399981671287577e70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3ffbd442d704daca9f4cc5a9896c472":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68df5f49d45c4304bd30ba261d3a14d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b3c6d1004fd4ead807fdfc4087ad9a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6501db91a5634362af03a2c45d83ba6c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9275fe134eba495f93a7c774da9867be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a86e1d28d0c54115b3f2975031bc8ae4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}