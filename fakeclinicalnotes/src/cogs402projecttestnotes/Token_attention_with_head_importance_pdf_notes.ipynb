{"cells":[{"cell_type":"markdown","source":["This notebook is primarily the same as the section on converting to a PDF in [Token_attention_with_head_importance](https://colab.research.google.com/drive/136BndmOXO7ADHApLSiVg7cl6m2_x2FN8?usp=sharing); however, this notebook solely focuses on converting the attentions into a PDF visualization. This notebook predicts over the dataset and finds interesting examples one may want to visualize the attentions of such as false negatives, false postiives, and very confident predictions. It of course, will output a PDF of the text with the attentions of the token layered on top of the token."],"metadata":{"id":"t8OGqf7Pl7-h"},"id":"t8OGqf7Pl7-h"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kZTPlUo8Wp1T","executionInfo":{"status":"ok","timestamp":1660027029014,"user_tz":420,"elapsed":18510,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"02bcd988-d35f-43d4-b873-cdf7e5dc5e0e"},"id":"kZTPlUo8Wp1T","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["### Install and Import Dependencies"],"metadata":{"id":"XFt7t0wAERQV"},"id":"XFt7t0wAERQV"},{"cell_type":"code","source":["# import sys\n","# sys.path.append('/content/drive/My Drive/{}'.format(\"cogs402longformer/\"))"],"metadata":{"id":"AlcBiC0nWtJE"},"id":"AlcBiC0nWtJE","execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install datasets --quiet"],"metadata":{"id":"s_6vceLhTIBf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660027035346,"user_tz":420,"elapsed":6335,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"d524cf9d-b7a1-4296-901f-fb566ee44204"},"id":"s_6vceLhTIBf","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 365 kB 6.9 MB/s \n","\u001b[K     |████████████████████████████████| 101 kB 14.1 MB/s \n","\u001b[K     |████████████████████████████████| 141 kB 83.2 MB/s \n","\u001b[K     |████████████████████████████████| 212 kB 80.2 MB/s \n","\u001b[K     |████████████████████████████████| 115 kB 76.5 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 77.3 MB/s \n","\u001b[K     |████████████████████████████████| 127 kB 70.8 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","source":["pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M-qXH2JkTMdA","executionInfo":{"status":"ok","timestamp":1660027044566,"user_tz":420,"elapsed":9224,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"57ecebc6-b210-4709-b2d4-172f8878e2af"},"id":"M-qXH2JkTMdA","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 8.0 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 56.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: tokenizers, transformers\n","Successfully installed tokenizers-0.12.1 transformers-4.21.1\n"]}]},{"cell_type":"markdown","source":["##Import Dataset and Model"],"metadata":{"id":"hSSPoSRn6r9A"},"id":"hSSPoSRn6r9A"},{"cell_type":"code","execution_count":null,"id":"9b774ad0-b725-4910-9050-423edf160ebd","metadata":{"id":"9b774ad0-b725-4910-9050-423edf160ebd"},"outputs":[],"source":["import os\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn"]},{"cell_type":"markdown","source":["Import the Reserach Papers dataset"],"metadata":{"id":"hfHRqrpw_VlN"},"id":"hfHRqrpw_VlN"},{"cell_type":"code","execution_count":null,"id":"66cc97f5-7e3a-476c-9858-5643eeaa6675","metadata":{"id":"66cc97f5-7e3a-476c-9858-5643eeaa6675","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["64a7d99de20c497cac092035237e6eac","79507002bd824215a5888c55c69ebebd","31c648be98b141b7878f3d8181345132","c08557ceb01d4e63ac51eebdd7be5a44","7dfa19e33ed048da83c749a6c9d86f0c","ce56630d42584ec4bcb4f132dad0b1aa","ad7c64dd3ac94c0cafb6ecd7d02a9a37","9d671223d0a945a1b46e8c3ecb2df318","c227bf4d20a5475dad5c2493e385c3d5","f064510e93cf41b88f944c2c23de55ac","ea8fc239dad545ad8f9fdb876330f8ed","81fcf1b48a4748a4b9bb01d73b2c86c1","f0ea10634a9d426987bba955c1a83565","e1edd76d9fb34e1d919bb34eb6e42d21","60badc3a024b47e899b2c0e6324c27f3","498f984d1f474cd3a5a7744100254ad5","402b4a379b6f45bbb0d1785d148bb8a2","877d14d6c3f94fb3a930943a6ceb6870","6fe8fa5958f04ad2a2e09134ca1396c0","11afb3360fd840f98f74d6511f1c8314","be4e6a1de79246fd8689bb3b4422a453","9424e0382ef04e98a6d60e7d4c8e2446","1a0fcf5b1a9e4ce6814b06a28623cbe6","f4be6cce427a4b8097001d62d48daee7","53ee54a729b24db9a72871e9f6fa6829","15e8d09cfd3d4f65adcfd9319ca332be","b8aa25928d4b458d8daf22799b936a9e","0bf8458365874678a265925028997960","2b51930b66e7478cb21612c3521ba43a","f7a683ebfb4c4caaa9aaab306a7217dc","a3c03e50a6c942ce82087cc8e316c1f0","e3e2e55627fd433f998f19e257920376","13611085692e425f83702f14e5ef6f1f","d2afeb13dedc40fa83250179c93ecbde","7bcc697e7cf84f3bbdff376ccc47a545","b312a4249e9940ee8389f942149d9634","474be50ebaba40998448ec1d836ca6e1","52709963b71f40da8ec7aed8152ccb1b","6d500486d5944e3cb9c11e8ba1afedbc","966bc743d2054bd5ad9676a1d8aea9d9","8b2858ca326c472694edbfd40fb86eb1","3a115c2716104aacb589b33f1c7ea93a","e9437f0e5ecb435581d76aada34782bd","532bd3a419cd46baaa1a8a8d219787ca"]},"executionInfo":{"status":"ok","timestamp":1660027052860,"user_tz":420,"elapsed":5811,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"9ff39f27-0e80-419e-b114-85c41cfe7622"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64a7d99de20c497cac092035237e6eac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading vocab.json:   0%|          | 0.00/878k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81fcf1b48a4748a4b9bb01d73b2c86c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a0fcf5b1a9e4ce6814b06a28623cbe6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer.json:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2afeb13dedc40fa83250179c93ecbde"}},"metadata":{}}],"source":["import datasets\n","from datasets import load_dataset\n","from transformers import LongformerForSequenceClassification, AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained('allenai/longformer-base-4096')\n","\n","def longformer_finetuned_notes():\n","    test = torch.load(\"/content/drive/MyDrive/cogs402longformer/fakeclinicalnotes/models/full_augmented_lr2e-5_dropout3_10_trained_threshold.pt\")\n","    model = LongformerForSequenceClassification.from_pretrained('allenai/longformer-base-4096', state_dict=test['state_dict'], num_labels = 2)\n","    return model\n","\n","def preprocess_function(tokenizer, example, max_length):\n","    example['text'] = [str(x).lower() for x in example['text']]\n","    example.update(tokenizer(example['text'], padding='max_length', max_length=max_length, truncation=True))\n","    return example\n","\n","def get_notes_dataset(split):\n","    max_length = 2048\n","    # dataset = load_dataset(\"danielhou13/cogs402datafake\")[dataset_type]\n","    dataset = split\n","    # tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","    dataset = dataset.map(lambda x: preprocess_function(tokenizer, x, max_length), batched=True)\n","    setattr(dataset, 'input_columns', ['input_ids', 'attention_mask'])\n","    setattr(dataset, 'target_columns', ['labels'])\n","    setattr(dataset, 'max_length', max_length)\n","    setattr(dataset, 'tokenizer', tokenizer)\n","    return dataset\n","\n","# def notes_test_set():\n","#     return get_notes_dataset('test')\n","\n","# def notes_train_set():\n","#     return get_notes_dataset('train')"]},{"cell_type":"markdown","source":["Load papers model and dataset and preprocess it"],"metadata":{"id":"srzj_2BeNGOK"},"id":"srzj_2BeNGOK"},{"cell_type":"code","execution_count":null,"id":"24ad54a3-db97-47e3-8cc7-417d4db2c99b","metadata":{"id":"24ad54a3-db97-47e3-8cc7-417d4db2c99b","executionInfo":{"status":"ok","timestamp":1660027099194,"user_tz":420,"elapsed":46344,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"colab":{"base_uri":"https://localhost:8080/","height":417,"referenced_widgets":["3907ed36b9444fa28fecbec1aecb4839","1ff6a049b2d9499098a18bbd1528065b","447126b6ffbc42ae83cec659f1fc834e","60ed120b79eb4a0dbe21c3bbc5335ebd","795466e4d20941a5abb635bad8a8bbfb","caad565f52a94ff186435973d46c2604","50016c74edf44822ac070e484c434e1e","68f375016bea456a99fe2bdf3c4a57c1","3a099609abe1410881b470afc249d6ee","dd5b42d3126e4d999b8a7c538a135f50","8d6f315064dd46f3827e70ef250516d9","f7547421d2824f42b6341a9faf2a4e67","c12243c415ab4d3f8786013a9971bd24","057d17fd098749458b4ad7ab6f370242","d0f02c9344cc4c85875263b2224b0c63","86a28aee77a243cc91ef3cad80b7ab69","be898a533044457cbd13175bd9e1ea1e","e1294f747b3343ea9e524f4538465e86","bf8aa752bc8c4a918dfe3bdfb2507240","76834b6ab88d4bc78a1f5a98e9801b76","e726c2bb604b4467ba2f53505eda0271","375074015ede4a9ca0e73316e46e8746","b44191a4c892477c94ea3aa05fc7934a","fb494797c1f945968d20c40b9c98d3a4","9bd07725876a4651889e72b0607966cd","7bb7335b2d1a417688c7c1f3579ce8e2","b730f7c52f244a3b907108ba959c7894","08f1e78d35e64fc280fbf685ce901fa3","48c80a6c88d04e6785a218ee84e4d269","54133b2784cf499e80fc89e32e812763","99e804cd5b814f0386965955f3ac1d5c","e8582d70fa85404faf0849c9749b5cf8","62216f3d48d14d998a1373c1dd1fc0e0","48e745b4eb0e40a6b8d8581451bc375b","1bec9787428e48dda83935e38389a44c","9989dc88553d434693eeb384fbef28bf","b2036da088954853bf4def237169af84","5014425efb48487eaff5327c7d1f42d2","d2ff2d7bb24c425fbc2fd10eae4561b7","fc40e0f41a4e4cb9a564fc7b17635202","4be16d1da099475991dee27c5dd44e8b","41b7e48703ec499e969e32075efc1e6f","1a45ba1a5c604d83b7195320833b7dea","bb0f86ad98c14b6fbb9b034764ee09f8","49876f0fd1fb426c95d014de7a01f05a","6fcf196085d84c1ab53bdf66ea9d5dcc","63c4557f081042699a0998d093512b71","d3308367e6104ed8a3a310f8d71f6864","f058c869ae6244b5a59d45b1611120bf","87cb4b572d4b4fbc9e5cef6f2d078624","56d2b3e5025f4133982ae8648dbacbf3","4f46f78a39d54ba58fe667dd8fec92fd","95b1c4022440461e8ffd153f89363701","62d589f80acf45c0bb186d396fac2c8b","892b4d5979d341baafa1627836a12474","f3567a6bb09e44b6a89c4c8c4164d3a3","d6523595d7e04779914c0173b10def52","688be0b904a049a7b032e7ba0f5303dd","7350d8ac4d3d49978824dd2803335a7a","c06a2852d8df404eab8bd03b8a270dcf","6c5aaa4ff47c463aaf6b1583a6ed626a","88845e9ab40b492c962c1af3b638e7fa","e95b609c24744932a46c0967d8527ccb","f48a963ebdfa4e2795bbb758aaebec6a","28c506a8ead94b99bb930d23a114e34e","4d440ac69c214c349db569c360576b84","464037dc0ca4473e9007e6c543290c50","ac0b4c7811704860b417c2ab3fee3684","b87972569da344ed9656d9dcdd3901c4","4e121d2b905047b99f03b9f231dcbee8","d78b84fa2cfa4cfc896a2815ba5e30dc","fe37daeac5b14feb8c6be2f90a6947c2","88b90d9f221342488d7be4088a9649c7","eec7ae2422254cb1b0b4a7d73df09c17","7924ca200cfe4501bc0191df768cc261","5471a50205fa47fcb8c8146ce261cb54","d573e68c41bb4ebca7acbf185e4947e8","77c3251fb05f4154abb338f84150c9b8","932b53c1d66c4cf1a9c38e54c965d375","993fde43e65e4c78a3f48701cae9489b","f4f859a052274e559d5d9d490ac8e2ee","105b5e142f3042b2a5a7ca9de4ac83f5","cbae85bfa490413c83b0c69f05ccf42d","a76078ddb5d2432cab28426d876292f5","58a649d2a5be40468630aac908568d35","17cccedbdec44826becc5f04b97209ad","4c65949e05a44f9fa3199ea4a18d54dd","2508670995394e319f72c823b64e7883"]},"outputId":"9dd9f118-e37d-4dce-c8b4-811d2bbea693"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/613 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3907ed36b9444fa28fecbec1aecb4839"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Using custom data configuration danielhou13--cogs402datafake-c20c2db2d92a66bc\n"]},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset None/None (download: 59.71 KiB, generated: 113.90 KiB, post-processed: Unknown size, total: 173.61 KiB) to /root/.cache/huggingface/datasets/danielhou13___parquet/danielhou13--cogs402datafake-c20c2db2d92a66bc/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7547421d2824f42b6341a9faf2a4e67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/61.1k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b44191a4c892477c94ea3aa05fc7934a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48e745b4eb0e40a6b8d8581451bc375b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["0 tables [00:00, ? tables/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49876f0fd1fb426c95d014de7a01f05a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/danielhou13___parquet/danielhou13--cogs402datafake-c20c2db2d92a66bc/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3567a6bb09e44b6a89c4c8c4164d3a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"464037dc0ca4473e9007e6c543290c50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/570M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77c3251fb05f4154abb338f84150c9b8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['longformer_model.encoder.layer.7.attention.self.query.bias', 'longformer_model.encoder.layer.1.output.dense.bias', 'longformer_model.encoder.layer.8.output.LayerNorm.weight', 'longformer_model.encoder.layer.1.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.0.attention.self.query.weight', 'longformer_model.encoder.layer.2.attention.self.value.weight', 'longformer_model.encoder.layer.1.intermediate.dense.weight', 'longformer_model.encoder.layer.10.intermediate.dense.bias', 'longformer_model.encoder.layer.7.intermediate.dense.bias', 'longformer_model.encoder.layer.11.attention.output.dense.weight', 'longformer_model.embeddings.position_embeddings.weight', 'longformer_model.encoder.layer.11.attention.self.query_global.weight', 'longformer_model.encoder.layer.2.attention.self.query_global.bias', 'longformer_model.encoder.layer.0.attention.self.query_global.weight', 'longformer_model.encoder.layer.3.output.LayerNorm.weight', 'longformer_model.encoder.layer.6.attention.output.dense.weight', 'longformer_model.encoder.layer.6.attention.self.key_global.weight', 'longformer_model.encoder.layer.7.attention.self.key_global.weight', 'longformer_model.encoder.layer.11.attention.self.value.bias', 'longformer_model.encoder.layer.7.attention.self.query_global.bias', 'longformer_model.encoder.layer.8.attention.self.key.bias', 'longformer_model.encoder.layer.8.attention.self.key_global.bias', 'longformer_model.embeddings.position_ids', 'longformer_model.encoder.layer.5.output.LayerNorm.bias', 'longformer_model.encoder.layer.9.attention.self.query_global.weight', 'longformer_model.encoder.layer.2.intermediate.dense.weight', 'longformer_model.encoder.layer.2.intermediate.dense.bias', 'longformer_model.encoder.layer.6.output.LayerNorm.bias', 'longformer_model.encoder.layer.8.attention.self.query_global.weight', 'longformer_model.encoder.layer.4.attention.self.value_global.weight', 'longformer_model.encoder.layer.3.output.dense.bias', 'longformer_model.encoder.layer.5.attention.self.query.bias', 'longformer_model.encoder.layer.6.intermediate.dense.bias', 'longformer_model.encoder.layer.2.attention.self.query.weight', 'longformer_model.encoder.layer.7.attention.self.query_global.weight', 'longformer_model.encoder.layer.10.attention.self.value.bias', 'longformer_model.encoder.layer.9.attention.self.value_global.weight', 'longformer_model.encoder.layer.5.output.dense.weight', 'longformer_model.encoder.layer.3.attention.self.query.bias', 'longformer_model.encoder.layer.11.attention.self.query.weight', 'longformer_model.encoder.layer.5.attention.self.query.weight', 'longformer_model.encoder.layer.8.output.LayerNorm.bias', 'longformer_model.encoder.layer.9.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.3.attention.self.key_global.weight', 'longformer_model.encoder.layer.5.attention.self.query_global.weight', 'longformer_model.encoder.layer.9.attention.self.value.weight', 'longformer_model.encoder.layer.10.attention.self.key.bias', 'longformer_model.encoder.layer.2.output.LayerNorm.bias', 'longformer_model.encoder.layer.5.intermediate.dense.weight', 'longformer_model.encoder.layer.5.attention.self.key_global.weight', 'longformer_model.encoder.layer.3.attention.self.query_global.weight', 'longformer_model.encoder.layer.4.attention.self.key.bias', 'longformer_model.encoder.layer.4.attention.self.value.weight', 'longformer_model.encoder.layer.5.attention.self.query_global.bias', 'longformer_model.encoder.layer.8.attention.output.dense.weight', 'longformer_model.encoder.layer.9.attention.self.key.bias', 'longformer_model.encoder.layer.6.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.4.attention.self.query_global.weight', 'longformer_model.encoder.layer.11.attention.self.value.weight', 'longformer_model.encoder.layer.6.attention.self.query_global.weight', 'longformer_model.encoder.layer.10.attention.self.value.weight', 'longformer_model.encoder.layer.4.intermediate.dense.weight', 'longformer_model.encoder.layer.6.attention.self.value_global.weight', 'longformer_model.encoder.layer.9.output.LayerNorm.weight', 'longformer_model.encoder.layer.5.output.dense.bias', 'longformer_model.encoder.layer.11.attention.output.dense.bias', 'longformer_model.encoder.layer.9.attention.output.dense.bias', 'longformer_model.encoder.layer.1.attention.self.value_global.bias', 'longformer_model.encoder.layer.3.attention.self.key.weight', 'longformer_model.encoder.layer.10.attention.self.query.weight', 'longformer_model.encoder.layer.0.output.LayerNorm.bias', 'longformer_model.encoder.layer.7.attention.self.value_global.bias', 'longformer_model.encoder.layer.6.attention.self.query.weight', 'longformer_model.encoder.layer.3.attention.self.query.weight', 'longformer_model.encoder.layer.3.intermediate.dense.bias', 'longformer_model.encoder.layer.8.intermediate.dense.bias', 'longformer_model.encoder.layer.11.intermediate.dense.weight', 'longformer_model.encoder.layer.1.attention.self.key_global.bias', 'longformer_model.encoder.layer.6.attention.self.value.weight', 'longformer_model.encoder.layer.6.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.7.attention.self.value.bias', 'longformer_model.encoder.layer.11.attention.self.query_global.bias', 'longformer_model.encoder.layer.1.attention.self.key_global.weight', 'longformer_model.encoder.layer.6.attention.self.query_global.bias', 'longformer_model.encoder.layer.2.attention.self.key.bias', 'longformer_model.encoder.layer.7.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.11.output.dense.bias', 'longformer_model.encoder.layer.0.attention.self.value.weight', 'longformer_model.encoder.layer.0.attention.self.key_global.bias', 'longformer_model.encoder.layer.1.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.2.attention.self.query.bias', 'longformer_model.encoder.layer.6.attention.self.key.weight', 'longformer_model.encoder.layer.7.attention.self.key_global.bias', 'longformer_model.encoder.layer.11.attention.self.query.bias', 'longformer_model.encoder.layer.10.output.LayerNorm.weight', 'longformer_model.encoder.layer.0.attention.self.value.bias', 'longformer_model.encoder.layer.4.attention.output.dense.bias', 'longformer_model.encoder.layer.7.attention.self.query.weight', 'longformer_model.encoder.layer.5.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.9.attention.self.query.bias', 'longformer_model.embeddings.LayerNorm.weight', 'longformer_model.encoder.layer.9.output.dense.bias', 'longformer_model.encoder.layer.7.attention.self.key.bias', 'longformer_model.encoder.layer.2.attention.output.dense.bias', 'longformer_model.encoder.layer.9.attention.self.value_global.bias', 'longformer_model.encoder.layer.1.attention.output.dense.bias', 'longformer_model.encoder.layer.3.attention.self.value_global.bias', 'longformer_model.encoder.layer.7.attention.self.value.weight', 'longformer_model.encoder.layer.8.attention.self.value.weight', 'longformer_model.encoder.layer.1.attention.self.query_global.bias', 'longformer_model.encoder.layer.1.attention.self.query_global.weight', 'longformer_model.encoder.layer.1.attention.output.dense.weight', 'longformer_model.encoder.layer.6.attention.output.dense.bias', 'longformer_model.encoder.layer.4.attention.self.key.weight', 'longformer_model.encoder.layer.5.attention.self.value_global.weight', 'longformer_model.encoder.layer.0.output.LayerNorm.weight', 'longformer_model.encoder.layer.7.intermediate.dense.weight', 'longformer_model.encoder.layer.8.output.dense.weight', 'longformer_model.encoder.layer.2.attention.self.key_global.weight', 'longformer_model.encoder.layer.10.output.dense.bias', 'longformer_model.encoder.layer.11.attention.self.key_global.weight', 'longformer_model.encoder.layer.11.attention.self.value_global.bias', 'longformer_model.encoder.layer.11.intermediate.dense.bias', 'longformer_model.encoder.layer.4.output.dense.weight', 'longformer_model.encoder.layer.8.attention.self.key.weight', 'longformer_model.encoder.layer.7.attention.self.value_global.weight', 'longformer_model.encoder.layer.7.output.LayerNorm.bias', 'longformer_model.encoder.layer.10.intermediate.dense.weight', 'longformer_model.encoder.layer.11.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.8.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.6.attention.self.value_global.bias', 'longformer_model.encoder.layer.11.attention.self.key.weight', 'longformer_model.encoder.layer.4.output.dense.bias', 'longformer_model.encoder.layer.4.attention.self.key_global.bias', 'dense.weight', 'longformer_model.encoder.layer.9.attention.self.query.weight', 'longformer_model.encoder.layer.9.intermediate.dense.bias', 'fc.weight', 'longformer_model.encoder.layer.3.attention.self.value_global.weight', 'fc.bias', 'longformer_model.embeddings.word_embeddings.weight', 'longformer_model.encoder.layer.2.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.1.attention.self.key.weight', 'longformer_model.encoder.layer.10.attention.self.value_global.bias', 'longformer_model.encoder.layer.11.output.dense.weight', 'longformer_model.encoder.layer.0.attention.self.query_global.bias', 'longformer_model.encoder.layer.5.attention.self.key_global.bias', 'longformer_model.encoder.layer.0.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.7.output.LayerNorm.weight', 'longformer_model.encoder.layer.6.attention.self.key_global.bias', 'longformer_model.encoder.layer.9.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.0.attention.self.key.bias', 'longformer_model.encoder.layer.9.attention.self.key.weight', 'longformer_model.encoder.layer.6.intermediate.dense.weight', 'longformer_model.encoder.layer.3.output.LayerNorm.bias', 'longformer_model.encoder.layer.4.attention.self.query_global.bias', 'longformer_model.encoder.layer.8.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.1.output.LayerNorm.weight', 'longformer_model.encoder.layer.2.attention.self.value.bias', 'longformer_model.encoder.layer.7.attention.output.dense.bias', 'longformer_model.encoder.layer.8.attention.self.query_global.bias', 'longformer_model.embeddings.token_type_embeddings.weight', 'longformer_model.encoder.layer.1.attention.self.value_global.weight', 'longformer_model.encoder.layer.5.output.LayerNorm.weight', 'longformer_model.encoder.layer.7.attention.self.key.weight', 'longformer_model.encoder.layer.9.attention.self.query_global.bias', 'longformer_model.encoder.layer.2.attention.self.value_global.weight', 'longformer_model.encoder.layer.3.attention.self.key_global.bias', 'longformer_model.encoder.layer.9.attention.self.key_global.bias', 'longformer_model.encoder.layer.8.attention.self.query.bias', 'longformer_model.encoder.layer.7.output.dense.weight', 'longformer_model.encoder.layer.10.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.0.attention.self.value_global.bias', 'longformer_model.encoder.layer.3.attention.self.value.weight', 'longformer_model.encoder.layer.11.attention.self.key_global.bias', 'longformer_model.encoder.layer.10.attention.self.query_global.bias', 'longformer_model.embeddings.LayerNorm.bias', 'longformer_model.encoder.layer.10.attention.self.key.weight', 'longformer_model.encoder.layer.3.attention.output.dense.bias', 'longformer_model.encoder.layer.4.intermediate.dense.bias', 'longformer_model.encoder.layer.2.attention.self.key_global.bias', 'longformer_model.encoder.layer.4.attention.self.value_global.bias', 'longformer_model.encoder.layer.1.attention.self.key.bias', 'longformer_model.encoder.layer.0.output.dense.weight', 'longformer_model.encoder.layer.4.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.9.intermediate.dense.weight', 'longformer_model.encoder.layer.10.attention.output.dense.bias', 'longformer_model.encoder.layer.0.attention.self.key.weight', 'longformer_model.encoder.layer.2.attention.output.dense.weight', 'longformer_model.encoder.layer.6.output.dense.weight', 'longformer_model.encoder.layer.2.output.dense.weight', 'longformer_model.encoder.layer.3.attention.output.LayerNorm.weight', 'dense.bias', 'longformer_model.encoder.layer.2.attention.self.query_global.weight', 'longformer_model.encoder.layer.0.attention.self.query.bias', 'longformer_model.encoder.layer.10.output.dense.weight', 'longformer_model.encoder.layer.1.attention.self.value.weight', 'longformer_model.encoder.layer.5.attention.self.value_global.bias', 'longformer_model.encoder.layer.2.output.LayerNorm.weight', 'longformer_model.encoder.layer.8.attention.self.key_global.weight', 'longformer_model.encoder.layer.1.output.LayerNorm.bias', 'longformer_model.encoder.layer.4.attention.output.dense.weight', 'longformer_model.encoder.layer.2.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.10.attention.self.key_global.bias', 'longformer_model.encoder.layer.11.output.LayerNorm.weight', 'longformer_model.encoder.layer.10.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.8.attention.self.value.bias', 'longformer_model.encoder.layer.6.attention.self.value.bias', 'longformer_model.encoder.layer.8.attention.self.value_global.bias', 'longformer_model.encoder.layer.1.attention.self.query.weight', 'longformer_model.encoder.layer.6.output.dense.bias', 'longformer_model.encoder.layer.10.output.LayerNorm.bias', 'longformer_model.encoder.layer.5.intermediate.dense.bias', 'longformer_model.encoder.layer.1.intermediate.dense.bias', 'longformer_model.encoder.layer.10.attention.self.key_global.weight', 'longformer_model.encoder.layer.8.attention.self.query.weight', 'longformer_model.encoder.layer.5.attention.self.key.bias', 'longformer_model.encoder.layer.4.attention.self.key_global.weight', 'longformer_model.encoder.layer.4.output.LayerNorm.bias', 'longformer_model.encoder.layer.6.output.LayerNorm.weight', 'longformer_model.encoder.layer.11.attention.self.key.bias', 'longformer_model.encoder.layer.0.attention.output.dense.bias', 'longformer_model.encoder.layer.4.output.LayerNorm.weight', 'longformer_model.encoder.layer.0.intermediate.dense.weight', 'longformer_model.encoder.layer.3.attention.self.value.bias', 'longformer_model.encoder.layer.6.attention.self.query.bias', 'longformer_model.encoder.layer.10.attention.output.dense.weight', 'longformer_model.encoder.layer.8.attention.output.dense.bias', 'longformer_model.encoder.layer.3.output.dense.weight', 'longformer_model.encoder.layer.1.attention.self.value.bias', 'longformer_model.encoder.layer.3.intermediate.dense.weight', 'longformer_model.encoder.layer.8.output.dense.bias', 'longformer_model.encoder.layer.8.intermediate.dense.weight', 'longformer_model.encoder.layer.10.attention.self.query_global.weight', 'longformer_model.encoder.layer.9.attention.output.dense.weight', 'longformer_model.encoder.layer.3.attention.self.key.bias', 'longformer_model.encoder.layer.1.attention.self.query.bias', 'longformer_model.encoder.layer.5.attention.self.value.bias', 'longformer_model.encoder.layer.0.attention.output.LayerNorm.weight', 'longformer_model.encoder.layer.0.attention.output.dense.weight', 'longformer_model.encoder.layer.3.attention.self.query_global.bias', 'longformer_model.encoder.layer.4.attention.self.query.bias', 'longformer_model.encoder.layer.5.attention.output.dense.weight', 'longformer_model.encoder.layer.10.attention.self.value_global.weight', 'longformer_model.encoder.layer.0.attention.self.key_global.weight', 'longformer_model.encoder.layer.7.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.11.output.LayerNorm.bias', 'longformer_model.encoder.layer.4.attention.self.query.weight', 'longformer_model.encoder.layer.5.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.5.attention.self.value.weight', 'longformer_model.encoder.layer.11.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.0.output.dense.bias', 'longformer_model.encoder.layer.3.attention.output.dense.weight', 'longformer_model.encoder.layer.4.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.0.attention.self.value_global.weight', 'longformer_model.encoder.layer.9.attention.self.value.bias', 'longformer_model.encoder.layer.8.attention.self.value_global.weight', 'longformer_model.encoder.layer.10.attention.self.query.bias', 'longformer_model.encoder.layer.2.output.dense.bias', 'longformer_model.encoder.layer.5.attention.output.dense.bias', 'longformer_model.encoder.layer.9.output.LayerNorm.bias', 'longformer_model.encoder.layer.11.attention.self.value_global.weight', 'longformer_model.encoder.layer.4.attention.self.value.bias', 'longformer_model.encoder.layer.6.attention.self.key.bias', 'longformer_model.encoder.layer.9.output.dense.weight', 'longformer_model.encoder.layer.9.attention.self.key_global.weight', 'longformer_model.encoder.layer.7.output.dense.bias', 'longformer_model.encoder.layer.5.attention.self.key.weight', 'longformer_model.encoder.layer.0.intermediate.dense.bias', 'longformer_model.encoder.layer.2.attention.self.value_global.bias', 'longformer_model.encoder.layer.2.attention.self.key.weight', 'longformer_model.encoder.layer.3.attention.output.LayerNorm.bias', 'longformer_model.encoder.layer.1.output.dense.weight', 'longformer_model.encoder.layer.7.attention.output.dense.weight']\n","- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['longformer.encoder.layer.8.attention.self.query.weight', 'longformer.encoder.layer.2.attention.self.key_global.weight', 'longformer.encoder.layer.3.attention.self.value.weight', 'longformer.encoder.layer.11.attention.self.key_global.bias', 'longformer.encoder.layer.0.attention.self.query_global.bias', 'longformer.encoder.layer.1.attention.output.dense.bias', 'longformer.encoder.layer.10.output.dense.bias', 'longformer.encoder.layer.3.attention.output.dense.weight', 'longformer.encoder.layer.9.output.LayerNorm.bias', 'longformer.encoder.layer.11.attention.self.value.bias', 'longformer.encoder.layer.1.intermediate.dense.weight', 'longformer.encoder.layer.11.intermediate.dense.bias', 'longformer.encoder.layer.10.output.LayerNorm.weight', 'longformer.encoder.layer.1.attention.self.query.weight', 'longformer.encoder.layer.1.attention.self.key_global.weight', 'longformer.encoder.layer.4.attention.self.value_global.weight', 'longformer.encoder.layer.7.attention.self.key_global.weight', 'longformer.encoder.layer.7.intermediate.dense.bias', 'longformer.embeddings.token_type_embeddings.weight', 'longformer.encoder.layer.0.attention.output.dense.weight', 'longformer.encoder.layer.8.attention.output.dense.weight', 'longformer.encoder.layer.9.attention.output.dense.bias', 'longformer.encoder.layer.2.attention.self.key.weight', 'longformer.encoder.layer.2.attention.self.value.bias', 'longformer.encoder.layer.3.attention.self.key.bias', 'longformer.encoder.layer.3.attention.self.key_global.weight', 'longformer.encoder.layer.3.attention.output.LayerNorm.bias', 'longformer.encoder.layer.2.attention.output.LayerNorm.weight', 'longformer.encoder.layer.4.output.LayerNorm.weight', 'longformer.encoder.layer.5.attention.output.LayerNorm.weight', 'longformer.encoder.layer.6.attention.self.key.weight', 'longformer.encoder.layer.1.attention.self.value.weight', 'longformer.encoder.layer.0.attention.self.key_global.bias', 'longformer.encoder.layer.5.attention.self.value_global.bias', 'longformer.encoder.layer.5.attention.self.query_global.weight', 'longformer.encoder.layer.5.attention.self.key.bias', 'longformer.encoder.layer.0.attention.self.value.bias', 'longformer.encoder.layer.3.output.dense.bias', 'longformer.encoder.layer.7.attention.self.value_global.bias', 'longformer.encoder.layer.5.output.dense.weight', 'longformer.encoder.layer.6.attention.self.query_global.bias', 'longformer.encoder.layer.9.attention.self.key_global.weight', 'longformer.encoder.layer.9.attention.self.query_global.weight', 'longformer.encoder.layer.2.attention.self.key.bias', 'longformer.encoder.layer.9.output.dense.bias', 'longformer.encoder.layer.4.attention.self.key.weight', 'longformer.encoder.layer.9.attention.self.query.bias', 'longformer.encoder.layer.10.attention.self.query.weight', 'classifier.dense.weight', 'longformer.encoder.layer.6.attention.self.key.bias', 'longformer.encoder.layer.11.attention.self.query.bias', 'longformer.encoder.layer.0.attention.self.value.weight', 'classifier.out_proj.weight', 'longformer.encoder.layer.9.attention.self.query.weight', 'longformer.encoder.layer.0.output.LayerNorm.weight', 'longformer.encoder.layer.7.attention.self.value.bias', 'longformer.encoder.layer.5.attention.self.query_global.bias', 'longformer.encoder.layer.4.attention.self.key_global.weight', 'longformer.encoder.layer.4.attention.self.key_global.bias', 'longformer.encoder.layer.6.attention.self.query.weight', 'longformer.encoder.layer.7.attention.output.dense.weight', 'longformer.encoder.layer.8.intermediate.dense.bias', 'longformer.encoder.layer.5.attention.self.query.weight', 'longformer.encoder.layer.8.output.LayerNorm.weight', 'longformer.encoder.layer.3.attention.self.query_global.bias', 'longformer.encoder.layer.8.attention.output.LayerNorm.bias', 'longformer.encoder.layer.10.attention.self.query_global.bias', 'longformer.encoder.layer.5.attention.self.key.weight', 'longformer.encoder.layer.6.attention.self.key_global.weight', 'longformer.encoder.layer.6.intermediate.dense.bias', 'longformer.encoder.layer.1.attention.output.dense.weight', 'longformer.encoder.layer.7.attention.self.key.weight', 'longformer.encoder.layer.8.attention.output.dense.bias', 'longformer.encoder.layer.4.attention.output.LayerNorm.weight', 'longformer.encoder.layer.10.attention.self.query_global.weight', 'longformer.encoder.layer.2.output.dense.weight', 'longformer.encoder.layer.11.attention.self.value.weight', 'longformer.encoder.layer.7.attention.self.key.bias', 'longformer.encoder.layer.5.attention.self.query.bias', 'longformer.encoder.layer.8.attention.output.LayerNorm.weight', 'longformer.encoder.layer.3.output.LayerNorm.bias', 'longformer.encoder.layer.10.attention.output.dense.weight', 'longformer.encoder.layer.1.intermediate.dense.bias', 'longformer.encoder.layer.11.attention.output.dense.weight', 'longformer.encoder.layer.7.attention.output.LayerNorm.weight', 'longformer.encoder.layer.10.attention.self.key.bias', 'longformer.encoder.layer.5.attention.self.value.bias', 'longformer.encoder.layer.3.attention.self.key.weight', 'longformer.encoder.layer.4.attention.self.value_global.bias', 'longformer.encoder.layer.1.output.LayerNorm.weight', 'longformer.encoder.layer.7.attention.self.value.weight', 'longformer.encoder.layer.3.attention.self.query.bias', 'longformer.encoder.layer.7.attention.self.query.weight', 'longformer.encoder.layer.0.attention.output.LayerNorm.bias', 'longformer.embeddings.position_embeddings.weight', 'longformer.encoder.layer.0.output.dense.bias', 'longformer.encoder.layer.3.intermediate.dense.bias', 'longformer.encoder.layer.7.output.dense.weight', 'longformer.encoder.layer.2.attention.self.query_global.bias', 'longformer.encoder.layer.0.attention.self.key.weight', 'longformer.encoder.layer.8.attention.self.key_global.bias', 'longformer.encoder.layer.2.attention.self.key_global.bias', 'longformer.encoder.layer.11.attention.self.key_global.weight', 'longformer.encoder.layer.3.attention.self.value_global.bias', 'longformer.encoder.layer.5.attention.output.dense.weight', 'longformer.encoder.layer.9.attention.self.query_global.bias', 'longformer.encoder.layer.6.attention.output.LayerNorm.weight', 'longformer.encoder.layer.9.output.dense.weight', 'classifier.out_proj.bias', 'longformer.encoder.layer.5.output.dense.bias', 'longformer.encoder.layer.10.attention.output.dense.bias', 'longformer.encoder.layer.4.output.LayerNorm.bias', 'classifier.dense.bias', 'longformer.encoder.layer.11.attention.self.query.weight', 'longformer.encoder.layer.0.attention.self.key_global.weight', 'longformer.encoder.layer.1.output.dense.weight', 'longformer.encoder.layer.9.intermediate.dense.bias', 'longformer.encoder.layer.0.attention.self.query_global.weight', 'longformer.encoder.layer.10.attention.self.key.weight', 'longformer.encoder.layer.3.intermediate.dense.weight', 'longformer.encoder.layer.10.attention.output.LayerNorm.bias', 'longformer.encoder.layer.8.output.LayerNorm.bias', 'longformer.encoder.layer.4.output.dense.weight', 'longformer.encoder.layer.9.intermediate.dense.weight', 'longformer.encoder.layer.5.output.LayerNorm.weight', 'longformer.encoder.layer.5.intermediate.dense.weight', 'longformer.embeddings.LayerNorm.weight', 'longformer.encoder.layer.3.attention.output.LayerNorm.weight', 'longformer.encoder.layer.0.intermediate.dense.weight', 'longformer.embeddings.LayerNorm.bias', 'longformer.encoder.layer.5.attention.self.key_global.bias', 'longformer.encoder.layer.9.output.LayerNorm.weight', 'longformer.encoder.layer.5.attention.self.value_global.weight', 'longformer.encoder.layer.0.attention.self.value_global.bias', 'longformer.encoder.layer.7.attention.self.query_global.bias', 'longformer.encoder.layer.6.attention.output.dense.bias', 'longformer.encoder.layer.7.output.LayerNorm.weight', 'longformer.encoder.layer.0.attention.output.LayerNorm.weight', 'longformer.encoder.layer.5.output.LayerNorm.bias', 'longformer.encoder.layer.10.attention.self.value_global.bias', 'longformer.encoder.layer.8.attention.self.value.weight', 'longformer.encoder.layer.3.output.dense.weight', 'longformer.encoder.layer.8.attention.self.value.bias', 'longformer.encoder.layer.11.output.LayerNorm.weight', 'longformer.encoder.layer.10.attention.self.key_global.weight', 'longformer.encoder.layer.0.intermediate.dense.bias', 'longformer.encoder.layer.6.attention.self.value.bias', 'longformer.encoder.layer.9.attention.self.key_global.bias', 'longformer.encoder.layer.8.intermediate.dense.weight', 'longformer.encoder.layer.0.attention.output.dense.bias', 'longformer.encoder.layer.2.attention.output.LayerNorm.bias', 'longformer.encoder.layer.9.attention.self.value.bias', 'longformer.encoder.layer.4.intermediate.dense.weight', 'longformer.encoder.layer.9.attention.output.dense.weight', 'longformer.encoder.layer.9.attention.self.value.weight', 'longformer.encoder.layer.7.attention.self.key_global.bias', 'longformer.encoder.layer.9.attention.self.key.weight', 'longformer.encoder.layer.8.attention.self.key.weight', 'longformer.encoder.layer.5.attention.self.value.weight', 'longformer.encoder.layer.1.output.LayerNorm.bias', 'longformer.encoder.layer.2.attention.self.value_global.weight', 'longformer.encoder.layer.4.attention.self.query_global.weight', 'longformer.encoder.layer.6.output.dense.bias', 'longformer.embeddings.word_embeddings.weight', 'longformer.encoder.layer.11.output.dense.weight', 'longformer.encoder.layer.2.attention.self.value.weight', 'longformer.encoder.layer.3.attention.output.dense.bias', 'longformer.encoder.layer.8.attention.self.key.bias', 'longformer.encoder.layer.11.intermediate.dense.weight', 'longformer.encoder.layer.8.output.dense.bias', 'longformer.encoder.layer.4.attention.self.value.bias', 'longformer.encoder.layer.1.attention.self.key_global.bias', 'longformer.encoder.layer.3.attention.self.value.bias', 'longformer.encoder.layer.7.attention.self.query_global.weight', 'longformer.encoder.layer.6.output.dense.weight', 'longformer.encoder.layer.9.attention.self.value_global.bias', 'longformer.encoder.layer.8.attention.self.value_global.bias', 'longformer.encoder.layer.10.output.LayerNorm.bias', 'longformer.encoder.layer.11.attention.self.key.weight', 'longformer.encoder.layer.11.attention.output.dense.bias', 'longformer.encoder.layer.4.output.dense.bias', 'longformer.encoder.layer.4.attention.self.query.bias', 'longformer.encoder.layer.10.attention.self.query.bias', 'longformer.encoder.layer.0.attention.self.value_global.weight', 'longformer.encoder.layer.5.attention.self.key_global.weight', 'longformer.encoder.layer.4.intermediate.dense.bias', 'longformer.encoder.layer.6.attention.self.query.bias', 'longformer.encoder.layer.1.attention.output.LayerNorm.bias', 'longformer.encoder.layer.4.attention.self.value.weight', 'longformer.encoder.layer.4.attention.self.query_global.bias', 'longformer.encoder.layer.6.attention.self.key_global.bias', 'longformer.encoder.layer.6.attention.output.LayerNorm.bias', 'longformer.encoder.layer.11.attention.output.LayerNorm.weight', 'longformer.encoder.layer.2.intermediate.dense.weight', 'longformer.encoder.layer.0.attention.self.query.weight', 'longformer.encoder.layer.2.attention.self.query.bias', 'longformer.encoder.layer.3.attention.self.query_global.weight', 'longformer.encoder.layer.11.attention.self.query_global.weight', 'longformer.encoder.layer.1.output.dense.bias', 'longformer.encoder.layer.8.attention.self.query_global.bias', 'longformer.encoder.layer.1.attention.self.value_global.bias', 'longformer.encoder.layer.11.attention.self.value_global.weight', 'longformer.encoder.layer.1.attention.output.LayerNorm.weight', 'longformer.encoder.layer.4.attention.self.key.bias', 'longformer.encoder.layer.1.attention.self.query_global.bias', 'longformer.encoder.layer.4.attention.output.dense.weight', 'longformer.encoder.layer.9.attention.self.key.bias', 'longformer.encoder.layer.2.attention.self.value_global.bias', 'longformer.encoder.layer.11.attention.self.query_global.bias', 'longformer.encoder.layer.10.intermediate.dense.bias', 'longformer.encoder.layer.1.attention.self.value.bias', 'longformer.encoder.layer.4.attention.self.query.weight', 'longformer.encoder.layer.4.attention.output.LayerNorm.bias', 'longformer.encoder.layer.7.intermediate.dense.weight', 'longformer.encoder.layer.6.attention.self.value_global.weight', 'longformer.encoder.layer.6.intermediate.dense.weight', 'longformer.encoder.layer.2.attention.self.query.weight', 'longformer.encoder.layer.7.output.dense.bias', 'longformer.encoder.layer.5.intermediate.dense.bias', 'longformer.encoder.layer.0.attention.self.query.bias', 'longformer.encoder.layer.1.attention.self.query_global.weight', 'longformer.encoder.layer.9.attention.output.LayerNorm.bias', 'longformer.encoder.layer.2.output.LayerNorm.weight', 'longformer.encoder.layer.7.attention.self.query.bias', 'longformer.encoder.layer.10.attention.self.value.weight', 'longformer.encoder.layer.5.attention.output.LayerNorm.bias', 'longformer.encoder.layer.11.output.LayerNorm.bias', 'longformer.encoder.layer.11.attention.output.LayerNorm.bias', 'longformer.encoder.layer.3.attention.self.key_global.bias', 'longformer.encoder.layer.10.attention.self.value.bias', 'longformer.encoder.layer.6.attention.self.value.weight', 'longformer.encoder.layer.8.attention.self.query.bias', 'longformer.encoder.layer.1.attention.self.query.bias', 'longformer.encoder.layer.3.output.LayerNorm.weight', 'longformer.encoder.layer.2.attention.self.query_global.weight', 'longformer.encoder.layer.3.attention.self.query.weight', 'longformer.encoder.layer.0.output.dense.weight', 'longformer.encoder.layer.4.attention.output.dense.bias', 'longformer.encoder.layer.3.attention.self.value_global.weight', 'longformer.encoder.layer.6.attention.self.query_global.weight', 'longformer.encoder.layer.6.output.LayerNorm.weight', 'longformer.encoder.layer.7.attention.output.dense.bias', 'longformer.encoder.layer.7.attention.output.LayerNorm.bias', 'longformer.encoder.layer.8.output.dense.weight', 'longformer.encoder.layer.11.output.dense.bias', 'longformer.encoder.layer.8.attention.self.key_global.weight', 'longformer.encoder.layer.2.output.dense.bias', 'longformer.encoder.layer.7.output.LayerNorm.bias', 'longformer.encoder.layer.8.attention.self.query_global.weight', 'longformer.encoder.layer.10.attention.self.value_global.weight', 'longformer.encoder.layer.1.attention.self.value_global.weight', 'longformer.encoder.layer.7.attention.self.value_global.weight', 'longformer.encoder.layer.2.attention.output.dense.weight', 'longformer.encoder.layer.6.attention.self.value_global.bias', 'longformer.encoder.layer.0.attention.self.key.bias', 'longformer.encoder.layer.0.output.LayerNorm.bias', 'longformer.encoder.layer.10.intermediate.dense.weight', 'longformer.encoder.layer.1.attention.self.key.weight', 'longformer.encoder.layer.2.attention.output.dense.bias', 'longformer.encoder.layer.10.attention.output.LayerNorm.weight', 'longformer.encoder.layer.10.attention.self.key_global.bias', 'longformer.encoder.layer.11.attention.self.key.bias', 'longformer.encoder.layer.6.attention.output.dense.weight', 'longformer.encoder.layer.2.output.LayerNorm.bias', 'longformer.encoder.layer.5.attention.output.dense.bias', 'longformer.encoder.layer.10.output.dense.weight', 'longformer.encoder.layer.9.attention.self.value_global.weight', 'longformer.encoder.layer.8.attention.self.value_global.weight', 'longformer.encoder.layer.11.attention.self.value_global.bias', 'longformer.encoder.layer.9.attention.output.LayerNorm.weight', 'longformer.encoder.layer.6.output.LayerNorm.bias', 'longformer.encoder.layer.2.intermediate.dense.bias', 'longformer.encoder.layer.1.attention.self.key.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["['input_ids', 'attention_mask', 'labels']\n"]}],"source":["#import dataset from local\n","ds = pd.read_csv(\"/content/drive/MyDrive/cogs402longformer/fakeclinicalnotes/data/fake_notes.csv\")\n","dataset = datasets.Dataset.from_pandas(ds)\n","cogs402_ds = dataset.train_test_split(test_size=0.20)\n","cogs402_ds['validation'] = cogs402_ds.pop('test')\n","\n","#get the training set and set format the columns into a tensor\n","cogs402_test = get_notes_dataset(cogs402_ds['train'])\n","columns = cogs402_test.input_columns + cogs402_test.target_columns\n","print(columns)\n","cogs402_test.set_format(type='torch', columns=columns)\n","cogs402_test=cogs402_test.remove_columns(['text'])\n","\n","#import model\n","model = longformer_finetuned_notes()"]},{"cell_type":"code","execution_count":null,"id":"deaabfa2-0855-41fd-870c-7a8b91e32d44","metadata":{"id":"deaabfa2-0855-41fd-870c-7a8b91e32d44","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660027099418,"user_tz":420,"elapsed":226,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"30744025-ce03-4648-e55d-9a34475cb179"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}],"source":["if torch.cuda.is_available():\n","    model = model.cuda()\n","\n","print(model.device)"]},{"cell_type":"markdown","source":["## Predict over the dataset"],"metadata":{"id":"lUXRli8TIIwm"},"id":"lUXRli8TIIwm"},{"cell_type":"markdown","source":["Predict using the model on the selected dataset using the [Huggingface trainer](https://huggingface.co/docs/transformers/main_classes/trainer) API."],"metadata":{"id":"IXjbkX-PAGay"},"id":"IXjbkX-PAGay"},{"cell_type":"code","source":["from transformers import Trainer, TrainingArguments\n","\n","batch_size = 1\n","gradient_acc = 4\n","model_name = f\"longformer-finetuned_papers\"\n","training_args = TrainingArguments(output_dir=f\"models/{model_name}\",\n","                                  num_train_epochs = 2,\n","                                  learning_rate=2e-5,\n","                                  per_device_train_batch_size=batch_size,\n","                                  per_device_eval_batch_size=batch_size,\n","                                  weight_decay=0.01,\n","                                  evaluation_strategy=\"epoch\",\n","                                  disable_tqdm=False,\n","                                  push_to_hub=False,\n","                                  log_level=\"error\",\n","                                  fp16=True,\n","                                  gradient_accumulation_steps=gradient_acc,\n","                                  gradient_checkpointing=True,\n","                                  save_strategy = \"epoch\")"],"metadata":{"id":"7PUTFonI_XLM"},"id":"7PUTFonI_XLM","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["F1 and accuracy are good general metrics for model performance. Recall and precision can be used if desired."],"metadata":{"id":"NSxE_HDPAKaT"},"id":"NSxE_HDPAKaT"},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, f1_score\n","\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    f1 = f1_score(labels, preds, average=\"weighted\")\n","    acc = accuracy_score(labels, preds)\n","    return {\"accuracy\": acc, \"f1\": f1}"],"metadata":{"id":"65V97tOz_e37"},"id":"65V97tOz_e37","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Place the finishing touches on our trainer, passing in the arguments, model, metrics, and datacollator (which doesn't really matter here as we pass in one item at a time)."],"metadata":{"id":"SmeWbe1hEpjD"},"id":"SmeWbe1hEpjD"},{"cell_type":"code","source":["from transformers import DataCollatorWithPadding\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    tokenizer=tokenizer,\n","    data_collator = data_collator\n",")"],"metadata":{"id":"TpkwUmWN_lu1"},"id":"TpkwUmWN_lu1","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here we predict over the entire validation set."],"metadata":{"id":"J_rg0KRlE2PU"},"id":"J_rg0KRlE2PU"},{"cell_type":"code","source":["preds_output = trainer.predict(cogs402_test)"],"metadata":{"id":"4W9kCODH_wfT","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1660027109236,"user_tz":420,"elapsed":4299,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"718376b8-70d5-4963-f3e4-c56d4e445ec9"},"id":"4W9kCODH_wfT","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[""]},"metadata":{}}]},{"cell_type":"markdown","source":["## Picking Examples"],"metadata":{"id":"wj5dQazdIbxH"},"id":"wj5dQazdIbxH"},{"cell_type":"markdown","source":["False negatives and false postives are usually very interesting examples to analyze so to get the list of all false negatives and positives, we get our model's predictions and the list of true labels."],"metadata":{"id":"wjeyImJmApjd"},"id":"wjeyImJmApjd"},{"cell_type":"code","source":["y_preds = np.argmax(preds_output.predictions, axis=1)\n","y_true = np.array(cogs402_test[\"labels\"])"],"metadata":{"id":"IyRQ0z-QAzAU"},"id":"IyRQ0z-QAzAU","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can get the list of false negatives and false positives by subtracting the list of labels. \n","\n","\n","If, after subtracting, the list is 0, then we have a correct prediction as the two labels are the same. We can then filter by the value of the labels to get the positive and negative class. \n","\n","\n","If, after subtracting the false label from the true label, we have a negative, then we know that the actual label is 0 while the predicted label is 1 (as 0-1 is -1). Therefore, we get a false positive in that case. \n","\n","\n","On the other hand, if after subtracting the false label from the true label, we get a positive, then we know that the actual label is 1 while the predicted label is 0 (as 1-0 is 1). Therefore, we have a false negative."],"metadata":{"id":"T9iF_01WFrZL"},"id":"T9iF_01WFrZL"},{"cell_type":"code","source":["diff = y_true-y_preds\n","correct = np.where(diff == 0)[0]\n","\n","pos = np.where((y_true-y_preds == 0) & (y_true==1))[0]\n","neg = np.where((y_true-y_preds == 0) & (y_true==0))[0]\n","\n","false_pos = np.where(diff == -1)[0]\n","false_neg = np.where(diff == 1)[0]\n","\n","print('Correctly classified: ', correct)\n","\n","print('cor pos: ', pos)\n","print('cor neg: ', neg)\n","\n","print('False positives: ', false_pos)\n","print('False negatives: ', false_neg)"],"metadata":{"id":"ZoIa9_KIA2rt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660027109237,"user_tz":420,"elapsed":11,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"2c8eb652-25df-49c6-db59-93163d65e869"},"id":"ZoIa9_KIA2rt","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Correctly classified:  [ 9 10 11]\n","cor pos:  []\n","cor neg:  [ 9 10 11]\n","False positives:  []\n","False negatives:  [0 1 2 3 4 5 6 7 8]\n"]}]},{"cell_type":"markdown","source":["Take example for evaluation based on random pick"],"metadata":{"id":"d4DdhW2T6wHE"},"id":"d4DdhW2T6wHE"},{"cell_type":"code","execution_count":null,"id":"a35e74a3-bd67-4ee2-8e5b-2da01503f27b","metadata":{"id":"a35e74a3-bd67-4ee2-8e5b-2da01503f27b"},"outputs":[],"source":["# rand_pos = np.random.choice(pos, size=1)\n","# rand_neg = np.random.choice(neg, size=1)\n","# rand_fp = np.random.choice(false_pos, size=1)\n","# rand_fn = np.random.choice(false_neg, size=1)"]},{"cell_type":"markdown","source":["Some other interesting examples include the examples that are the most confidently predicted to be positive or negative. (i.e. the examples with the highest predicted probability)"],"metadata":{"id":"kyVEhUfidwRV"},"id":"kyVEhUfidwRV"},{"cell_type":"code","source":["highest_pos = [np.argmax(preds_output.predictions[:,1])]\n","highest_neg = [np.argmax(preds_output.predictions[:,0])]\n","\n","# for news dataset\n","# highest_neg = [np.argmax(np.delete(preds_output.predictions, 1933, 0)[:,0])]\n","\n","print(highest_pos)\n","print(highest_neg)"],"metadata":{"id":"6WWpe52Cd3wk","executionInfo":{"status":"ok","timestamp":1660027109238,"user_tz":420,"elapsed":9,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"80acb66b-65f5-4a40-cf1e-1390fb3ceee6"},"id":"6WWpe52Cd3wk","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0]\n","[6]\n"]}]},{"cell_type":"markdown","source":["## Getting the attention"],"metadata":{"id":"RIeTsarXI7I9"},"id":"RIeTsarXI7I9"},{"cell_type":"markdown","source":["Now that we have the example we want to visualize the attentions for, we pass it into the model again in order to obtain the attention output. We stack the attentions to get an output attention tensor of shape: (layer, batch, head, seq_len, x + attention_window + 1) and a global attention tensor of shape (layer, batch, head, seq_len, x) where x is the number of global attention tokens."],"metadata":{"id":"xctV7QJdJEDe"},"id":"xctV7QJdJEDe"},{"cell_type":"code","source":["test_val = [7]\n","print(test_val)\n","testexam = cogs402_test[test_val]"],"metadata":{"id":"FrX3LUUxeORB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660027109238,"user_tz":420,"elapsed":7,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"8570a679-919a-4e7b-e927-8214aa80ee79"},"id":"FrX3LUUxeORB","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[7]\n"]}]},{"cell_type":"code","execution_count":null,"id":"04c5bcaf-5fe3-4813-8444-5cfb2c63a92b","metadata":{"id":"04c5bcaf-5fe3-4813-8444-5cfb2c63a92b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660027109814,"user_tz":420,"elapsed":581,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"af93aa17-2afd-4b11-a73d-7ec1fe05304c"},"outputs":[{"output_type":"stream","name":"stdout","text":["output_attention.shape torch.Size([12, 1, 12, 2048, 514])\n","gl_output_attention.shape torch.Size([12, 1, 12, 2048, 1])\n"]}],"source":["output = model(testexam[\"input_ids\"].cuda(), attention_mask=testexam['attention_mask'].cuda(), labels=testexam['labels'].cuda(), output_attentions = True)\n","batch_attn = output[-2]\n","output_attentions = torch.stack(batch_attn).cpu()\n","global_attention = output[-1]\n","output_global_attentions = torch.stack(global_attention).cpu()\n","print(\"output_attention.shape\", output_attentions.shape)\n","print(\"gl_output_attention.shape\", output_global_attentions.shape)"]},{"cell_type":"code","source":["print(testexam['labels'][0])\n","print(output[1].argmax())"],"metadata":{"id":"SO4yNy98t_UP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660027110043,"user_tz":420,"elapsed":231,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"d59f13fb-ee44-4e09-a615-a16e635b45ca"},"id":"SO4yNy98t_UP","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1)\n","tensor(0, device='cuda:0')\n"]}]},{"cell_type":"code","execution_count":null,"id":"2467c3d1-fe58-4e6d-aa98-534a6df72fcc","metadata":{"id":"2467c3d1-fe58-4e6d-aa98-534a6df72fcc"},"outputs":[],"source":["# print(os.getcwd())\n","# yes = torch.load(\"resources/longformer_test2/epoch_3/aggregate_attn.pt\")"]},{"cell_type":"markdown","source":["A unique property of the longformer model is that the matrix output for the attention is not a seq_len x seq_len output. Each token can only attend to the preceeding w/2 tokens and the succeeding w/2 tokens, dictated by whatever you choose the model's attention window w to be. Another name for this is called the sliding window attention. Therefore, we need to convert sliding attention matrix to correct seq_len x seq_len matrix to remain consistent with other types of Transformer Neural Networks.\n","\n","To do so, we run the following 4 functions. Our attentions will change from an output attention tensor of shape (layer, batch, head, seq_len, x + attention_window + 1) and a global attention tensor of shape (layer, batch, head, seq_len, x) to a single tensor of shape (layer, batch, head, seq_len, seq_len). More information about the functions can be found here. More information about the functions can be found [here](https://colab.research.google.com/drive/1Kxx26NtIlUzioRCHpsR8IbSz_DpRFxEZ#scrollTo=liVhkxiH9Le0)."],"metadata":{"id":"OevnNprR67LK"},"id":"OevnNprR67LK"},{"cell_type":"code","execution_count":null,"id":"0882a3e5-1b0c-4319-92a3-92f5b516d854","metadata":{"id":"0882a3e5-1b0c-4319-92a3-92f5b516d854"},"outputs":[],"source":["def create_head_matrix(output_attentions, global_attentions):\n","    new_attention_matrix = torch.zeros((output_attentions.shape[0], \n","                                      output_attentions.shape[0]))\n","    for i in range(output_attentions.shape[0]):\n","        test_non_zeroes = torch.nonzero(output_attentions[i]).squeeze()\n","        test2 = output_attentions[i][test_non_zeroes[1:]]\n","        new_attention_matrix_indices = test_non_zeroes[1:]-257 + i\n","        new_attention_matrix[i][new_attention_matrix_indices] = test2\n","        new_attention_matrix[i][0] = output_attentions[i][0]\n","        new_attention_matrix[0] = global_attentions.squeeze()[:output_attentions.shape[0]]\n","    return new_attention_matrix.detach().cpu().numpy()\n","\n","\n","def attentions_all_heads(output_attentions, global_attentions):\n","    new_matrix = []\n","    for i in range(output_attentions.shape[0]):\n","        matrix = create_head_matrix(output_attentions[i], global_attentions[i])\n","        new_matrix.append(matrix)\n","    return np.stack(new_matrix)\n","\n","\n","def all_batches(output_attentions, global_attentions):\n","    new_matrix = []\n","    for i in range(output_attentions.shape[0]):\n","        matrix = attentions_all_heads(output_attentions[i], global_attentions[i])\n","        new_matrix.append(matrix)\n","    return np.stack(new_matrix)\n","\n","def all_layers(output_attentions, global_attentions):\n","    new_matrix = []\n","    for i in range(output_attentions.shape[0]):\n","        matrix = all_batches(output_attentions[i], global_attentions[i])\n","        new_matrix.append(matrix)\n","    return np.stack(new_matrix)"]},{"cell_type":"code","source":["converted_mat = all_layers(output_attentions, output_global_attentions)\n","print(converted_mat.shape)"],"metadata":{"id":"IpdfMEMAuvyR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660027135431,"user_tz":420,"elapsed":25390,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"a1c5cc31-cab3-40f6-9939-ad1b01f7fd9e"},"id":"IpdfMEMAuvyR","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(12, 1, 12, 2048, 2048)\n"]}]},{"cell_type":"markdown","source":["## Formatting the attentions"],"metadata":{"id":"OA32VVs6KF-M"},"id":"OA32VVs6KF-M"},{"cell_type":"markdown","source":["Our end goal is to overlay the attentions onto the tokens and produce a PDF of the results, so we need to grab the original tokens from the text. We cant grab the original text as it is one large string, but using the tokenizer function, we can change our input ids back to a list of tokens."],"metadata":{"id":"Sl4xm-JGKKvt"},"id":"Sl4xm-JGKKvt"},{"cell_type":"code","source":["all_tokens = tokenizer.convert_ids_to_tokens(testexam[\"input_ids\"][0])"],"metadata":{"id":"N-Wr_p4LsTv-"},"id":"N-Wr_p4LsTv-","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Some heads may be more important than others so we scale each attention matrix by their respective head and layer. The notebook used to get head importance is [here](https://colab.research.google.com/drive/1sIEvUvCofF0puv0mRZUio3JEF0y1Ce3g?usp=sharing)."],"metadata":{"id":"P-nS_AHa7Hv6"},"id":"P-nS_AHa7Hv6"},{"cell_type":"code","source":["# head_importance = torch.load(\"/content/drive/MyDrive/fakeclinicalnotes/t3-visapplication/notes/head_importance.pt\")\n","head_importance = torch.load(\"/content/drive/MyDrive/cogs402longformer/fakeclinicalnotes/t3-visapplication/notes/head_importance.pt\") "],"metadata":{"id":"UsAznmcDyBgR"},"id":"UsAznmcDyBgR","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def scale_by_importance(attention_matrix, head_importance):\n","  new_matrix = np.zeros_like(attention_matrix)\n","  for i in range(attention_matrix.shape[0]):\n","    head_importance_layer = head_importance[i]\n","    for j in range(attention_matrix.shape[1]):\n","      new_matrix[i,j] = attention_matrix[i,j] * np.expand_dims(head_importance_layer, axis=(1,2))\n","  return new_matrix"],"metadata":{"id":"_HFs_vLw0230"},"id":"_HFs_vLw0230","execution_count":null,"outputs":[]},{"cell_type":"code","source":["converted_mat_importance = scale_by_importance(converted_mat, head_importance)"],"metadata":{"id":"XUcjPfxeHbqT"},"id":"XUcjPfxeHbqT","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Get the sum of the attentions for all the tokens (column-wise). In other words, find out how much every word is attended to"],"metadata":{"id":"u0ViKJAn7Ap0"},"id":"u0ViKJAn7Ap0"},{"cell_type":"code","source":["attention_matrix_importance = converted_mat_importance.sum(axis=3)\n","print(attention_matrix_importance.shape)"],"metadata":{"id":"EhMNdupbxFrx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660027197283,"user_tz":420,"elapsed":241,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"2219bff6-6828-4daf-b988-9aeda0e11a30"},"id":"EhMNdupbxFrx","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(12, 1, 12, 2048)\n"]}]},{"cell_type":"markdown","source":["## Visualizing the Attention"],"metadata":{"id":"BvnR9GJi13oP"},"id":"BvnR9GJi13oP"},{"cell_type":"markdown","source":["A dataframe is good for picking out information from the example, but it isn't the best being a easy to read visualization. Its easier to see how much each word is attended to in an example if we have the actual example, with the words highlighted based on the magnitude of attention.\n","\n","We use https://github.com/jiesutd/Text-Attention-Heatmap-Visualization to show how much each token in the example is attended to, up to the max number of tokens we specified earlier.\n","\n","In short, these functions iterate over the list of attentions and tokens, cleans the tokens to remove special characters, and normalizes the data if you wish for it to."],"metadata":{"id":"DjTu0_guLI1T"},"id":"DjTu0_guLI1T"},{"cell_type":"code","source":["## convert the text/attention list to latex code, which will further generates the text heatmap based on attention weights.\n","import numpy as np\n","\n","latex_special_token = [\"!@#$%^&*(){}\"]\n","\n","def generate(text_list, attention_list, latex_file, color='red', rescale_value = True):\n","\tassert(len(text_list) == len(attention_list))\n","\tif rescale_value:\n","\t\tattention_list = rescale(attention_list)\n","\tword_num = len(text_list)\n","\ttext_list = clean_word(text_list)\n","\twith open(latex_file,'w') as f:\n","\t\tf.write(r'''\\documentclass[varwidth]{standalone}\n","\\special{papersize=210mm,297mm}\n","\\usepackage{color}\n","\\usepackage{tcolorbox}\n","\\usepackage{CJK}\n","\\usepackage{adjustbox}\n","\\tcbset{width=0.9\\textwidth,boxrule=0pt,colback=red,arc=0pt,auto outer arc,left=0pt,right=0pt,boxsep=5pt}\n","\\begin{document}\n","\\begin{CJK*}{UTF8}{gbsn}'''+'\\n')\n","\t\tstring = r'''{\\setlength{\\fboxsep}{0pt}\\colorbox{white!0}{\\parbox{0.9\\textwidth}{'''+\"\\n\"\n","\t\tfor idx in range(word_num):\n","\t\t\tstring += \"\\\\colorbox{%s!%s}{\"%(color, attention_list[idx])+\"\\\\strut \" + text_list[idx]+\"} \"\n","\t\tstring += \"\\n}}}\"\n","\t\tf.write(string+'\\n')\n","\t\tf.write(r'''\\end{CJK*}\n","\\end{document}''')\n","\n","def rescale(input_list):\n","\tthe_array = np.asarray(input_list)\n","\tthe_max = np.max(the_array)\n","\tthe_min = np.min(the_array)\n","\trescale = ((the_array - the_min)/(the_max-the_min))*100\n","\treturn rescale.tolist()\n","\n","\n","def clean_word(word_list):\n","\tnew_word_list = []\n","\tfor word in word_list:\n","\t\tfor special_sensitive in [\"\\\\\", \"^\"]:\n","\t\t\tif special_sensitive in word:\n","\t\t\t\tword = word.replace(special_sensitive, '')\n","\t\tfor latex_sensitive in [\"%\", \"&\", \"#\", \"_\",  \"{\", \"}\"]:\n","\t\t\tif latex_sensitive in word:\n","\t\t\t\tword = word.replace(latex_sensitive, '\\\\' +latex_sensitive)\n","\t\tnew_word_list.append(word)\n","\treturn new_word_list"],"metadata":{"id":"FCsAm5i3jmKA"},"id":"FCsAm5i3jmKA","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here, we sum get the attentions over all layers and heads."],"metadata":{"id":"chtfdhR_LmE2"},"id":"chtfdhR_LmE2"},{"cell_type":"code","source":["average_attention = attention_matrix_importance.squeeze().sum(axis=1)\n","average_attention = average_attention.sum(axis=0)\n","print(average_attention)"],"metadata":{"id":"goaO9arYjopz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660027197284,"user_tz":420,"elapsed":8,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"de14a460-1043-4a6e-9873-3017222524cc"},"id":"goaO9arYjopz","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[282.53772   44.761     44.19396  ...  44.002342  43.229713  44.133484]\n"]}]},{"cell_type":"markdown","source":["We call the main function above. It takes in a list of tokens, a list of attentions, a title, and a colour. Please change \"papers\" to whatever your project requires."],"metadata":{"id":"Hzic3AuULynV"},"id":"Hzic3AuULynV"},{"cell_type":"code","source":["title_all = f\"notes_{test_val[0]}.tex\"\n","generate(all_tokens, average_attention, title_all, 'red')"],"metadata":{"id":"htPtu7kErWfN"},"id":"htPtu7kErWfN","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Lets suppose you don't want to find out the attentions over all layers, but just one layer. You can do that by doing one less summation and instead picking out the layer you want immediately. Here we are picking out the last layer."],"metadata":{"id":"TCKn9M3ILsEh"},"id":"TCKn9M3ILsEh"},{"cell_type":"code","source":["print(attention_matrix_importance[11].squeeze().shape)\n","average_attention_final_layer = attention_matrix_importance[11].squeeze().sum(axis=0)\n","print(average_attention_final_layer)\n","\n","# mean_12 = np.median(average_attention_final_layer)\n","# average_attention_final_layer[average_attention_final_layer < mean_12] = 0\n","# print(average_attention_final_layer)"],"metadata":{"id":"GaM018NVunZH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660027197286,"user_tz":420,"elapsed":7,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"ce5f3eea-d0e2-4150-82ec-5568105a1144"},"id":"GaM018NVunZH","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(12, 2048)\n","[9.736143  1.4387776 1.4594319 ... 1.3754647 1.3575159 1.3396648]\n"]}]},{"cell_type":"markdown","source":["We call the main function above. Please change \"papers\" to whatever your project requires."],"metadata":{"id":"Cq8g9U_RML8Y"},"id":"Cq8g9U_RML8Y"},{"cell_type":"code","source":["title_last_layer = f\"notes_{test_val[0]}_layer_12_only.tex\"\n","generate(all_tokens, average_attention_final_layer, title_last_layer, 'red')"],"metadata":{"id":"fSl21NvVyW-n"},"id":"fSl21NvVyW-n","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Of course, you can experiment with which layers, or heads you want to visualize the attentions for based on what you desire from your own project."],"metadata":{"id":"46NQc1FGMTf6"},"id":"46NQc1FGMTf6"},{"cell_type":"markdown","source":["## Masked Attention\n","\n","Lets suppose we want to look at the attention heatmap without the stopwords and punctuations"],"metadata":{"id":"8x5OJe-NVZ4x"},"id":"8x5OJe-NVZ4x"},{"cell_type":"markdown","source":["We import a list of stopwords from nltk and tokenize them so they are in the same style as our input tokens. We create a set using the stopwords."],"metadata":{"id":"CZo1iiYfVj0y"},"id":"CZo1iiYfVj0y"},{"cell_type":"code","source":["import nltk\n","from transformers import AutoTokenizer\n","nltk.download('stopwords')\n","tokenizer2 = AutoTokenizer.from_pretrained('allenai/longformer-base-4096', add_prefix_space=True)"],"metadata":{"id":"hiFZX4ShyRkv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660027200692,"user_tz":420,"elapsed":3410,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"16189d9d-5c3b-4cd1-f55b-f9a88d9bd230"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"id":"hiFZX4ShyRkv"},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","all_stopwords = stopwords.words('english')\n","all_stopwords.append(\" \")\n","stopwords = set(tokenizer2.tokenize(all_stopwords, is_split_into_words =True))\n","stopwords.update(all_stopwords)\n","print(stopwords)"],"metadata":{"id":"YSp0bf1ZyTn8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660027200693,"user_tz":420,"elapsed":8,"user":{"displayName":"daniel hou","userId":"13623878136116974888"}},"outputId":"38c6c9c9-b26d-4c92-f114-6cb66a14c04e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Ġin', \"you're\", 'Ġdoing', 'Ġaren', 'whom', 'now', 'd', 'Ġdown', 'Ġhas', \"'t\", 'Ġfrom', 'Ġwere', 'Ġbefore', 'ourselves', 'shan', 'Ġthere', 'Ġthey', 'Ġdidn', 'Ġthe', 'while', 'Ġfurther', \"doesn't\", 'Ġthan', 'Ġis', 'Ġfew', 'Ġwhile', 'Ġhe', 'were', 'has', 'below', 'Ġwhen', 'Ġjust', 'after', 'into', 'weren', 'Ġhaving', 'once', 'Ġdo', 'Ġre', 'same', 'on', 'and', 'Ġher', 'Ġsome', 'Ġtheir', 'Ġthen', 'don', 'can', 'who', 'under', \"she's\", 'you', 'Ġthemselves', 'Ġwhom', 'Ġoff', 'above', 'Ġsame', 'itself', 'hers', 'doing', 'just', 'Ġhis', \"needn't\", 'no', 'Ġunder', 'again', 'we', 'at', 'Ġabove', 'Ġonly', 'all', 'Ġthose', 'Ġown', 'each', \"haven't\", 'Ġwhy', \"should've\", 'Ġnow', 'most', 'your', 'how', 'own', 'Ġme', 'out', \"'ll\", 'Ġwouldn', 'Ġhim', 'Ġwhat', \"aren't\", 'Ġor', 'but', \"it's\", 'didn', 'Ġhadn', 'i', 'myself', 'off', 'Ġan', 'Ġhere', 'such', 've', 'theirs', 'Ġas', 'Ġhers', 'Ġthrough', 'doesn', 'Ġhaven', \"'re\", 'shouldn', 'Ġyou', 'Ġ', 'Ġso', 'Ġo', 'won', 'Ġbe', 'needn', 'where', 'very', 'Ġother', 'during', 'should', 'there', 'so', 'Ġd', \"hadn't\", 'Ġthem', 'Ġwe', 'our', 'aren', 'too', 'Ġbeen', 'am', 'Ġout', 'couldn', \"'d\", \"you've\", 'Ġtoo', 'more', 'Ġuntil', 'yours', \"hasn't\", 'Ġwho', 'Ġbut', 'what', 'Ġhave', 'Ġhad', 'before', 'about', 'Ġbetween', 'Ġbeing', 'mightn', 'Ġmust', 'Ġon', 'Ġmight', \"'ve\", 'of', 'they', 'for', 'he', 'Ġsuch', 'Ġherself', 'Ġabout', 'Ġif', 'him', ' ', 'Ġmore', 'Ġourselves', 'other', 'Ġall', 'Ġve', 'Ġmost', 'only', \"wouldn't\", \"mustn't\", 'here', 'Ġt', 'a', 'Ġtheirs', 'few', 'y', 'Ġhimself', 'by', 'Ġinto', 'then', 'between', 'Ġain', 'that', 'ours', 'with', 'Ġisn', 'had', 'Ġwhich', 'are', 'Ġour', 'yourselves', 'an', 'her', 'm', 'Ġat', \"'s\", 'Ġdid', 'Ġbelow', 'll', \"shan't\", 'hadn', 'Ġwill', 'himself', 'Ġmyself', 'hasn', 'Ġup', 'Ġno', 'Ġby', \"that'll\", 'o', 'some', 'Ġyours', 'Ġit', 'its', \"shouldn't\", 'Ġa', 're', 'their', 'have', 'Ġthese', 'than', 's', 'being', 'Ġagainst', 'Ġover', 'those', 'Ġare', 'Ġof', \"isn't\", 'Ġwith', 'themselves', 'Ġll', 'Ġdoes', \"you'll\", 'Ġonce', 'until', \"couldn't\", 'Ġafter', 'been', 'the', 'or', 'Ġthat', 'to', 'Ġs', \"weren't\", 'ain', 'she', 'Ġwasn', 'because', 'not', 'Ġduring', 'ma', 'Ġbecause', \"don't\", \"wasn't\", 'why', 'Ġm', 'through', 'Ġcouldn', 'this', 'does', 'did', 'was', 'me', 'having', 'my', 'any', 'his', 'be', 'Ġitself', 'herself', 'Ġshe', 't', 'Ġand', 'as', 'Ġeach', 'Ġdoesn', 'Ġneed', 'Ġours', 'Ġto', 'is', 'Ġnot', 'yourself', 'Ġfor', \"won't\", 'from', 'Ġdon', 'Ġhow', 'Ġvery', 'wasn', 'them', 'against', 'Ġma', 'Ġwon', 'Ġany', 'which', 'Ġam', 'Ġshould', 'these', 'down', 'mustn', 'further', 'Ġmy', \"didn't\", 'Ġwhere', 'Ġi', \"mightn't\", 'Ġagain', 'when', 'haven', 'over', 'Ġboth', 'Ġcan', 'isn', 'if', 'Ġy', 'Ġyour', 'do', 'Ġyourselves', 'Ġweren', \"you'd\", 'Ġsh', 'Ġnor', 'up', 'will', 'Ġyourself', 'nor', 'Ġshouldn', 'in', 'Ġthis', 'Ġits', 'wouldn', 'it', 'Ġwas', 'n', 'both', 'Ġhasn'}\n"]}],"id":"YSp0bf1ZyTn8"},{"cell_type":"markdown","source":["We apply the mask over the summed attention by creating a mask where all words that are in our set of stopwords or non-alpha are set to 0. "],"metadata":{"id":"wEfwtSKcVtjw"},"id":"wEfwtSKcVtjw"},{"cell_type":"code","source":["alpha_neumeric_nums = [idx for idx, element in enumerate(all_tokens) if element.isalpha() if element not in stopwords]\n","mask = np.ones(average_attention_final_layer.shape,dtype=bool) \n","mask[alpha_neumeric_nums] = False\n","\n","average_attention_final_layer[mask] = 0\n","average_attention[mask] = 0"],"metadata":{"id":"Kq7809nZyrc1"},"execution_count":null,"outputs":[],"id":"Kq7809nZyrc1"},{"cell_type":"markdown","source":["Remake the heatmap using our masked attention."],"metadata":{"id":"4pG_hAgpWJCw"},"id":"4pG_hAgpWJCw"},{"cell_type":"code","source":["title_all = f\"papers_{test_val[0]}_all_masked.tex\"\n","generate(all_tokens, average_attention, title_all, 'red')"],"metadata":{"id":"QO8GQ0TWWIe-"},"execution_count":null,"outputs":[],"id":"QO8GQ0TWWIe-"},{"cell_type":"code","source":["title_all = f\"papers_{test_val[0]}_12_masked.tex\"\n","generate(all_tokens, average_attention_final_layer, title_all, 'red')"],"metadata":{"id":"96qlyzW9QQQM"},"execution_count":null,"outputs":[],"id":"96qlyzW9QQQM"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"provenance":[{"file_id":"1Gyxj9rP2KnnCzit9zN3h3MeTTiQ13R7B","timestamp":1658867796010},{"file_id":"1iVojJQp0CZS484tMZqIizosXPLxgKvRX","timestamp":1656448374773},{"file_id":"1QaArRBpiPUWB-xqhdHQF0RuYpOmElf0x","timestamp":1655855819552}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"64a7d99de20c497cac092035237e6eac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_79507002bd824215a5888c55c69ebebd","IPY_MODEL_31c648be98b141b7878f3d8181345132","IPY_MODEL_c08557ceb01d4e63ac51eebdd7be5a44"],"layout":"IPY_MODEL_7dfa19e33ed048da83c749a6c9d86f0c"}},"79507002bd824215a5888c55c69ebebd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce56630d42584ec4bcb4f132dad0b1aa","placeholder":"​","style":"IPY_MODEL_ad7c64dd3ac94c0cafb6ecd7d02a9a37","value":"Downloading config.json: 100%"}},"31c648be98b141b7878f3d8181345132":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d671223d0a945a1b46e8c3ecb2df318","max":694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c227bf4d20a5475dad5c2493e385c3d5","value":694}},"c08557ceb01d4e63ac51eebdd7be5a44":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f064510e93cf41b88f944c2c23de55ac","placeholder":"​","style":"IPY_MODEL_ea8fc239dad545ad8f9fdb876330f8ed","value":" 694/694 [00:00&lt;00:00, 23.9kB/s]"}},"7dfa19e33ed048da83c749a6c9d86f0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce56630d42584ec4bcb4f132dad0b1aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad7c64dd3ac94c0cafb6ecd7d02a9a37":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d671223d0a945a1b46e8c3ecb2df318":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c227bf4d20a5475dad5c2493e385c3d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f064510e93cf41b88f944c2c23de55ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea8fc239dad545ad8f9fdb876330f8ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81fcf1b48a4748a4b9bb01d73b2c86c1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f0ea10634a9d426987bba955c1a83565","IPY_MODEL_e1edd76d9fb34e1d919bb34eb6e42d21","IPY_MODEL_60badc3a024b47e899b2c0e6324c27f3"],"layout":"IPY_MODEL_498f984d1f474cd3a5a7744100254ad5"}},"f0ea10634a9d426987bba955c1a83565":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_402b4a379b6f45bbb0d1785d148bb8a2","placeholder":"​","style":"IPY_MODEL_877d14d6c3f94fb3a930943a6ceb6870","value":"Downloading vocab.json: 100%"}},"e1edd76d9fb34e1d919bb34eb6e42d21":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fe8fa5958f04ad2a2e09134ca1396c0","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_11afb3360fd840f98f74d6511f1c8314","value":898823}},"60badc3a024b47e899b2c0e6324c27f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be4e6a1de79246fd8689bb3b4422a453","placeholder":"​","style":"IPY_MODEL_9424e0382ef04e98a6d60e7d4c8e2446","value":" 878k/878k [00:00&lt;00:00, 2.75MB/s]"}},"498f984d1f474cd3a5a7744100254ad5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"402b4a379b6f45bbb0d1785d148bb8a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"877d14d6c3f94fb3a930943a6ceb6870":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6fe8fa5958f04ad2a2e09134ca1396c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11afb3360fd840f98f74d6511f1c8314":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be4e6a1de79246fd8689bb3b4422a453":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9424e0382ef04e98a6d60e7d4c8e2446":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a0fcf5b1a9e4ce6814b06a28623cbe6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f4be6cce427a4b8097001d62d48daee7","IPY_MODEL_53ee54a729b24db9a72871e9f6fa6829","IPY_MODEL_15e8d09cfd3d4f65adcfd9319ca332be"],"layout":"IPY_MODEL_b8aa25928d4b458d8daf22799b936a9e"}},"f4be6cce427a4b8097001d62d48daee7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bf8458365874678a265925028997960","placeholder":"​","style":"IPY_MODEL_2b51930b66e7478cb21612c3521ba43a","value":"Downloading merges.txt: 100%"}},"53ee54a729b24db9a72871e9f6fa6829":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7a683ebfb4c4caaa9aaab306a7217dc","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a3c03e50a6c942ce82087cc8e316c1f0","value":456318}},"15e8d09cfd3d4f65adcfd9319ca332be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3e2e55627fd433f998f19e257920376","placeholder":"​","style":"IPY_MODEL_13611085692e425f83702f14e5ef6f1f","value":" 446k/446k [00:00&lt;00:00, 933kB/s]"}},"b8aa25928d4b458d8daf22799b936a9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bf8458365874678a265925028997960":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b51930b66e7478cb21612c3521ba43a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7a683ebfb4c4caaa9aaab306a7217dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3c03e50a6c942ce82087cc8e316c1f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e3e2e55627fd433f998f19e257920376":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13611085692e425f83702f14e5ef6f1f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2afeb13dedc40fa83250179c93ecbde":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7bcc697e7cf84f3bbdff376ccc47a545","IPY_MODEL_b312a4249e9940ee8389f942149d9634","IPY_MODEL_474be50ebaba40998448ec1d836ca6e1"],"layout":"IPY_MODEL_52709963b71f40da8ec7aed8152ccb1b"}},"7bcc697e7cf84f3bbdff376ccc47a545":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d500486d5944e3cb9c11e8ba1afedbc","placeholder":"​","style":"IPY_MODEL_966bc743d2054bd5ad9676a1d8aea9d9","value":"Downloading tokenizer.json: 100%"}},"b312a4249e9940ee8389f942149d9634":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b2858ca326c472694edbfd40fb86eb1","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a115c2716104aacb589b33f1c7ea93a","value":1355863}},"474be50ebaba40998448ec1d836ca6e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9437f0e5ecb435581d76aada34782bd","placeholder":"​","style":"IPY_MODEL_532bd3a419cd46baaa1a8a8d219787ca","value":" 1.29M/1.29M [00:00&lt;00:00, 1.46MB/s]"}},"52709963b71f40da8ec7aed8152ccb1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d500486d5944e3cb9c11e8ba1afedbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"966bc743d2054bd5ad9676a1d8aea9d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b2858ca326c472694edbfd40fb86eb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a115c2716104aacb589b33f1c7ea93a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e9437f0e5ecb435581d76aada34782bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"532bd3a419cd46baaa1a8a8d219787ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3907ed36b9444fa28fecbec1aecb4839":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1ff6a049b2d9499098a18bbd1528065b","IPY_MODEL_447126b6ffbc42ae83cec659f1fc834e","IPY_MODEL_60ed120b79eb4a0dbe21c3bbc5335ebd"],"layout":"IPY_MODEL_795466e4d20941a5abb635bad8a8bbfb"}},"1ff6a049b2d9499098a18bbd1528065b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_caad565f52a94ff186435973d46c2604","placeholder":"​","style":"IPY_MODEL_50016c74edf44822ac070e484c434e1e","value":"Downloading: 100%"}},"447126b6ffbc42ae83cec659f1fc834e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_68f375016bea456a99fe2bdf3c4a57c1","max":613,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a099609abe1410881b470afc249d6ee","value":613}},"60ed120b79eb4a0dbe21c3bbc5335ebd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd5b42d3126e4d999b8a7c538a135f50","placeholder":"​","style":"IPY_MODEL_8d6f315064dd46f3827e70ef250516d9","value":" 613/613 [00:00&lt;00:00, 13.6kB/s]"}},"795466e4d20941a5abb635bad8a8bbfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"caad565f52a94ff186435973d46c2604":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50016c74edf44822ac070e484c434e1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68f375016bea456a99fe2bdf3c4a57c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a099609abe1410881b470afc249d6ee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd5b42d3126e4d999b8a7c538a135f50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d6f315064dd46f3827e70ef250516d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7547421d2824f42b6341a9faf2a4e67":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c12243c415ab4d3f8786013a9971bd24","IPY_MODEL_057d17fd098749458b4ad7ab6f370242","IPY_MODEL_d0f02c9344cc4c85875263b2224b0c63"],"layout":"IPY_MODEL_86a28aee77a243cc91ef3cad80b7ab69"}},"c12243c415ab4d3f8786013a9971bd24":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be898a533044457cbd13175bd9e1ea1e","placeholder":"​","style":"IPY_MODEL_e1294f747b3343ea9e524f4538465e86","value":"Downloading data files: 100%"}},"057d17fd098749458b4ad7ab6f370242":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf8aa752bc8c4a918dfe3bdfb2507240","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_76834b6ab88d4bc78a1f5a98e9801b76","value":1}},"d0f02c9344cc4c85875263b2224b0c63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e726c2bb604b4467ba2f53505eda0271","placeholder":"​","style":"IPY_MODEL_375074015ede4a9ca0e73316e46e8746","value":" 1/1 [00:01&lt;00:00,  1.26s/it]"}},"86a28aee77a243cc91ef3cad80b7ab69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be898a533044457cbd13175bd9e1ea1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1294f747b3343ea9e524f4538465e86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf8aa752bc8c4a918dfe3bdfb2507240":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76834b6ab88d4bc78a1f5a98e9801b76":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e726c2bb604b4467ba2f53505eda0271":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"375074015ede4a9ca0e73316e46e8746":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b44191a4c892477c94ea3aa05fc7934a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fb494797c1f945968d20c40b9c98d3a4","IPY_MODEL_9bd07725876a4651889e72b0607966cd","IPY_MODEL_7bb7335b2d1a417688c7c1f3579ce8e2"],"layout":"IPY_MODEL_b730f7c52f244a3b907108ba959c7894"}},"fb494797c1f945968d20c40b9c98d3a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08f1e78d35e64fc280fbf685ce901fa3","placeholder":"​","style":"IPY_MODEL_48c80a6c88d04e6785a218ee84e4d269","value":"Downloading data: 100%"}},"9bd07725876a4651889e72b0607966cd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_54133b2784cf499e80fc89e32e812763","max":61146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_99e804cd5b814f0386965955f3ac1d5c","value":61146}},"7bb7335b2d1a417688c7c1f3579ce8e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8582d70fa85404faf0849c9749b5cf8","placeholder":"​","style":"IPY_MODEL_62216f3d48d14d998a1373c1dd1fc0e0","value":" 61.1k/61.1k [00:00&lt;00:00, 452kB/s]"}},"b730f7c52f244a3b907108ba959c7894":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08f1e78d35e64fc280fbf685ce901fa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48c80a6c88d04e6785a218ee84e4d269":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54133b2784cf499e80fc89e32e812763":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99e804cd5b814f0386965955f3ac1d5c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8582d70fa85404faf0849c9749b5cf8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62216f3d48d14d998a1373c1dd1fc0e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48e745b4eb0e40a6b8d8581451bc375b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1bec9787428e48dda83935e38389a44c","IPY_MODEL_9989dc88553d434693eeb384fbef28bf","IPY_MODEL_b2036da088954853bf4def237169af84"],"layout":"IPY_MODEL_5014425efb48487eaff5327c7d1f42d2"}},"1bec9787428e48dda83935e38389a44c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2ff2d7bb24c425fbc2fd10eae4561b7","placeholder":"​","style":"IPY_MODEL_fc40e0f41a4e4cb9a564fc7b17635202","value":"Extracting data files: 100%"}},"9989dc88553d434693eeb384fbef28bf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4be16d1da099475991dee27c5dd44e8b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_41b7e48703ec499e969e32075efc1e6f","value":1}},"b2036da088954853bf4def237169af84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a45ba1a5c604d83b7195320833b7dea","placeholder":"​","style":"IPY_MODEL_bb0f86ad98c14b6fbb9b034764ee09f8","value":" 1/1 [00:00&lt;00:00, 29.65it/s]"}},"5014425efb48487eaff5327c7d1f42d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2ff2d7bb24c425fbc2fd10eae4561b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc40e0f41a4e4cb9a564fc7b17635202":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4be16d1da099475991dee27c5dd44e8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41b7e48703ec499e969e32075efc1e6f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1a45ba1a5c604d83b7195320833b7dea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb0f86ad98c14b6fbb9b034764ee09f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"49876f0fd1fb426c95d014de7a01f05a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6fcf196085d84c1ab53bdf66ea9d5dcc","IPY_MODEL_63c4557f081042699a0998d093512b71","IPY_MODEL_d3308367e6104ed8a3a310f8d71f6864"],"layout":"IPY_MODEL_f058c869ae6244b5a59d45b1611120bf"}},"6fcf196085d84c1ab53bdf66ea9d5dcc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_87cb4b572d4b4fbc9e5cef6f2d078624","placeholder":"​","style":"IPY_MODEL_56d2b3e5025f4133982ae8648dbacbf3","value":""}},"63c4557f081042699a0998d093512b71":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f46f78a39d54ba58fe667dd8fec92fd","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_95b1c4022440461e8ffd153f89363701","value":1}},"d3308367e6104ed8a3a310f8d71f6864":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62d589f80acf45c0bb186d396fac2c8b","placeholder":"​","style":"IPY_MODEL_892b4d5979d341baafa1627836a12474","value":" 0/? [00:00&lt;?, ? tables/s]"}},"f058c869ae6244b5a59d45b1611120bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87cb4b572d4b4fbc9e5cef6f2d078624":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56d2b3e5025f4133982ae8648dbacbf3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f46f78a39d54ba58fe667dd8fec92fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"95b1c4022440461e8ffd153f89363701":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"62d589f80acf45c0bb186d396fac2c8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"892b4d5979d341baafa1627836a12474":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3567a6bb09e44b6a89c4c8c4164d3a3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6523595d7e04779914c0173b10def52","IPY_MODEL_688be0b904a049a7b032e7ba0f5303dd","IPY_MODEL_7350d8ac4d3d49978824dd2803335a7a"],"layout":"IPY_MODEL_c06a2852d8df404eab8bd03b8a270dcf"}},"d6523595d7e04779914c0173b10def52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c5aaa4ff47c463aaf6b1583a6ed626a","placeholder":"​","style":"IPY_MODEL_88845e9ab40b492c962c1af3b638e7fa","value":"100%"}},"688be0b904a049a7b032e7ba0f5303dd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e95b609c24744932a46c0967d8527ccb","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f48a963ebdfa4e2795bbb758aaebec6a","value":1}},"7350d8ac4d3d49978824dd2803335a7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28c506a8ead94b99bb930d23a114e34e","placeholder":"​","style":"IPY_MODEL_4d440ac69c214c349db569c360576b84","value":" 1/1 [00:00&lt;00:00, 33.77it/s]"}},"c06a2852d8df404eab8bd03b8a270dcf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c5aaa4ff47c463aaf6b1583a6ed626a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88845e9ab40b492c962c1af3b638e7fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e95b609c24744932a46c0967d8527ccb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f48a963ebdfa4e2795bbb758aaebec6a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"28c506a8ead94b99bb930d23a114e34e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d440ac69c214c349db569c360576b84":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"464037dc0ca4473e9007e6c543290c50":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ac0b4c7811704860b417c2ab3fee3684","IPY_MODEL_b87972569da344ed9656d9dcdd3901c4","IPY_MODEL_4e121d2b905047b99f03b9f231dcbee8"],"layout":"IPY_MODEL_d78b84fa2cfa4cfc896a2815ba5e30dc"}},"ac0b4c7811704860b417c2ab3fee3684":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe37daeac5b14feb8c6be2f90a6947c2","placeholder":"​","style":"IPY_MODEL_88b90d9f221342488d7be4088a9649c7","value":"100%"}},"b87972569da344ed9656d9dcdd3901c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eec7ae2422254cb1b0b4a7d73df09c17","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7924ca200cfe4501bc0191df768cc261","value":1}},"4e121d2b905047b99f03b9f231dcbee8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5471a50205fa47fcb8c8146ce261cb54","placeholder":"​","style":"IPY_MODEL_d573e68c41bb4ebca7acbf185e4947e8","value":" 1/1 [00:00&lt;00:00, 12.38ba/s]"}},"d78b84fa2cfa4cfc896a2815ba5e30dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe37daeac5b14feb8c6be2f90a6947c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88b90d9f221342488d7be4088a9649c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eec7ae2422254cb1b0b4a7d73df09c17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7924ca200cfe4501bc0191df768cc261":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5471a50205fa47fcb8c8146ce261cb54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d573e68c41bb4ebca7acbf185e4947e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77c3251fb05f4154abb338f84150c9b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_932b53c1d66c4cf1a9c38e54c965d375","IPY_MODEL_993fde43e65e4c78a3f48701cae9489b","IPY_MODEL_f4f859a052274e559d5d9d490ac8e2ee"],"layout":"IPY_MODEL_105b5e142f3042b2a5a7ca9de4ac83f5"}},"932b53c1d66c4cf1a9c38e54c965d375":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbae85bfa490413c83b0c69f05ccf42d","placeholder":"​","style":"IPY_MODEL_a76078ddb5d2432cab28426d876292f5","value":"Downloading pytorch_model.bin: 100%"}},"993fde43e65e4c78a3f48701cae9489b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_58a649d2a5be40468630aac908568d35","max":597257159,"min":0,"orientation":"horizontal","style":"IPY_MODEL_17cccedbdec44826becc5f04b97209ad","value":597257159}},"f4f859a052274e559d5d9d490ac8e2ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c65949e05a44f9fa3199ea4a18d54dd","placeholder":"​","style":"IPY_MODEL_2508670995394e319f72c823b64e7883","value":" 570M/570M [00:23&lt;00:00, 28.3MB/s]"}},"105b5e142f3042b2a5a7ca9de4ac83f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbae85bfa490413c83b0c69f05ccf42d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a76078ddb5d2432cab28426d876292f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58a649d2a5be40468630aac908568d35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17cccedbdec44826becc5f04b97209ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4c65949e05a44f9fa3199ea4a18d54dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2508670995394e319f72c823b64e7883":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}